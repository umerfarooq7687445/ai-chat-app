curl 'https://openrouter.ai/api/frontend/models/find?q=free' \
  -H 'accept: */*' \
  -H 'accept-language: en-US,en;q=0.6' \
  -b '__client_uat=0; __client_uat_NO6jtgZM=0; _ga=GA1.1.1879986049.1767714100; _ga_R8YZRJS2XN=GS2.1.s1767714099$o1$g1$t1767714125$j34$l0$h0$dV19oIkeOqPZgWzWKxFMpjFCjoFl5b5NJsA; _dd_s=aid=16ba6ce5-c9da-49c2-8ede-082481fb4208&rum=2&id=622e9b8d-f1dc-47ce-836f-c776ac9867b9&created=1767714098959&expire=1767715027817' \
  -H 'if-modified-since: Tue, 06 Jan 2026 15:41:39 GMT' \
  -H 'priority: u=1, i' \
  -H 'referer: https://openrouter.ai/models/?q=free' \
  -H 'sec-ch-ua: "Brave";v="143", "Chromium";v="143", "Not A(Brand";v="24"' \
  -H 'sec-ch-ua-mobile: ?0' \
  -H 'sec-ch-ua-platform: "macOS"' \
  -H 'sec-fetch-dest: empty' \
  -H 'sec-fetch-mode: cors' \
  -H 'sec-fetch-site: same-origin' \
  -H 'sec-gpc: 1' \
  -H 'user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36'


  {
    "data": {
        "models": [
            {
                "slug": "xiaomi/mimo-v2-flash",
                "hf_slug": "XiaomiMiMo/MiMo-V2-Flash",
                "updated_at": "2025-12-18T19:11:13.637601+00:00",
                "created_at": "2025-12-14T16:55:08+00:00",
                "hf_updated_at": null,
                "name": "Xiaomi: MiMo-V2-Flash (free)",
                "short_name": "MiMo-V2-Flash (free)",
                "author": "xiaomi",
                "description": "MiMo-V2-Flash is an open-source foundation language model developed by Xiaomi. It is a Mixture-of-Experts model with 309B total parameters and 15B active parameters, adopting hybrid attention architecture. MiMo-V2-Flash supports a hybrid-thinking toggle and a 256K context window, and excels at reasoning, coding, and agent scenarios. On SWE-bench Verified and SWE-bench Multilingual, MiMo-V2-Flash ranks as the top #1 open-source model globally, delivering performance comparable to Claude Sonnet 4.5 while costing only about 3.5% as much.\n\nNote: when integrating with agentic tools such as Claude Code, Cline, or Roo Code, **turn off reasoning mode** for the best and fastest performance—this model is deeply optimized for this scenario.\n\nUsers can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config).",
                "model_version_group_id": null,
                "context_length": 262144,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": "You are MiMo, an AI assistant developed by Xiaomi.\n\nYour knowledge cutoff date is December 2024.",
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "xiaomi/mimo-v2-flash-20251210",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    },
                    "chat_template_config": {}
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": 0.95,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "b15d10a1-65ec-4357-88e8-dc99751b93be",
                    "name": "Xiaomi | xiaomi/mimo-v2-flash-20251210:free",
                    "context_length": 262144,
                    "model": {
                        "slug": "xiaomi/mimo-v2-flash",
                        "hf_slug": "XiaomiMiMo/MiMo-V2-Flash",
                        "updated_at": "2025-12-18T19:11:13.637601+00:00",
                        "created_at": "2025-12-14T16:55:08+00:00",
                        "hf_updated_at": null,
                        "name": "Xiaomi: MiMo-V2-Flash",
                        "short_name": "MiMo-V2-Flash",
                        "author": "xiaomi",
                        "description": "MiMo-V2-Flash is an open-source foundation language model developed by Xiaomi. It is a Mixture-of-Experts model with 309B total parameters and 15B active parameters, adopting hybrid attention architecture. MiMo-V2-Flash supports a hybrid-thinking toggle and a 256K context window, and excels at reasoning, coding, and agent scenarios. On SWE-bench Verified and SWE-bench Multilingual, MiMo-V2-Flash ranks as the top #1 open-source model globally, delivering performance comparable to Claude Sonnet 4.5 while costing only about 3.5% as much.\n\nNote: when integrating with agentic tools such as Claude Code, Cline, or Roo Code, **turn off reasoning mode** for the best and fastest performance—this model is deeply optimized for this scenario.\n\nUsers can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config).",
                        "model_version_group_id": null,
                        "context_length": 262144,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": "You are MiMo, an AI assistant developed by Xiaomi.\n\nYour knowledge cutoff date is December 2024.",
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "xiaomi/mimo-v2-flash-20251210",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            },
                            "chat_template_config": {}
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": 0.95,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "xiaomi/mimo-v2-flash:free",
                    "model_variant_permaslug": "xiaomi/mimo-v2-flash-20251210:free",
                    "adapter_name": "XiaomiAdapter",
                    "provider_name": "Xiaomi",
                    "provider_info": {
                        "name": "Xiaomi",
                        "displayName": "Xiaomi",
                        "slug": "xiaomi",
                        "baseUrl": "https://api.xiaomimimo.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 30,
                            "canPublish": false,
                            "termsOfServiceURL": "https://platform.xiaomimimo.com/intl/#/docs/terms/user-agreement",
                            "privacyPolicyURL": "https://platform.xiaomimimo.com/intl/#/docs/terms/privacy-policy",
                            "requiresUserIDs": true
                        },
                        "headquarters": "CN",
                        "datacenters": [
                            "SG",
                            "NL"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [
                            "user_353qok8CmkPxVcEtDuGZzQOEu4u",
                            "user_35F3bTvDBxn8U8NlFRLtIufJNlD",
                            "user_36vqlXmXNo4fc4k6musIPTdL7Sj"
                        ],
                        "adapterName": "XiaomiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.mi.com/&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Xiaomi",
                    "provider_slug": "xiaomi/fp8",
                    "provider_model_id": "xiaomi/mimo-v2-flash",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 65536,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "response_format",
                        "tools",
                        "tool_choice",
                        "frequency_penalty",
                        "presence_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 30,
                        "canPublish": false,
                        "termsOfServiceURL": "https://platform.xiaomimimo.com/intl/#/docs/terms/user-agreement",
                        "privacyPolicyURL": "https://platform.xiaomimimo.com/intl/#/docs/terms/privacy-policy",
                        "requiresUserIDs": true
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "disable_free_endpoint_limits": true,
                        "reasoning_return_mechanism": "reasoning-content",
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": false,
                            "type_function": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "mistralai/devstral-2512",
                "hf_slug": "mistralai/Devstral-2-123B-Instruct-2512",
                "updated_at": "2025-12-09T16:24:38.243423+00:00",
                "created_at": "2025-12-09T13:03:39+00:00",
                "hf_updated_at": null,
                "name": "Mistral: Devstral 2 2512 (free)",
                "short_name": "Devstral 2 2512 (free)",
                "author": "mistralai",
                "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding. It is a 123B-parameter dense transformer model supporting a 256K context window.\n\nDevstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems. The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases. It is available under a modified MIT license.",
                "model_version_group_id": null,
                "context_length": 262144,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Mistral",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": "",
                "routing_error_message": "",
                "permaslug": "mistralai/devstral-2512",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {
                    "temperature": 0.3,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "051afd3d-0ef7-4e5d-a4c6-58152b120da0",
                    "name": "Mistral | mistralai/devstral-2512:free",
                    "context_length": 262144,
                    "model": {
                        "slug": "mistralai/devstral-2512",
                        "hf_slug": "mistralai/Devstral-2-123B-Instruct-2512",
                        "updated_at": "2025-12-09T16:24:38.243423+00:00",
                        "created_at": "2025-12-09T13:03:39+00:00",
                        "hf_updated_at": null,
                        "name": "Mistral: Devstral 2 2512",
                        "short_name": "Devstral 2 2512",
                        "author": "mistralai",
                        "description": "Devstral 2 is a state-of-the-art open-source model by Mistral AI specializing in agentic coding. It is a 123B-parameter dense transformer model supporting a 256K context window.\n\nDevstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems. The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases. It is available under a modified MIT license.",
                        "model_version_group_id": null,
                        "context_length": 262144,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Mistral",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": "",
                        "routing_error_message": "",
                        "permaslug": "mistralai/devstral-2512",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {
                            "temperature": 0.3,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "mistralai/devstral-2512:free",
                    "model_variant_permaslug": "mistralai/devstral-2512:free",
                    "adapter_name": "MistralAdapter",
                    "provider_name": "Mistral",
                    "provider_info": {
                        "name": "Mistral",
                        "displayName": "Mistral",
                        "slug": "mistral",
                        "baseUrl": "https://api.mistral.ai/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 30,
                            "canPublish": false,
                            "termsOfServiceURL": "https://mistral.ai/terms/#terms-of-use",
                            "privacyPolicyURL": "https://mistral.ai/terms/#privacy-policy"
                        },
                        "headquarters": "FR",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "MistralAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": "https://status.mistral.ai/",
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/Mistral.png"
                        },
                        "ignoredProviderModels": [
                            "mistral-moderation-2411-all",
                            "voxtral-mini-2507",
                            "voxtral-small-2507",
                            "voxtral-mini-transcribe-2507",
                            "mistral-medium",
                            "mistral-tiny",
                            "mistral-tiny-2312",
                            "open-mistral-nemo",
                            "mistral-tiny-2407",
                            "open-mixtral-8x7b",
                            "mistral-small",
                            "mistral-small-2312",
                            "open-mixtral-8x22b-2404",
                            "mistral-large-pixtral-2411",
                            "codestral-2412",
                            "codestral-2411-rc5",
                            "pixtral-12b",
                            "mistral-moderation-2411",
                            "mistral-ocr-2503",
                            "mistral-ocr-2505",
                            "mistral-saba-2502",
                            "open-mixtral-8x22b",
                            "mistral-large-2407",
                            "magistral-medium-2507",
                            "mistral-embed",
                            "codestral-embed",
                            "codestral-2501",
                            "mistral-small-2501",
                            "mistral-ocr-2512"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Mistral",
                    "provider_slug": "mistral",
                    "provider_model_id": "devstral-2512",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "seed",
                        "response_format",
                        "structured_outputs",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 30,
                        "canPublish": false,
                        "termsOfServiceURL": "https://mistral.ai/terms/#terms-of-use",
                        "privacyPolicyURL": "https://mistral.ai/terms/#privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": 600,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_input_audio": false,
                        "disable_free_endpoint_limits": true,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "kwaipilot/kat-coder-pro",
                "hf_slug": "",
                "updated_at": "2026-01-05T03:28:20.327462+00:00",
                "created_at": "2025-11-10T03:38:32.123517+00:00",
                "hf_updated_at": null,
                "name": "Kwaipilot: KAT-Coder-Pro V1 (free)",
                "short_name": "KAT-Coder-Pro V1 (free)",
                "author": "kwaipilot",
                "description": "KAT-Coder-Pro V1 is KwaiKAT's most advanced agentic coding model in the KAT-Coder series. Designed specifically for agentic coding tasks, it excels in real-world software engineering scenarios, achieving 73.4% solve rate on the SWE-Bench Verified benchmark. \n\nThe model has been optimized for tool-use capability, multi-turn interaction, instruction following, generalization, and comprehensive capabilities through a multi-stage training process, including mid-training, supervised fine-tuning (SFT), reinforcement fine-tuning (RFT), and scalable agentic RL.",
                "model_version_group_id": null,
                "context_length": 256000,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "The free endpoint has reduced rate limits from January 5-12, after which it will be deprecated. Use [kwaipilot/kat-coder-pro-v1](https://openrouter.ai/kwaipilot/kat-coder-pro) for continued access.",
                "promotion_message": "",
                "routing_error_message": null,
                "permaslug": "kwaipilot/kat-coder-pro-v1",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": null,
                    "end_token": null,
                    "system_prompt": null,
                    "is_mandatory_reasoning": null,
                    "supports_reasoning_max_tokens": null,
                    "supported_reasoning_efforts": null,
                    "default_reasoning_effort": null
                },
                "features": {
                    "reasoning_config": {
                        "start_token": null,
                        "end_token": null,
                        "system_prompt": null,
                        "is_mandatory_reasoning": null,
                        "supports_reasoning_max_tokens": null,
                        "supported_reasoning_efforts": null,
                        "default_reasoning_effort": null
                    },
                    "chat_template_config": {
                        "should_hoist_and_merge_system_messages": null
                    }
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "30a194a6-96b0-48c2-b141-5dfb0eb00e32",
                    "name": "AtlasCloud | kwaipilot/kat-coder-pro-v1:free",
                    "context_length": 256000,
                    "model": {
                        "slug": "kwaipilot/kat-coder-pro",
                        "hf_slug": "",
                        "updated_at": "2026-01-05T03:28:20.327462+00:00",
                        "created_at": "2025-11-10T03:38:32.123517+00:00",
                        "hf_updated_at": null,
                        "name": "Kwaipilot: KAT-Coder-Pro V1",
                        "short_name": "KAT-Coder-Pro V1",
                        "author": "kwaipilot",
                        "description": "KAT-Coder-Pro V1 is KwaiKAT's most advanced agentic coding model in the KAT-Coder series. Designed specifically for agentic coding tasks, it excels in real-world software engineering scenarios, achieving 73.4% solve rate on the SWE-Bench Verified benchmark. \n\nThe model has been optimized for tool-use capability, multi-turn interaction, instruction following, generalization, and comprehensive capabilities through a multi-stage training process, including mid-training, supervised fine-tuning (SFT), reinforcement fine-tuning (RFT), and scalable agentic RL.",
                        "model_version_group_id": null,
                        "context_length": 262144,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "The free endpoint has reduced rate limits from January 5-12, after which it will be deprecated. Use [kwaipilot/kat-coder-pro-v1](https://openrouter.ai/kwaipilot/kat-coder-pro) for continued access.",
                        "promotion_message": "",
                        "routing_error_message": null,
                        "permaslug": "kwaipilot/kat-coder-pro-v1",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": null,
                            "end_token": null,
                            "system_prompt": null,
                            "is_mandatory_reasoning": null,
                            "supports_reasoning_max_tokens": null,
                            "supported_reasoning_efforts": null,
                            "default_reasoning_effort": null
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": null,
                                "end_token": null,
                                "system_prompt": null,
                                "is_mandatory_reasoning": null,
                                "supports_reasoning_max_tokens": null,
                                "supported_reasoning_efforts": null,
                                "default_reasoning_effort": null
                            },
                            "chat_template_config": {
                                "should_hoist_and_merge_system_messages": null
                            }
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "kwaipilot/kat-coder-pro:free",
                    "model_variant_permaslug": "kwaipilot/kat-coder-pro-v1:free",
                    "adapter_name": "AtlasCloudAdapter",
                    "provider_name": "AtlasCloud",
                    "provider_info": {
                        "name": "AtlasCloud",
                        "displayName": "AtlasCloud",
                        "slug": "atlas-cloud",
                        "baseUrl": "https://api.atlascloud.ai/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "privacyPolicyURL": "https://www.atlascloud.ai/privacy"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "AtlasCloudAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.atlascloud.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-thinking",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.5-flash-preview-05-20",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash",
                            "gemini-2.5-pro",
                            "gemini-2.5-flash-thinking",
                            "gemini-2.5-flash-lite",
                            "claude-opus-4-1-20250805-thinking",
                            "claude-opus-4-1-20250805",
                            "claude-opus-4-20250514-thinking",
                            "claude-opus-4-20250514",
                            "claude-sonnet-4-20250514-thinking",
                            "claude-sonnet-4-20250514",
                            "claude-3-7-sonnet-20250219-thinking",
                            "claude-3-7-sonnet-20250219",
                            "claude-3-5-sonnet-20241022",
                            "claude-3-5-haiku-20241022",
                            "gemini-2.5-flash-image-preview",
                            "gpt-4.1",
                            "gpt-4.1-mini",
                            "gpt-4o",
                            "gpt-4o-mini",
                            "gpt-5",
                            "gpt-5-nano",
                            "o1",
                            "o1-mini",
                            "o3",
                            "o3-mini",
                            "o4-mini",
                            "grok-3",
                            "grok-4",
                            "claude-sonnet-4-5-20250929-thinking",
                            "claude-sonnet-4-5-20250929",
                            "doubao-pro-32k",
                            "doubao-1-5-thinking-pro-250415",
                            "doubao-1-5-pro-256k-250115",
                            "doubao-seed-1-6-thinking-250715",
                            "doubao-seed-1-6-thinking-250615",
                            "doubao-pro-32k-241215",
                            "doubao-seed-1-6-flash-250615",
                            "doubao-lite-32k-character-250228",
                            "doubao-seed-1-6-250615",
                            "doubao-1-5-vision-pro-32k-250115",
                            "doubao-pro-32k-character-241215",
                            "doubao-1-5-vision-pro-250328",
                            "doubao-1-5-ui-tars-250428",
                            "doubao-1-5-thinking-vision-pro-250428",
                            "doubao-1-5-thinking-pro-m-250428",
                            "doubao-1.5-pro-256k",
                            "doubao-1.5-pro-32k",
                            "doubao-1-5-pro-32k-250115",
                            "claude-haiku-4-5-20251001-thinking",
                            "claude-haiku-4-5-20251001",
                            "gemini-2.5-flash-lite-preview-09-2025-enterprise",
                            "gemini-2.5-flash-enterprise",
                            "gemini-2.5-flash-preview-09-2025-enterprise",
                            "gemini-2.5-flash-lite-enterprise",
                            "gemini-2.5-flash-preview-09-2025",
                            "gemini-2.5-flash-lite-preview-09-2025",
                            "grok-3-mini-enterprise",
                            "grok-3-enterprise",
                            "google/gemini-3-pro-preview",
                            "OpenAI/gpt-5",
                            "OpenAI/gpt-5-pro",
                            "OpenAI/gpt-5-chat",
                            "OpenAI/gpt-5-codex",
                            "OpenAI/gpt-5-mini",
                            "OpenAI/gpt-5-nano",
                            "google/gemini-2.5-pro-developer",
                            "google/gemini-2.5-pro-preview-06-05-developer",
                            "google/gemini-2.5-flash-preview-05-20-developer",
                            "google/gemini-2.5-flash-lite-preview-06-17-developer",
                            "google/gemini-2.5-flash-developer",
                            "google/gemini-2.5-flash-lite-developer",
                            "xai/grok-3-mini",
                            "xai/grok-3",
                            "anthropic/claude-haiku-4.5-20251001-thinking-developer",
                            "anthropic/claude-haiku-4.5-20251001-developer",
                            "xai/grok-4-developer",
                            "google/gemini-2.5-flash-image-preview-developer",
                            "google/gemini-2.5-flash-preview-202509-developer",
                            "google/gemini-2.5-flash",
                            "google/gemini-2.5-flash-preview-202509",
                            "google/gemini-2.5-flash-lite",
                            "google/gemini-2.5-flash-lite-preview-202509",
                            "google/gemini-2.5-flash-lite-preview-202509-developer",
                            "anthropic/claude-sonnet-4-20250514-thinking-developer",
                            "anthropic/claude-sonnet-4-20250514-developer",
                            "anthropic/claude-sonnet-4.5-20250929-developer",
                            "google/gemini-2.5-pro-preview-0605-developer",
                            "google/gemini-2.5-flash-preview-0520-developer",
                            "google/gemini-2.5-flash-lite-preview-0617-developer",
                            "xai/grok-3-developer",
                            "anthropic/claude-sonnet-4.5-20250929-thinking-developer",
                            "anthropic/claude-sonnet-3.7-20250219-thinking-developer",
                            "anthropic/claude-sonnet-3.7-20250219-developer",
                            "anthropic/claude-sonnet-3.5-20241022-developer",
                            "anthropic/claude-haiku-3.5-20241022-developer",
                            "openai/gpt-5.1",
                            "openai/gpt-5.1-chat",
                            "openai/gpt-5.1-codex",
                            "openai/gpt-5.1-codex-mini",
                            "google/gemini-3-pro-preview-thinking-developer",
                            "google/gemini-3-pro-preview-developer",
                            "openai/gpt-5-developer",
                            "openai/gpt-5-nano-developer",
                            "openai/gpt-4o-developer",
                            "openai/gpt-4o-mini-developer",
                            "openai/o1-developer",
                            "openai/o1-mini-developer",
                            "openai/o3-developer",
                            "openai/o3-mini-developer",
                            "openai/o4-mini-developer",
                            "openai/gpt-4.1-developer",
                            "openai/gpt-4.1-mini-developer",
                            "openai/o3-pro",
                            "openai/o4-mini",
                            "openai/o3-mini",
                            "openai/o3",
                            "openai/o1",
                            "openai/gpt-4.1",
                            "openai/gpt-4.1-mini",
                            "openai/gpt-4.1-nano",
                            "openai/gpt-4o",
                            "openai/gpt-4o-mini",
                            "anthropic/claude-opus-4.5-20251101-developer",
                            "openai/gpt-5.1-codex-developer",
                            "openai/gpt-5.1-chat-developer",
                            "openai/gpt-5.1-developer",
                            "anthropic/claude-sonnet-4-20250514",
                            "anthropic/claude-haiku-4.5-20251001",
                            "anthropic/claude-sonnet-4.5-20250929",
                            "anthropic/claude-opus-4.1-20250805",
                            "anthropic/claude-3.7-sonnet-20250219",
                            "anthropic/claude-opus-4-20250514",
                            "openai/gpt-5.1-codex-mini-developer",
                            "openai/gpt-5-pro-developer",
                            "openai/gpt-5-mini-developer",
                            "openai/gpt-5-codex-developer",
                            "anthropic/claude-opus-4-20250514-developer",
                            "openai/gpt-4.1-nano-developer",
                            "kwaipilot/kat-coder-air",
                            "kwaipilot/kat-coder-exp-72b-1010",
                            "openai/gpt-5",
                            "openai/gpt-5-chat",
                            "openai/gpt-5-codex",
                            "openai/gpt-5-mini",
                            "openai/gpt-5-nano",
                            "openai/gpt-5-pro",
                            "openai/gpt-5.1-codex-max",
                            "openai/gpt-5.2",
                            "openai/gpt-5.2-chat",
                            "google/gemini-2.5-pro",
                            "openai/gpt-5.2-developer",
                            "anthropic/claude-opus-4.5-20251101",
                            "openai/gpt-image-1-developer",
                            "google/gemini-3-flash-preview-developer",
                            "google/gemini-3-flash-preview",
                            "google/gemini-2.0-flash",
                            "google/gemini-2.0-flash-lite",
                            "deepseek-ai/deepseek-ocr"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "AtlasCloud",
                    "provider_slug": "atlas-cloud/fp16",
                    "provider_model_id": "kwaipilot/kat-coder-pro",
                    "quantization": "fp16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 128000,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "tools",
                        "tool_choice",
                        "structured_outputs",
                        "response_format"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "privacyPolicyURL": "https://www.atlascloud.ai/privacy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": 7,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "disable_free_endpoint_limits": true,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": "2026-01-12"
                }
            },
            {
                "slug": "tngtech/deepseek-r1t2-chimera",
                "hf_slug": "tngtech/DeepSeek-TNG-R1T2-Chimera",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-08T15:03:05.127934+00:00",
                "hf_updated_at": null,
                "name": "TNG: DeepSeek R1T2 Chimera (free)",
                "short_name": "DeepSeek R1T2 Chimera (free)",
                "author": "tngtech",
                "description": "DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from TNG Tech. It is a 671 B-parameter mixture-of-experts text-generation model assembled from DeepSeek-AI’s R1-0528, R1, and V3-0324 checkpoints with an Assembly-of-Experts merge. The tri-parent design yields strong reasoning performance while running roughly 20 % faster than the original R1 and more than 2× faster than R1-0528 under vLLM, giving a favorable cost-to-intelligence trade-off. The checkpoint supports contexts up to 60 k tokens in standard use (tested to ~130 k) and maintains consistent <think> token behaviour, making it suitable for long-context analysis, dialogue and other open-ended generation tasks.",
                "model_version_group_id": null,
                "context_length": 163840,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "DeepSeek",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "tngtech/deepseek-r1t2-chimera",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    }
                },
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "62aa67ef-4310-4921-9da1-e86543114d22",
                    "name": "Chutes | tngtech/deepseek-r1t2-chimera:free",
                    "context_length": 163840,
                    "model": {
                        "slug": "tngtech/deepseek-r1t2-chimera",
                        "hf_slug": "tngtech/DeepSeek-TNG-R1T2-Chimera",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-08T15:03:05.127934+00:00",
                        "hf_updated_at": null,
                        "name": "TNG: DeepSeek R1T2 Chimera",
                        "short_name": "DeepSeek R1T2 Chimera",
                        "author": "tngtech",
                        "description": "DeepSeek-TNG-R1T2-Chimera is the second-generation Chimera model from TNG Tech. It is a 671 B-parameter mixture-of-experts text-generation model assembled from DeepSeek-AI’s R1-0528, R1, and V3-0324 checkpoints with an Assembly-of-Experts merge. The tri-parent design yields strong reasoning performance while running roughly 20 % faster than the original R1 and more than 2× faster than R1-0528 under vLLM, giving a favorable cost-to-intelligence trade-off. The checkpoint supports contexts up to 60 k tokens in standard use (tested to ~130 k) and maintains consistent <think> token behaviour, making it suitable for long-context analysis, dialogue and other open-ended generation tasks.",
                        "model_version_group_id": null,
                        "context_length": 163840,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "DeepSeek",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "tngtech/deepseek-r1t2-chimera",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            }
                        },
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "tngtech/deepseek-r1t2-chimera:free",
                    "model_variant_permaslug": "tngtech/deepseek-r1t2-chimera:free",
                    "adapter_name": "ChutesAdapter",
                    "provider_name": "Chutes",
                    "provider_info": {
                        "name": "Chutes",
                        "displayName": "Chutes",
                        "slug": "chutes",
                        "baseUrl": "https://llm.chutes.ai/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": false,
                            "termsOfServiceURL": "https://chutes.ai/tos"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "ChutesAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "openbmb/MiniCPM4-8B",
                            "agentica-org/DeepSWE-Preview",
                            "moonshotai/Kimi-K2-Instruct-tools",
                            "internlm/Intern-S1",
                            "TheDrummer/Gemmasutra-Pro-27B-v1.1",
                            "all-hands/openhands-lm-32b-v0.1-ep3",
                            "TheDrummer/Tunguska-39B-v1",
                            "Meridian",
                            "Zenith",
                            "Proxima",
                            "agentica-org/DeepCoder-14B-Preview",
                            "TheDrummer/Cydonia-24B-v2.1",
                            "Tesslate/UIGEN-X-32B-0727",
                            "NousResearch/Hermes-4-14B",
                            "unsloth/gemma-3-4b-it",
                            "tencent/Hunyuan-A13B-Instruct",
                            "unsloth/Llama-3.2-3B-Instruct",
                            "unsloth/Llama-3.2-1B-Instruct",
                            "zai-org/GLM-4.5-turbo",
                            "zai-org/GLM-4.6-turbo",
                            "rednote-hilab/dots.ocr",
                            "deepseek-ai/DeepSeek-V3-0324-turbo",
                            "deepseek-ai/DeepSeek-V3.1-turbo",
                            "moonshotai/Kimi-K2-Thinking",
                            "zai-org/GLM-4.5",
                            "deepseek-ai/DeepSeek-V3.1"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Chutes",
                    "provider_slug": "chutes",
                    "provider_model_id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "seed",
                        "top_k",
                        "repetition_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": false,
                        "termsOfServiceURL": "https://chutes.ai/tos"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "nex-agi/deepseek-v3.1-nex-n1",
                "hf_slug": "nex-agi/DeepSeek-V3.1-Nex-N1",
                "updated_at": "2025-12-11T13:42:01.208686+00:00",
                "created_at": "2025-12-08T14:33:13.21834+00:00",
                "hf_updated_at": null,
                "name": "Nex AGI: DeepSeek V3.1 Nex N1 (free)",
                "short_name": "DeepSeek V3.1 Nex N1 (free)",
                "author": "nex-agi",
                "description": "DeepSeek V3.1 Nex-N1 is the flagship release of the Nex-N1 series — a post-trained model designed to highlight agent autonomy, tool use, and real-world productivity. \n\nNex-N1 demonstrates competitive performance across all evaluation scenarios, showing particularly strong results in practical coding and HTML generation tasks.",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "DeepSeek",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "nex-agi/deepseek-v3.1-nex-n1",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "220ae074-7efe-45b9-b305-b23ad6c641c7",
                    "name": "SiliconFlow | nex-agi/deepseek-v3.1-nex-n1:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "nex-agi/deepseek-v3.1-nex-n1",
                        "hf_slug": "nex-agi/DeepSeek-V3.1-Nex-N1",
                        "updated_at": "2025-12-11T13:42:01.208686+00:00",
                        "created_at": "2025-12-08T14:33:13.21834+00:00",
                        "hf_updated_at": null,
                        "name": "Nex AGI: DeepSeek V3.1 Nex N1",
                        "short_name": "DeepSeek V3.1 Nex N1",
                        "author": "nex-agi",
                        "description": "DeepSeek V3.1 Nex-N1 is the flagship release of the Nex-N1 series — a post-trained model designed to highlight agent autonomy, tool use, and real-world productivity. \n\nNex-N1 demonstrates competitive performance across all evaluation scenarios, showing particularly strong results in practical coding and HTML generation tasks.",
                        "model_version_group_id": null,
                        "context_length": 8192,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "DeepSeek",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "nex-agi/deepseek-v3.1-nex-n1",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "nex-agi/deepseek-v3.1-nex-n1:free",
                    "model_variant_permaslug": "nex-agi/deepseek-v3.1-nex-n1:free",
                    "adapter_name": "SiliconFlowAdapter",
                    "provider_name": "SiliconFlow",
                    "provider_info": {
                        "name": "SiliconFlow",
                        "displayName": "SiliconFlow",
                        "slug": "siliconflow",
                        "baseUrl": "https://api.siliconflow.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://docs.siliconflow.com/en/legals/terms-of-service",
                            "privacyPolicyURL": "https://docs.siliconflow.com/en/legals/privacy-policy"
                        },
                        "headquarters": "SG",
                        "datacenters": [],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "SiliconFlowAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "/images/icons/SiliconFlow.svg"
                        },
                        "ignoredProviderModels": [
                            "inclusionAI/Ling-mini-2.0",
                            "inclusionAI/Ring-flash-2.0",
                            "inclusionAI/Ling-flash-2.0"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "SiliconFlow",
                    "provider_slug": "siliconflow/fp8",
                    "provider_model_id": "nex-agi/DeepSeek-V3.1-Nex-N1",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 163840,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "temperature",
                        "top_p",
                        "top_k",
                        "frequency_penalty",
                        "tool_choice",
                        "tools",
                        "structured_outputs",
                        "response_format"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://docs.siliconflow.com/en/legals/terms-of-service",
                        "privacyPolicyURL": "https://docs.siliconflow.com/en/legals/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "input_cache_read": "0",
                        "input_cache_write": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "tngtech/deepseek-r1t-chimera",
                "hf_slug": "tngtech/DeepSeek-R1T-Chimera",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-04-27T13:34:35.172638+00:00",
                "hf_updated_at": null,
                "name": "TNG: DeepSeek R1T Chimera (free)",
                "short_name": "DeepSeek R1T Chimera (free)",
                "author": "tngtech",
                "description": "DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3 (0324), combining the reasoning capabilities of R1 with the token efficiency improvements of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized for general text generation tasks.\n\nThe model merges pretrained weights from both source models to balance performance across reasoning, efficiency, and instruction-following tasks. It is released under the MIT license and intended for research and commercial use.",
                "model_version_group_id": null,
                "context_length": 163840,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "DeepSeek",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "tngtech/deepseek-r1t-chimera",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>"
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>"
                    }
                },
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "817eb65c-3217-4a55-9d95-834243ed3e3b",
                    "name": "Chutes | tngtech/deepseek-r1t-chimera:free",
                    "context_length": 163840,
                    "model": {
                        "slug": "tngtech/deepseek-r1t-chimera",
                        "hf_slug": "tngtech/DeepSeek-R1T-Chimera",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-04-27T13:34:35.172638+00:00",
                        "hf_updated_at": null,
                        "name": "TNG: DeepSeek R1T Chimera",
                        "short_name": "DeepSeek R1T Chimera",
                        "author": "tngtech",
                        "description": "DeepSeek-R1T-Chimera is created by merging DeepSeek-R1 and DeepSeek-V3 (0324), combining the reasoning capabilities of R1 with the token efficiency improvements of V3. It is based on a DeepSeek-MoE Transformer architecture and is optimized for general text generation tasks.\n\nThe model merges pretrained weights from both source models to balance performance across reasoning, efficiency, and instruction-following tasks. It is released under the MIT license and intended for research and commercial use.",
                        "model_version_group_id": null,
                        "context_length": 163840,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "DeepSeek",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "tngtech/deepseek-r1t-chimera",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>"
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>"
                            }
                        },
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "tngtech/deepseek-r1t-chimera:free",
                    "model_variant_permaslug": "tngtech/deepseek-r1t-chimera:free",
                    "adapter_name": "ChutesAdapter",
                    "provider_name": "Chutes",
                    "provider_info": {
                        "name": "Chutes",
                        "displayName": "Chutes",
                        "slug": "chutes",
                        "baseUrl": "https://llm.chutes.ai/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": false,
                            "termsOfServiceURL": "https://chutes.ai/tos"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "ChutesAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "openbmb/MiniCPM4-8B",
                            "agentica-org/DeepSWE-Preview",
                            "moonshotai/Kimi-K2-Instruct-tools",
                            "internlm/Intern-S1",
                            "TheDrummer/Gemmasutra-Pro-27B-v1.1",
                            "all-hands/openhands-lm-32b-v0.1-ep3",
                            "TheDrummer/Tunguska-39B-v1",
                            "Meridian",
                            "Zenith",
                            "Proxima",
                            "agentica-org/DeepCoder-14B-Preview",
                            "TheDrummer/Cydonia-24B-v2.1",
                            "Tesslate/UIGEN-X-32B-0727",
                            "NousResearch/Hermes-4-14B",
                            "unsloth/gemma-3-4b-it",
                            "tencent/Hunyuan-A13B-Instruct",
                            "unsloth/Llama-3.2-3B-Instruct",
                            "unsloth/Llama-3.2-1B-Instruct",
                            "zai-org/GLM-4.5-turbo",
                            "zai-org/GLM-4.6-turbo",
                            "rednote-hilab/dots.ocr",
                            "deepseek-ai/DeepSeek-V3-0324-turbo",
                            "deepseek-ai/DeepSeek-V3.1-turbo",
                            "moonshotai/Kimi-K2-Thinking",
                            "zai-org/GLM-4.5",
                            "deepseek-ai/DeepSeek-V3.1"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Chutes",
                    "provider_slug": "chutes",
                    "provider_model_id": "tngtech/DeepSeek-R1T-Chimera",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "seed",
                        "top_k",
                        "repetition_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": false,
                        "termsOfServiceURL": "https://chutes.ai/tos"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "nvidia/nemotron-3-nano-30b-a3b",
                "hf_slug": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
                "updated_at": "2025-12-16T17:44:22.146099+00:00",
                "created_at": "2025-12-14T16:54:35+00:00",
                "hf_updated_at": null,
                "name": "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
                "short_name": "Nemotron 3 Nano 30B A3B (free)",
                "author": "nvidia",
                "description": "NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with highest compute efficiency and accuracy for developers to build specialized agentic AI systems.\n\nThe model is fully open with open-weights, datasets and recipes so developers can easily\ncustomize, optimize, and deploy the model on their infrastructure for maximum privacy and\nsecurity.\n\nNote: For the free endpoint, all prompts and output are logged to improve the provider's model and its product and services. Please do not upload any personal, confidential, or otherwise sensitive information. This is a trial use only. Do not use for production or business-critical systems.",
                "model_version_group_id": null,
                "context_length": 256000,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": "",
                "routing_error_message": "",
                "permaslug": "nvidia/nemotron-3-nano-30b-a3b",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    },
                    "chat_template_config": {}
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "94f9fb8b-f775-405d-8c3a-6c918cb12dd8",
                    "name": "Nvidia | nvidia/nemotron-3-nano-30b-a3b:free",
                    "context_length": 256000,
                    "model": {
                        "slug": "nvidia/nemotron-3-nano-30b-a3b",
                        "hf_slug": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
                        "updated_at": "2025-12-16T17:44:22.146099+00:00",
                        "created_at": "2025-12-14T16:54:35+00:00",
                        "hf_updated_at": null,
                        "name": "NVIDIA: Nemotron 3 Nano 30B A3B",
                        "short_name": "Nemotron 3 Nano 30B A3B",
                        "author": "nvidia",
                        "description": "NVIDIA Nemotron 3 Nano 30B A3B is a small language MoE model with highest compute efficiency and accuracy for developers to build specialized agentic AI systems.\n\nThe model is fully open with open-weights, datasets and recipes so developers can easily\ncustomize, optimize, and deploy the model on their infrastructure for maximum privacy and\nsecurity.\n\nNote: For the free endpoint, all prompts and output are logged to improve the provider's model and its product and services. Please do not upload any personal, confidential, or otherwise sensitive information. This is a trial use only. Do not use for production or business-critical systems.",
                        "model_version_group_id": null,
                        "context_length": 256000,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": "",
                        "routing_error_message": "",
                        "permaslug": "nvidia/nemotron-3-nano-30b-a3b",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            },
                            "chat_template_config": {}
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "nvidia/nemotron-3-nano-30b-a3b:free",
                    "model_variant_permaslug": "nvidia/nemotron-3-nano-30b-a3b:free",
                    "adapter_name": "NvidiaAdapter",
                    "provider_name": "Nvidia",
                    "provider_info": {
                        "name": "Nvidia",
                        "displayName": "NVIDIA",
                        "slug": "nvidia",
                        "baseUrl": "https://integrate.api.nvidia.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                            "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "NvidiaAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.nvidia.com/en-us/&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "NVIDIA",
                    "provider_slug": "nvidia/bf16",
                    "provider_model_id": "private/openrouter/nvidia/nemotron-3-nano-30b-a3b",
                    "quantization": "bf16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "temperature",
                        "max_tokens",
                        "seed",
                        "top_p",
                        "tool_choice",
                        "tools"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": true,
                        "retainsPrompts": true,
                        "canPublish": false,
                        "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                        "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_multipart": true,
                        "supports_input_audio": false,
                        "disable_free_endpoint_limits": false,
                        "reasoning_return_mechanism": "reasoning-content",
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": false,
                            "type_function": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "nvidia/nemotron-nano-12b-v2-vl",
                "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
                "updated_at": "2025-11-12T02:19:07.557675+00:00",
                "created_at": "2025-10-28T18:19:25.723503+00:00",
                "hf_updated_at": null,
                "name": "NVIDIA: Nemotron Nano 12B 2 VL (free)",
                "short_name": "Nemotron Nano 12B 2 VL (free)",
                "author": "nvidia",
                "description": "NVIDIA Nemotron Nano 2 VL is a 12-billion-parameter open multimodal reasoning model designed for video understanding and document intelligence. It introduces a hybrid Transformer-Mamba architecture, combining transformer-level accuracy with Mamba’s memory-efficient sequence modeling for significantly higher throughput and lower latency.\n\nThe model supports inputs of text and multi-image documents, producing natural-language outputs. It is trained on high-quality NVIDIA-curated synthetic datasets optimized for optical-character recognition, chart reasoning, and multimodal comprehension.\n\nNemotron Nano 2 VL achieves leading results on OCRBench v2 and scores ≈ 74 average across MMMU, MathVista, AI2D, OCRBench, OCR-Reasoning, ChartQA, DocVQA, and Video-MME—surpassing prior open VL baselines. With Efficient Video Sampling (EVS), it handles long-form videos while reducing inference cost.\n\nOpen-weights, training data, and fine-tuning recipes are released under a permissive NVIDIA open license, with deployment supported across NeMo, NIM, and major inference runtimes.",
                "model_version_group_id": null,
                "context_length": 128000,
                "input_modalities": [
                    "image",
                    "text",
                    "video"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": "",
                "routing_error_message": null,
                "permaslug": "nvidia/nemotron-nano-12b-v2-vl",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    },
                    "chat_template_config": {}
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "28304d1d-c2b9-4291-ba4d-dc63e798227e",
                    "name": "Nvidia | nvidia/nemotron-nano-12b-v2-vl:free",
                    "context_length": 128000,
                    "model": {
                        "slug": "nvidia/nemotron-nano-12b-v2-vl",
                        "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-12B-v2-VL-BF16",
                        "updated_at": "2025-11-12T02:19:07.557675+00:00",
                        "created_at": "2025-10-28T18:19:25.723503+00:00",
                        "hf_updated_at": null,
                        "name": "NVIDIA: Nemotron Nano 12B 2 VL",
                        "short_name": "Nemotron Nano 12B 2 VL",
                        "author": "nvidia",
                        "description": "NVIDIA Nemotron Nano 2 VL is a 12-billion-parameter open multimodal reasoning model designed for video understanding and document intelligence. It introduces a hybrid Transformer-Mamba architecture, combining transformer-level accuracy with Mamba’s memory-efficient sequence modeling for significantly higher throughput and lower latency.\n\nThe model supports inputs of text and multi-image documents, producing natural-language outputs. It is trained on high-quality NVIDIA-curated synthetic datasets optimized for optical-character recognition, chart reasoning, and multimodal comprehension.\n\nNemotron Nano 2 VL achieves leading results on OCRBench v2 and scores ≈ 74 average across MMMU, MathVista, AI2D, OCRBench, OCR-Reasoning, ChartQA, DocVQA, and Video-MME—surpassing prior open VL baselines. With Efficient Video Sampling (EVS), it handles long-form videos while reducing inference cost.\n\nOpen-weights, training data, and fine-tuning recipes are released under a permissive NVIDIA open license, with deployment supported across NeMo, NIM, and major inference runtimes.",
                        "model_version_group_id": null,
                        "context_length": 128000,
                        "input_modalities": [
                            "image",
                            "text",
                            "video"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": "",
                        "routing_error_message": null,
                        "permaslug": "nvidia/nemotron-nano-12b-v2-vl",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            },
                            "chat_template_config": {}
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "nvidia/nemotron-nano-12b-v2-vl:free",
                    "model_variant_permaslug": "nvidia/nemotron-nano-12b-v2-vl:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Nvidia",
                    "provider_info": {
                        "name": "Nvidia",
                        "displayName": "NVIDIA",
                        "slug": "nvidia",
                        "baseUrl": "https://1afcd6e8-59bf-4102-95ed-7ec410f6959f.invocation.api.nvcf.nvidia.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                            "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.nvidia.com/en-us/&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "NVIDIA",
                    "provider_slug": "nvidia",
                    "provider_model_id": "nvidia/nvidia-nemotron-nano-12b-v2-vl",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 128000,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "temperature",
                        "max_tokens",
                        "seed",
                        "top_p",
                        "tool_choice",
                        "tools"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": true,
                        "retainsPrompts": true,
                        "canPublish": false,
                        "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                        "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_multipart": true,
                        "supports_input_audio": false,
                        "supports_base64_video_input": true,
                        "supports_video_urls": true,
                        "disable_free_endpoint_limits": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "qwen/qwen3-coder",
                "hf_slug": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-23T00:29:06+00:00",
                "hf_updated_at": null,
                "name": "Qwen: Qwen3 Coder 480B A35B (free)",
                "short_name": "Qwen3 Coder 480B A35B (free)",
                "author": "qwen",
                "description": "Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code generation model developed by the Qwen team. It is optimized for agentic coding tasks such as function calling, tool use, and long-context reasoning over repositories. The model features 480 billion total parameters, with 35 billion active per forward pass (8 out of 160 experts).\n\nPricing for the Alibaba endpoints varies by context length. Once a request is greater than 128k input tokens, the higher pricing is used.",
                "model_version_group_id": null,
                "context_length": 262000,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Qwen3",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "a9bbd882-011f-4606-8f60-85f3cb642586",
                    "name": "Venice | qwen/qwen3-coder-480b-a35b-07-25:free",
                    "context_length": 262000,
                    "model": {
                        "slug": "qwen/qwen3-coder",
                        "hf_slug": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-23T00:29:06+00:00",
                        "hf_updated_at": null,
                        "name": "Qwen: Qwen3 Coder 480B A35B",
                        "short_name": "Qwen3 Coder 480B A35B",
                        "author": "qwen",
                        "description": "Qwen3-Coder-480B-A35B-Instruct is a Mixture-of-Experts (MoE) code generation model developed by the Qwen team. It is optimized for agentic coding tasks such as function calling, tool use, and long-context reasoning over repositories. The model features 480 billion total parameters, with 35 billion active per forward pass (8 out of 160 experts).\n\nPricing for the Alibaba endpoints varies by context length. Once a request is greater than 128k input tokens, the higher pricing is used.",
                        "model_version_group_id": null,
                        "context_length": 1048576,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Qwen3",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "qwen/qwen3-coder:free",
                    "model_variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice (Beta)",
                        "slug": "venice/beta",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice (Beta)",
                    "provider_slug": "venice/beta",
                    "provider_model_id": "qwen3-coder-480b-a35b-instruct",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 262000,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "z-ai/glm-4.5-air",
                "hf_slug": "zai-org/GLM-4.5-Air",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-25T19:20:58.066206+00:00",
                "hf_updated_at": null,
                "name": "Z.AI: GLM 4.5 Air (free)",
                "short_name": "GLM 4.5 Air (free)",
                "author": "z-ai",
                "description": "GLM-4.5-Air is the lightweight variant of our latest flagship model family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts the Mixture-of-Experts (MoE) architecture but with a more compact parameter size. GLM-4.5-Air also supports hybrid inference modes, offering a \"thinking mode\" for advanced reasoning and tool use, and a \"non-thinking mode\" for real-time interaction. Users can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "z-ai/glm-4.5-air",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    }
                },
                "default_parameters": {
                    "temperature": 0.75,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "ff702d6d-97f5-4336-8356-f2e09f8a0640",
                    "name": "Z.AI | z-ai/glm-4.5-air:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "z-ai/glm-4.5-air",
                        "hf_slug": "zai-org/GLM-4.5-Air",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-25T19:20:58.066206+00:00",
                        "hf_updated_at": null,
                        "name": "Z.AI: GLM 4.5 Air",
                        "short_name": "GLM 4.5 Air",
                        "author": "z-ai",
                        "description": "GLM-4.5-Air is the lightweight variant of our latest flagship model family, also purpose-built for agent-centric applications. Like GLM-4.5, it adopts the Mixture-of-Experts (MoE) architecture but with a more compact parameter size. GLM-4.5-Air also supports hybrid inference modes, offering a \"thinking mode\" for advanced reasoning and tool use, and a \"non-thinking mode\" for real-time interaction. Users can control the reasoning behaviour with the `reasoning` `enabled` boolean. [Learn more in our docs](https://openrouter.ai/docs/use-cases/reasoning-tokens#enable-reasoning-with-default-config)",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "z-ai/glm-4.5-air",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            }
                        },
                        "default_parameters": {
                            "temperature": 0.75,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "z-ai/glm-4.5-air:free",
                    "model_variant_permaslug": "z-ai/glm-4.5-air:free",
                    "adapter_name": "ZAIAdapter",
                    "provider_name": "Z.AI",
                    "provider_info": {
                        "name": "Z.AI",
                        "displayName": "Z.AI",
                        "slug": "z-ai",
                        "baseUrl": "https://api.z.ai/api/paas/v4",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://chat.z.ai/legal-agreement/terms-of-service",
                            "privacyPolicyURL": "https://chat.z.ai/legal-agreement/privacy-policy"
                        },
                        "headquarters": "SG",
                        "datacenters": [
                            "SG"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "ZAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://z.ai/model-api&size=256",
                            "className": "invert-0 dark:invert"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Z.AI",
                    "provider_slug": "z-ai",
                    "provider_model_id": "glm-4.5-flash",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 96000,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://chat.z.ai/legal-agreement/terms-of-service",
                        "privacyPolicyURL": "https://chat.z.ai/legal-agreement/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "tngtech/tng-r1t-chimera",
                "hf_slug": null,
                "updated_at": "2025-11-26T19:25:45.302623+00:00",
                "created_at": "2025-11-26T19:09:21.439199+00:00",
                "hf_updated_at": null,
                "name": "TNG: R1T Chimera (free)",
                "short_name": "R1T Chimera (free)",
                "author": "tngtech",
                "description": "TNG-R1T-Chimera is an experimental LLM with a faible for creative storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera released in April 2025 and is available exclusively via Chutes and OpenRouter.\n\nCharacteristics and improvements include:\n\nWe think that it has a creative and pleasant personality.\nIt has a preliminary EQ-Bench3 value of about 1305.\nIt is quite a bit more intelligent than the original, albeit a slightly slower.\nIt is much more think-token consistent, i.e. reasoning and answer blocks are properly delineated.\nTool calling is much improved.\n\nTNG Tech, the model authors, ask that users follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. These guidelines are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).",
                "model_version_group_id": null,
                "context_length": 163840,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "tngtech/tng-r1t-chimera",
                "supports_reasoning": true,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "b31307aa-c121-403c-a159-2e8f534f9836",
                    "name": "Chutes | tngtech/tng-r1t-chimera:free",
                    "context_length": 163840,
                    "model": {
                        "slug": "tngtech/tng-r1t-chimera",
                        "hf_slug": null,
                        "updated_at": "2025-11-26T19:25:45.302623+00:00",
                        "created_at": "2025-11-26T19:09:21.439199+00:00",
                        "hf_updated_at": null,
                        "name": "TNG: R1T Chimera",
                        "short_name": "R1T Chimera",
                        "author": "tngtech",
                        "description": "TNG-R1T-Chimera is an experimental LLM with a faible for creative storytelling and character interaction. It is a derivate of the original TNG/DeepSeek-R1T-Chimera released in April 2025 and is available exclusively via Chutes and OpenRouter.\n\nCharacteristics and improvements include:\n\nWe think that it has a creative and pleasant personality.\nIt has a preliminary EQ-Bench3 value of about 1305.\nIt is quite a bit more intelligent than the original, albeit a slightly slower.\nIt is much more think-token consistent, i.e. reasoning and answer blocks are properly delineated.\nTool calling is much improved.\n\nTNG Tech, the model authors, ask that users follow the careful guidelines that Microsoft has created for their \"MAI-DS-R1\" DeepSeek-based model. These guidelines are available on Hugging Face (https://huggingface.co/microsoft/MAI-DS-R1).",
                        "model_version_group_id": null,
                        "context_length": 163840,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "tngtech/tng-r1t-chimera",
                        "supports_reasoning": true,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "tngtech/tng-r1t-chimera:free",
                    "model_variant_permaslug": "tngtech/tng-r1t-chimera:free",
                    "adapter_name": "ChutesAdapter",
                    "provider_name": "Chutes",
                    "provider_info": {
                        "name": "Chutes",
                        "displayName": "Chutes",
                        "slug": "chutes",
                        "baseUrl": "https://llm.chutes.ai/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": false,
                            "termsOfServiceURL": "https://chutes.ai/tos"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "ChutesAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://chutes.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "openbmb/MiniCPM4-8B",
                            "agentica-org/DeepSWE-Preview",
                            "moonshotai/Kimi-K2-Instruct-tools",
                            "internlm/Intern-S1",
                            "TheDrummer/Gemmasutra-Pro-27B-v1.1",
                            "all-hands/openhands-lm-32b-v0.1-ep3",
                            "TheDrummer/Tunguska-39B-v1",
                            "Meridian",
                            "Zenith",
                            "Proxima",
                            "agentica-org/DeepCoder-14B-Preview",
                            "TheDrummer/Cydonia-24B-v2.1",
                            "Tesslate/UIGEN-X-32B-0727",
                            "NousResearch/Hermes-4-14B",
                            "unsloth/gemma-3-4b-it",
                            "tencent/Hunyuan-A13B-Instruct",
                            "unsloth/Llama-3.2-3B-Instruct",
                            "unsloth/Llama-3.2-1B-Instruct",
                            "zai-org/GLM-4.5-turbo",
                            "zai-org/GLM-4.6-turbo",
                            "rednote-hilab/dots.ocr",
                            "deepseek-ai/DeepSeek-V3-0324-turbo",
                            "deepseek-ai/DeepSeek-V3.1-turbo",
                            "moonshotai/Kimi-K2-Thinking",
                            "zai-org/GLM-4.5",
                            "deepseek-ai/DeepSeek-V3.1"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Chutes",
                    "provider_slug": "chutes/fp8",
                    "provider_model_id": "tngtech/TNG-R1T-Chimera-TEE",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 65536,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "seed",
                        "top_k",
                        "repetition_penalty",
                        "tools",
                        "tool_choice",
                        "response_format",
                        "structured_outputs"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": false,
                        "termsOfServiceURL": "https://chutes.ai/tos"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "is_mandatory_reasoning": true,
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "deepseek/deepseek-r1-0528",
                "hf_slug": "deepseek-ai/DeepSeek-R1-0528",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-05-28T17:59:30.833128+00:00",
                "hf_updated_at": null,
                "name": "DeepSeek: R1 0528 (free)",
                "short_name": "R1 0528 (free)",
                "author": "deepseek",
                "description": "May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1) Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model.",
                "model_version_group_id": null,
                "context_length": 163840,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "DeepSeek",
                "instruct_type": "deepseek-r1",
                "default_system": null,
                "default_stops": [
                    "<｜User｜>",
                    "<｜end▁of▁sentence｜>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "deepseek/deepseek-r1-0528",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>"
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>"
                    }
                },
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "1df69e91-1f72-4965-9fb3-be86cc8edc77",
                    "name": "ModelRun | deepseek/deepseek-r1-0528:free",
                    "context_length": 163840,
                    "model": {
                        "slug": "deepseek/deepseek-r1-0528",
                        "hf_slug": "deepseek-ai/DeepSeek-R1-0528",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-05-28T17:59:30.833128+00:00",
                        "hf_updated_at": null,
                        "name": "DeepSeek: R1 0528",
                        "short_name": "R1 0528",
                        "author": "deepseek",
                        "description": "May 28th update to the [original DeepSeek R1](/deepseek/deepseek-r1) Performance on par with [OpenAI o1](/openai/o1), but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.\n\nFully open-source model.",
                        "model_version_group_id": null,
                        "context_length": 163840,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "DeepSeek",
                        "instruct_type": "deepseek-r1",
                        "default_system": null,
                        "default_stops": [
                            "<｜User｜>",
                            "<｜end▁of▁sentence｜>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "deepseek/deepseek-r1-0528",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>"
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>"
                            }
                        },
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "deepseek/deepseek-r1-0528:free",
                    "model_variant_permaslug": "deepseek/deepseek-r1-0528:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "ModelRun",
                    "provider_info": {
                        "name": "ModelRun",
                        "displayName": "ModelRun",
                        "slug": "modelrun",
                        "baseUrl": "https://api2.runmodelrun.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                            "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://api.runmodelrun.com&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "ModelRun",
                    "provider_slug": "modelrun/fp4",
                    "provider_model_id": "deepseek/deepseek-r1-0528",
                    "quantization": "fp4",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "presence_penalty",
                        "repetition_penalty",
                        "frequency_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                        "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "is_mandatory_reasoning": true,
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemma-3-27b-it",
                "hf_slug": "",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-03-12T05:12:39.645813+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemma 3 27B (free)",
                "short_name": "Gemma 3 27B (free)",
                "author": "google",
                "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
                "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                "context_length": 131072,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Gemini",
                "instruct_type": "gemma",
                "default_system": null,
                "default_stops": [
                    "<start_of_turn>",
                    "<end_of_turn>",
                    "<eos>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemma-3-27b-it",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "f4276f71-4f8b-48e5-a823-42260e7c0965",
                    "name": "ModelRun | google/gemma-3-27b-it:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "google/gemma-3-27b-it",
                        "hf_slug": "",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-03-12T05:12:39.645813+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemma 3 27B",
                        "short_name": "Gemma 3 27B",
                        "author": "google",
                        "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 27B is Google's latest open source model, successor to [Gemma 2](google/gemma-2-27b-it)",
                        "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                        "context_length": 131072,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Gemini",
                        "instruct_type": "gemma",
                        "default_system": null,
                        "default_stops": [
                            "<start_of_turn>",
                            "<end_of_turn>",
                            "<eos>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemma-3-27b-it",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemma-3-27b-it:free",
                    "model_variant_permaslug": "google/gemma-3-27b-it:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "ModelRun",
                    "provider_info": {
                        "name": "ModelRun",
                        "displayName": "ModelRun",
                        "slug": "modelrun",
                        "baseUrl": "https://api.runmodelrun.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                            "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://api.runmodelrun.com&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "ModelRun",
                    "provider_slug": "modelrun",
                    "provider_model_id": "google/gemma-3-27b-it",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "presence_penalty",
                        "repetition_penalty",
                        "frequency_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                        "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_multipart": false,
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "meta-llama/llama-3.3-70b-instruct",
                "hf_slug": "meta-llama/Llama-3.3-70B-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-12-06T17:28:57.828422+00:00",
                "hf_updated_at": null,
                "name": "Meta: Llama 3.3 70B Instruct (free)",
                "short_name": "Llama 3.3 70B Instruct (free)",
                "author": "meta-llama",
                "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
                "model_version_group_id": "397604e2-45fa-454e-a85d-9921f5138747",
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Llama3",
                "instruct_type": "llama3",
                "default_system": null,
                "default_stops": [
                    "<|eot_id|>",
                    "<|end_of_text|>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "meta-llama/llama-3.3-70b-instruct",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "752a61e0-321b-4839-8c5b-8fb1c4795f94",
                    "name": "ModelRun | meta-llama/llama-3.3-70b-instruct:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "meta-llama/llama-3.3-70b-instruct",
                        "hf_slug": "meta-llama/Llama-3.3-70B-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-12-06T17:28:57.828422+00:00",
                        "hf_updated_at": null,
                        "name": "Meta: Llama 3.3 70B Instruct",
                        "short_name": "Llama 3.3 70B Instruct",
                        "author": "meta-llama",
                        "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.\n\n[Model Card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)",
                        "model_version_group_id": "397604e2-45fa-454e-a85d-9921f5138747",
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Llama3",
                        "instruct_type": "llama3",
                        "default_system": null,
                        "default_stops": [
                            "<|eot_id|>",
                            "<|end_of_text|>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "meta-llama/llama-3.3-70b-instruct",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "meta-llama/llama-3.3-70b-instruct:free",
                    "model_variant_permaslug": "meta-llama/llama-3.3-70b-instruct:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "ModelRun",
                    "provider_info": {
                        "name": "ModelRun",
                        "displayName": "ModelRun",
                        "slug": "modelrun",
                        "baseUrl": "https://api.runmodelrun.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                            "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://api.runmodelrun.com&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "ModelRun",
                    "provider_slug": "modelrun",
                    "provider_model_id": "meta-llama/Llama-3.3-70B-Instruct",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "presence_penalty",
                        "repetition_penalty",
                        "frequency_penalty",
                        "tool_choice",
                        "tools"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                        "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemini-2.0-flash-exp",
                "hf_slug": "",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-12-11T17:18:43.999311+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemini 2.0 Flash Experimental (free)",
                "short_name": "Gemini 2.0 Flash Experimental (free)",
                "author": "google",
                "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
                "model_version_group_id": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
                "context_length": 1048576,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Gemini",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemini-2.0-flash-exp",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "65df650a-3eae-46b0-b5b0-87546ca90cc3",
                    "name": "Google | google/gemini-2.0-flash-exp:free",
                    "context_length": 1048576,
                    "model": {
                        "slug": "google/gemini-2.0-flash-exp",
                        "hf_slug": "",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-12-11T17:18:43.999311+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemini 2.0 Flash Experimental",
                        "short_name": "Gemini 2.0 Flash Experimental",
                        "author": "google",
                        "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
                        "model_version_group_id": "e993dfbf-2cbd-4680-b866-c05bbdcc8f4d",
                        "context_length": 1048576,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Gemini",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemini-2.0-flash-exp",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemini-2.0-flash-exp:free",
                    "model_variant_permaslug": "google/gemini-2.0-flash-exp:free",
                    "adapter_name": "GoogleVertexGeminiAdapter",
                    "provider_name": "Google",
                    "provider_info": {
                        "name": "Google",
                        "displayName": "Google Vertex",
                        "slug": "google-vertex",
                        "baseUrl": "not_used",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://cloud.google.com/terms/",
                            "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice",
                            "requiresUserIDs": true
                        },
                        "headquarters": "US",
                        "regionOverrides": {
                            "europe": {
                                "baseUrl": "not-used"
                            }
                        },
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "GoogleVertexGeminiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": "https://status.cloud.google.com/products/sdXM79fz1FS6ekNpu37K/history",
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/GoogleVertex.svg"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-exp-03-25",
                            "gemini-2.0-flash-exp",
                            "gemini-1.5-flash-002",
                            "gemini-2.0-flash-lite-001",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash-lite",
                            "gemini-2.0-flash-001",
                            "llama-4-scout-17b-16e-instruct-maas",
                            "qwen3-235b-a22b-instruct-2507-maas",
                            "gemini-2.5-flash",
                            "gemini-2.5-flash-image-preview",
                            "llama-4-maverick-17b-128e-instruct-maas",
                            "llama-3.3-70b-instruct-maas",
                            "claude-3-5-haiku@20241022",
                            "qwen3-coder-480b-a35b-instruct-maas",
                            "gemini-1.5-pro-002",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.5-pro-preview-05-06",
                            "gemini-2.5-pro",
                            "deepseek-r1-0528-maas",
                            "claude-3-7-sonnet@20250219",
                            "claude-3-5-sonnet-v2@20241022",
                            "claude-sonnet-4@20250514",
                            "claude-opus-4-1@20250805",
                            "claude-opus-4@20250514",
                            "claude-3-haiku@20240307",
                            "claude-3-5-sonnet@20240620",
                            "claude-3-opus@20240229",
                            "gemini-2.5-flash-lite-preview-09-2025",
                            "gemini-2.5-flash-preview-09-2025",
                            "gemini-2.5-flash-image",
                            "claude-sonnet-4-5@20250929",
                            "claude-haiku-4-5@20251001",
                            "minimax/minimax-m2-maas",
                            "gemini-3-pro-preview",
                            "gemini-3-pro-image-preview",
                            "claude-opus-4-5@20251101"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Google Vertex",
                    "provider_slug": "google-vertex",
                    "provider_model_id": "gemini-2.0-flash-exp",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 8192,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "seed",
                        "response_format",
                        "stop",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 55,
                        "canPublish": false,
                        "termsOfServiceURL": "https://cloud.google.com/terms/",
                        "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice",
                        "requiresUserIDs": true
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition",
                "hf_slug": "cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-09T21:02:46.328189+00:00",
                "hf_updated_at": null,
                "name": "Venice: Uncensored (free)",
                "short_name": "Uncensored (free)",
                "author": "venice",
                "description": "Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration with Venice.ai. This model is designed as an “uncensored” instruct-tuned LLM, preserving user control over alignment, system prompts, and behavior. Intended for advanced and unrestricted use cases, Venice Uncensored emphasizes steerability and transparent behavior, removing default safety and alignment layers typically found in mainstream assistant models.",
                "model_version_group_id": null,
                "context_length": 32768,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "venice/uncensored",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "2d9e49f9-2147-4259-9871-4f6b6f181976",
                    "name": "Venice | venice/uncensored:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition",
                        "hf_slug": "cognitivecomputations/Dolphin-Mistral-24B-Venice-Edition",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-09T21:02:46.328189+00:00",
                        "hf_updated_at": null,
                        "name": "Venice: Uncensored",
                        "short_name": "Uncensored",
                        "author": "venice",
                        "description": "Venice Uncensored Dolphin Mistral 24B Venice Edition is a fine-tuned variant of Mistral-Small-24B-Instruct-2501, developed by dphn.ai in collaboration with Venice.ai. This model is designed as an “uncensored” instruct-tuned LLM, preserving user control over alignment, system prompts, and behavior. Intended for advanced and unrestricted use cases, Venice Uncensored emphasizes steerability and transparent behavior, removing default safety and alignment layers typically found in mainstream assistant models.",
                        "model_version_group_id": null,
                        "context_length": 32768,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "venice/uncensored",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
                    "model_variant_permaslug": "venice/uncensored:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice",
                        "slug": "venice",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice",
                    "provider_slug": "venice/fp16",
                    "provider_model_id": "venice-uncensored",
                    "quantization": "fp16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "structured_outputs",
                        "response_format",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": true,
                            "structured_outputs": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "openai/gpt-oss-120b",
                "hf_slug": "openai/gpt-oss-120b",
                "updated_at": "2025-12-16T16:05:01.81081+00:00",
                "created_at": "2025-08-05T17:17:11+00:00",
                "hf_updated_at": null,
                "name": "OpenAI: gpt-oss-120b (free)",
                "short_name": "gpt-oss-120b (free)",
                "author": "openai",
                "description": "gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE) language model from OpenAI designed for high-reasoning, agentic, and general-purpose production use cases. It activates 5.1B parameters per forward pass and is optimized to run on a single H100 GPU with native MXFP4 quantization. The model supports configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation.",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "GPT",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "openai/gpt-oss-120b",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": "",
                    "is_mandatory_reasoning": true,
                    "supports_reasoning_effort": true,
                    "supported_reasoning_efforts": [
                        "low",
                        "medium",
                        "high"
                    ],
                    "default_reasoning_effort": "medium"
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": "",
                        "is_mandatory_reasoning": true,
                        "supports_reasoning_effort": true,
                        "supported_reasoning_efforts": [
                            "low",
                            "medium",
                            "high"
                        ],
                        "default_reasoning_effort": "medium"
                    },
                    "chat_template_config": {}
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "447dca36-a2eb-4626-8675-bddd7c74a615",
                    "name": "OpenInference | openai/gpt-oss-120b:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "openai/gpt-oss-120b",
                        "hf_slug": "openai/gpt-oss-120b",
                        "updated_at": "2025-12-16T16:05:01.81081+00:00",
                        "created_at": "2025-08-05T17:17:11+00:00",
                        "hf_updated_at": null,
                        "name": "OpenAI: gpt-oss-120b",
                        "short_name": "gpt-oss-120b",
                        "author": "openai",
                        "description": "gpt-oss-120b is an open-weight, 117B-parameter Mixture-of-Experts (MoE) language model from OpenAI designed for high-reasoning, agentic, and general-purpose production use cases. It activates 5.1B parameters per forward pass and is optimized to run on a single H100 GPU with native MXFP4 quantization. The model supports configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation.",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "GPT",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "openai/gpt-oss-120b",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": "",
                            "is_mandatory_reasoning": true,
                            "supports_reasoning_effort": true,
                            "supported_reasoning_efforts": [
                                "low",
                                "medium",
                                "high"
                            ],
                            "default_reasoning_effort": "medium"
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": "",
                                "is_mandatory_reasoning": true,
                                "supports_reasoning_effort": true,
                                "supported_reasoning_efforts": [
                                    "low",
                                    "medium",
                                    "high"
                                ],
                                "default_reasoning_effort": "medium"
                            },
                            "chat_template_config": {}
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "openai/gpt-oss-120b:free",
                    "model_variant_permaslug": "openai/gpt-oss-120b:free",
                    "adapter_name": "OpenInferenceAdapter",
                    "provider_name": "OpenInference",
                    "provider_info": {
                        "name": "OpenInference",
                        "displayName": "OpenInference",
                        "slug": "open-inference",
                        "baseUrl": "https://openinference.ngrok.io/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": true,
                            "termsOfServiceURL": "https://www.openinference.xyz/terms",
                            "privacyPolicyURL": "https://www.openinference.xyz/terms"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": true,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenInferenceAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://openinference.xyz/&size=256",
                            "className": "invert dark:invert-0"
                        },
                        "ignoredProviderModels": [
                            "meta-llama/Llama-3.1-8B-Instruct",
                            "meta-llama/Llama-Guard-3-8B",
                            "Qwen/Qwen3-4B-Thinking-2507",
                            "openai/gpt-oss-120b-test",
                            "openai/gpt-oss-20b-test"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "OpenInference",
                    "provider_slug": "open-inference/int8",
                    "provider_model_id": "openai/gpt-oss-120b",
                    "quantization": "int8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "temperature",
                        "max_tokens",
                        "stop",
                        "seed",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": true,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": true,
                        "termsOfServiceURL": "https://www.openinference.xyz/terms",
                        "privacyPolicyURL": "https://www.openinference.xyz/terms"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "is_mandatory_reasoning": true,
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "nousresearch/hermes-3-llama-3.1-405b",
                "hf_slug": "NousResearch/Hermes-3-Llama-3.1-405B",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-08-16T00:00:00+00:00",
                "hf_updated_at": null,
                "name": "Nous: Hermes 3 405B Instruct (free)",
                "short_name": "Hermes 3 405B Instruct (free)",
                "author": "nousresearch",
                "description": "Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\nHermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general capabilities, with varying strengths and weaknesses attributable between the two.",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Llama3",
                "instruct_type": "chatml",
                "default_system": null,
                "default_stops": [
                    "<|im_start|>",
                    "<|im_end|>",
                    "<|endoftext|>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "nousresearch/hermes-3-llama-3.1-405b",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "196b4f57-a8ce-493a-8248-a24505c2862d",
                    "name": "Venice | nousresearch/hermes-3-llama-3.1-405b:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "nousresearch/hermes-3-llama-3.1-405b",
                        "hf_slug": "NousResearch/Hermes-3-Llama-3.1-405B",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-08-16T00:00:00+00:00",
                        "hf_updated_at": null,
                        "name": "Nous: Hermes 3 405B Instruct",
                        "short_name": "Hermes 3 405B Instruct",
                        "author": "nousresearch",
                        "description": "Hermes 3 is a generalist language model with many improvements over Hermes 2, including advanced agentic capabilities, much better roleplaying, reasoning, multi-turn conversation, long context coherence, and improvements across the board.\n\nHermes 3 405B is a frontier-level, full-parameter finetune of the Llama-3.1 405B foundation model, focused on aligning LLMs to the user, with powerful steering capabilities and control given to the end user.\n\nThe Hermes 3 series builds and expands on the Hermes 2 set of capabilities, including more powerful and reliable function calling and structured output capabilities, generalist assistant capabilities, and improved code generation skills.\n\nHermes 3 is competitive, if not superior, to Llama-3.1 Instruct models at general capabilities, with varying strengths and weaknesses attributable between the two.",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Llama3",
                        "instruct_type": "chatml",
                        "default_system": null,
                        "default_stops": [
                            "<|im_start|>",
                            "<|im_end|>",
                            "<|endoftext|>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "nousresearch/hermes-3-llama-3.1-405b",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "nousresearch/hermes-3-llama-3.1-405b:free",
                    "model_variant_permaslug": "nousresearch/hermes-3-llama-3.1-405b:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice (Beta)",
                        "slug": "venice/beta",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice (Beta)",
                    "provider_slug": "venice/beta",
                    "provider_model_id": "hermes-3-llama-3.1-405b",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "meta-llama/llama-3.1-405b-instruct",
                "hf_slug": "meta-llama/Meta-Llama-3.1-405B-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-07-23T00:00:00+00:00",
                "hf_updated_at": null,
                "name": "Meta: Llama 3.1 405B Instruct (free)",
                "short_name": "Llama 3.1 405B Instruct (free)",
                "author": "meta-llama",
                "description": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
                "model_version_group_id": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Llama3",
                "instruct_type": "llama3",
                "default_system": null,
                "default_stops": [
                    "<|eot_id|>",
                    "<|end_of_text|>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "meta-llama/llama-3.1-405b-instruct",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "76489a89-07af-484a-81ba-c6f8dfdeb5fa",
                    "name": "ModelRun | meta-llama/llama-3.1-405b-instruct:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "meta-llama/llama-3.1-405b-instruct",
                        "hf_slug": "meta-llama/Meta-Llama-3.1-405B-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-07-23T00:00:00+00:00",
                        "hf_updated_at": null,
                        "name": "Meta: Llama 3.1 405B Instruct",
                        "short_name": "Llama 3.1 405B Instruct",
                        "author": "meta-llama",
                        "description": "The highly anticipated 400B class of Llama3 is here! Clocking in at 128k context with impressive eval scores, the Meta AI team continues to push the frontier of open-source LLMs.\n\nMeta's latest class of model (Llama 3.1) launched with a variety of sizes & flavors. This 405B instruct-tuned version is optimized for high quality dialogue usecases.\n\nIt has demonstrated strong performance compared to leading closed-source models including GPT-4o and Claude 3.5 Sonnet in evaluations.\n\nTo read more about the model release, [click here](https://ai.meta.com/blog/meta-llama-3-1/). Usage of this model is subject to [Meta's Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).",
                        "model_version_group_id": "1fd9d06b-aa20-4c7d-a0b1-d3d9b5aae712",
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Llama3",
                        "instruct_type": "llama3",
                        "default_system": null,
                        "default_stops": [
                            "<|eot_id|>",
                            "<|end_of_text|>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "meta-llama/llama-3.1-405b-instruct",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "meta-llama/llama-3.1-405b-instruct:free",
                    "model_variant_permaslug": "meta-llama/llama-3.1-405b-instruct:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "ModelRun",
                    "provider_info": {
                        "name": "ModelRun",
                        "displayName": "ModelRun",
                        "slug": "modelrun",
                        "baseUrl": "https://api2.runmodelrun.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                            "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://api.runmodelrun.com&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "ModelRun",
                    "provider_slug": "modelrun/fp8",
                    "provider_model_id": "meta-llama/Llama-3.1-405B-Instruct-FP8",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "presence_penalty",
                        "repetition_penalty",
                        "frequency_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                        "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "mistralai/mistral-7b-instruct",
                "hf_slug": "mistralai/Mistral-7B-Instruct-v0.3",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-05-27T00:00:00+00:00",
                "hf_updated_at": null,
                "name": "Mistral: Mistral 7B Instruct (free)",
                "short_name": "Mistral 7B Instruct (free)",
                "author": "mistralai",
                "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
                "model_version_group_id": "1d07cc56-c54d-4587-b785-5093496397a4",
                "context_length": 32768,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Mistral",
                "instruct_type": "mistral",
                "default_system": null,
                "default_stops": [
                    "[INST]",
                    "</s>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "mistralai/mistral-7b-instruct",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {
                    "temperature": 0.3
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "d09ade5a-2aaf-4a93-9881-3db42f1ba63a",
                    "name": "DeepInfra | mistralai/mistral-7b-instruct:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "mistralai/mistral-7b-instruct",
                        "hf_slug": "mistralai/Mistral-7B-Instruct-v0.3",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-05-27T00:00:00+00:00",
                        "hf_updated_at": null,
                        "name": "Mistral: Mistral 7B Instruct",
                        "short_name": "Mistral 7B Instruct",
                        "author": "mistralai",
                        "description": "A high-performing, industry-standard 7.3B parameter model, with optimizations for speed and context length.\n\n*Mistral 7B Instruct has multiple version variants, and this is intended to be the latest version.*",
                        "model_version_group_id": "1d07cc56-c54d-4587-b785-5093496397a4",
                        "context_length": 32768,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Mistral",
                        "instruct_type": "mistral",
                        "default_system": null,
                        "default_stops": [
                            "[INST]",
                            "</s>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "mistralai/mistral-7b-instruct",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {
                            "temperature": 0.3
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "mistralai/mistral-7b-instruct:free",
                    "model_variant_permaslug": "mistralai/mistral-7b-instruct:free",
                    "adapter_name": "DeepInfraAdapter",
                    "provider_name": "DeepInfra",
                    "provider_info": {
                        "name": "DeepInfra",
                        "displayName": "DeepInfra",
                        "slug": "deepinfra",
                        "baseUrl": "https://api.deepinfra.com/v1/openai",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://deepinfra.com/terms",
                            "privacyPolicyURL": "https://deepinfra.com/privacy"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "DeepInfraAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": "https://status.deepinfra.com/",
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/DeepInfra.webp"
                        },
                        "ignoredProviderModels": [
                            "anthropic/claude-4-opus",
                            "anthropic/claude-4-sonnet",
                            "deepseek-ai/DeepSeek-R1-0528-Turbo",
                            "meta-llama/Llama-2-70b-chat-hf",
                            "mistralai/Mixtral-8x22B-Instruct-v0.1",
                            "google/gemma-1.1-7b-it",
                            "microsoft/Phi-3-medium-4k-instruct",
                            "google/gemma-2-27b-it",
                            "microsoft/WizardLM-2-7B",
                            "mattshumer/Reflection-Llama-3.1-70B",
                            "Sao10K/L3-8B-Lunaris-v1",
                            "openbmb/MiniCPM-Llama3-V-2_5",
                            "Qwen/QVQ-72B-Preview",
                            "deepinfra/airoboros-70b",
                            "Qwen/QwQ-32B-Preview",
                            "Phind/Phind-CodeLlama-34B-v2",
                            "lizpreciatior/lzlv_70b_fp16_hf",
                            "mistralai/Mistral-7B-Instruct-v0.2",
                            "cognitivecomputations/dolphin-2.6-mixtral-8x7b",
                            "cognitivecomputations/dolphin-2.9.1-llama-3-70b",
                            "Qwen/Qwen2-72B-Instruct",
                            "Qwen/Qwen2-7B-Instruct",
                            "google/gemma-2-9b-it",
                            "Sao10K/L3-70B-Euryale-v2.1",
                            "google/codegemma-7b-it",
                            "mistralai/Mistral-7B-Instruct-v0.1",
                            "KoboldAI/LLaMA2-13B-Tiefighter",
                            "meta-llama/Llama-2-13b-chat-hf",
                            "openchat/openchat_3.5",
                            "openchat/openchat-3.6-8b",
                            "bigcode/starcoder2-15b-instruct-v0.1",
                            "Gryphe/MythoMax-L2-13b-turbo",
                            "Austism/chronos-hermes-13b-v2",
                            "Qwen/Qwen2.5-Coder-7B",
                            "moonshotai/Kimi-K2-Instruct",
                            "google/gemini-1.5-flash",
                            "google/gemini-2.5-flash",
                            "google/gemini-2.0-flash-001",
                            "anthropic/claude-3-7-sonnet-latest",
                            "google/gemini-1.5-flash-8b",
                            "google/gemini-2.5-pro",
                            "NovaSky-AI/Sky-T1-32B-Preview",
                            "allenai/olmOCR-7B-0725-FP8",
                            "allenai/olmOCR-7B-0825",
                            "deepseek-ai/DeepSeek-V3-0324-Turbo",
                            "PaddlePaddle/PaddleOCR-VL-0.9B",
                            "allenai/olmOCR-7B-1025",
                            "allenai/olmOCR-2-7B-1025",
                            "allenai/olmOCR-2",
                            "deepseek-ai/DeepSeek-OCR",
                            "meta-llama/Llama-3.2-1B-Instruct",
                            "sentence-transformers/clip-ViT-B-32-multilingual-v1",
                            "shibing624/text2vec-base-chinese",
                            "sentence-transformers/clip-ViT-B-32",
                            "BAAI/bge-en-icl",
                            "Qwen/Qwen3-Embedding-8B-batch",
                            "Qwen/Qwen3-Embedding-4B-batch",
                            "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
                            "meta-llama/Meta-Llama-3.1-405B-Instruct",
                            "BAAI/bge-m3-multi",
                            "google/embeddinggemma-300m",
                            "Qwen/Qwen3-Embedding-0.6B-batch",
                            "meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "DeepInfra",
                    "provider_slug": "deepinfra/bf16",
                    "provider_model_id": "mistralai/Mistral-7B-Instruct-v0.3",
                    "quantization": "bf16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 16384,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "repetition_penalty",
                        "top_k",
                        "seed",
                        "min_p",
                        "response_format",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://deepinfra.com/terms",
                        "privacyPolicyURL": "https://deepinfra.com/privacy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 1
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": false,
                            "type_function": false
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "openai/gpt-oss-20b",
                "hf_slug": "openai/gpt-oss-20b",
                "updated_at": "2025-12-16T00:03:07.127808+00:00",
                "created_at": "2025-08-05T17:17:09+00:00",
                "hf_updated_at": null,
                "name": "OpenAI: gpt-oss-20b (free)",
                "short_name": "gpt-oss-20b (free)",
                "author": "openai",
                "description": "gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture with 3.6B active parameters per forward pass, optimized for lower-latency inference and deployability on consumer or single-GPU hardware. The model is trained in OpenAI’s Harmony response format and supports reasoning level configuration, fine-tuning, and agentic capabilities including function calling, tool use, and structured outputs.",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "GPT",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "openai/gpt-oss-20b",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": null,
                    "end_token": null,
                    "system_prompt": null,
                    "is_mandatory_reasoning": null,
                    "supports_reasoning_effort": true,
                    "supports_reasoning_max_tokens": null,
                    "supported_reasoning_efforts": [
                        "low",
                        "medium",
                        "high"
                    ],
                    "default_reasoning_effort": "medium"
                },
                "features": {
                    "reasoning_config": {
                        "start_token": null,
                        "end_token": null,
                        "system_prompt": null,
                        "is_mandatory_reasoning": null,
                        "supports_reasoning_effort": true,
                        "supports_reasoning_max_tokens": null,
                        "supported_reasoning_efforts": [
                            "low",
                            "medium",
                            "high"
                        ],
                        "default_reasoning_effort": "medium"
                    },
                    "chat_template_config": {
                        "should_hoist_and_merge_system_messages": null
                    }
                },
                "default_parameters": {
                    "temperature": null,
                    "top_p": null,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "3be5b183-38c9-4c00-a32f-1bf267cbe924",
                    "name": "OpenInference | openai/gpt-oss-20b:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "openai/gpt-oss-20b",
                        "hf_slug": "openai/gpt-oss-20b",
                        "updated_at": "2025-12-16T00:03:07.127808+00:00",
                        "created_at": "2025-08-05T17:17:09+00:00",
                        "hf_updated_at": null,
                        "name": "OpenAI: gpt-oss-20b",
                        "short_name": "gpt-oss-20b",
                        "author": "openai",
                        "description": "gpt-oss-20b is an open-weight 21B parameter model released by OpenAI under the Apache 2.0 license. It uses a Mixture-of-Experts (MoE) architecture with 3.6B active parameters per forward pass, optimized for lower-latency inference and deployability on consumer or single-GPU hardware. The model is trained in OpenAI’s Harmony response format and supports reasoning level configuration, fine-tuning, and agentic capabilities including function calling, tool use, and structured outputs.",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "GPT",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "openai/gpt-oss-20b",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": null,
                            "end_token": null,
                            "system_prompt": null,
                            "is_mandatory_reasoning": null,
                            "supports_reasoning_effort": true,
                            "supports_reasoning_max_tokens": null,
                            "supported_reasoning_efforts": [
                                "low",
                                "medium",
                                "high"
                            ],
                            "default_reasoning_effort": "medium"
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": null,
                                "end_token": null,
                                "system_prompt": null,
                                "is_mandatory_reasoning": null,
                                "supports_reasoning_effort": true,
                                "supports_reasoning_max_tokens": null,
                                "supported_reasoning_efforts": [
                                    "low",
                                    "medium",
                                    "high"
                                ],
                                "default_reasoning_effort": "medium"
                            },
                            "chat_template_config": {
                                "should_hoist_and_merge_system_messages": null
                            }
                        },
                        "default_parameters": {
                            "temperature": null,
                            "top_p": null,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "openai/gpt-oss-20b:free",
                    "model_variant_permaslug": "openai/gpt-oss-20b:free",
                    "adapter_name": "OpenInferenceAdapter",
                    "provider_name": "OpenInference",
                    "provider_info": {
                        "name": "OpenInference",
                        "displayName": "OpenInference",
                        "slug": "open-inference",
                        "baseUrl": "https://openinference.ngrok.io/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": true,
                            "termsOfServiceURL": "https://www.openinference.xyz/terms",
                            "privacyPolicyURL": "https://www.openinference.xyz/terms"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": true,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenInferenceAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://openinference.xyz/&size=256",
                            "className": "invert dark:invert-0"
                        },
                        "ignoredProviderModels": [
                            "meta-llama/Llama-3.1-8B-Instruct",
                            "meta-llama/Llama-Guard-3-8B",
                            "Qwen/Qwen3-4B-Thinking-2507",
                            "openai/gpt-oss-120b-test",
                            "openai/gpt-oss-20b-test"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "OpenInference",
                    "provider_slug": "open-inference/int8",
                    "provider_model_id": "openai/gpt-oss-20b",
                    "quantization": "int8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "temperature",
                        "max_tokens",
                        "stop",
                        "seed",
                        "tool_choice",
                        "tools"
                    ],
                    "is_byok": false,
                    "moderation_required": true,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": true,
                        "termsOfServiceURL": "https://www.openinference.xyz/terms",
                        "privacyPolicyURL": "https://www.openinference.xyz/terms"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "is_mandatory_reasoning": true,
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "mistralai/mistral-small-3.1-24b-instruct",
                "hf_slug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-03-17T19:15:37.00423+00:00",
                "hf_updated_at": null,
                "name": "Mistral: Mistral Small 3.1 24B (free)",
                "short_name": "Mistral Small 3.1 24B (free)",
                "author": "mistralai",
                "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)",
                "model_version_group_id": null,
                "context_length": 128000,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Mistral",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {
                    "temperature": 0.3
                },
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "ecbdc9f1-ecca-4f91-83cf-b3495a60e874",
                    "name": "Venice | mistralai/mistral-small-3.1-24b-instruct-2503:free",
                    "context_length": 128000,
                    "model": {
                        "slug": "mistralai/mistral-small-3.1-24b-instruct",
                        "hf_slug": "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-03-17T19:15:37.00423+00:00",
                        "hf_updated_at": null,
                        "name": "Mistral: Mistral Small 3.1 24B",
                        "short_name": "Mistral Small 3.1 24B",
                        "author": "mistralai",
                        "description": "Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501), featuring 24 billion parameters with advanced multimodal capabilities. It provides state-of-the-art performance in text-based reasoning and vision tasks, including image analysis, programming, mathematical reasoning, and multilingual support across dozens of languages. Equipped with an extensive 128k token context window and optimized for efficient local inference, it supports use cases such as conversational agents, function calling, long-document comprehension, and privacy-sensitive deployments. The updated version is [Mistral Small 3.2](mistralai/mistral-small-3.2-24b-instruct)",
                        "model_version_group_id": null,
                        "context_length": 128000,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Mistral",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {
                            "temperature": 0.3
                        },
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "mistralai/mistral-small-3.1-24b-instruct:free",
                    "model_variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice",
                        "slug": "venice",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice",
                    "provider_slug": "venice/fp8",
                    "provider_model_id": "mistral-31-24b",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "structured_outputs",
                        "response_format",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": 1,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": true,
                            "structured_outputs": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "nvidia/nemotron-nano-9b-v2",
                "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-09-05T21:13:27.486887+00:00",
                "hf_updated_at": null,
                "name": "NVIDIA: Nemotron Nano 9B V2 (free)",
                "short_name": "Nemotron Nano 9B V2 (free)",
                "author": "nvidia",
                "description": "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. \n\nThe model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so.",
                "model_version_group_id": null,
                "context_length": 128000,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "nvidia/nemotron-nano-9b-v2",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    }
                },
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "71549a70-5ef5-406b-ae54-fab8adfb6dae",
                    "name": "Nvidia | nvidia/nemotron-nano-9b-v2:free",
                    "context_length": 128000,
                    "model": {
                        "slug": "nvidia/nemotron-nano-9b-v2",
                        "hf_slug": "nvidia/NVIDIA-Nemotron-Nano-9B-v2",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-09-05T21:13:27.486887+00:00",
                        "hf_updated_at": null,
                        "name": "NVIDIA: Nemotron Nano 9B V2",
                        "short_name": "Nemotron Nano 9B V2",
                        "author": "nvidia",
                        "description": "NVIDIA-Nemotron-Nano-9B-v2 is a large language model (LLM) trained from scratch by NVIDIA, and designed as a unified model for both reasoning and non-reasoning tasks. It responds to user queries and tasks by first generating a reasoning trace and then concluding with a final response. \n\nThe model's reasoning capabilities can be controlled via a system prompt. If the user prefers the model to provide its final answer without intermediate reasoning traces, it can be configured to do so.",
                        "model_version_group_id": null,
                        "context_length": 32000,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "nvidia/nemotron-nano-9b-v2",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            }
                        },
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "nvidia/nemotron-nano-9b-v2:free",
                    "model_variant_permaslug": "nvidia/nemotron-nano-9b-v2:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Nvidia",
                    "provider_info": {
                        "name": "Nvidia",
                        "displayName": "NVIDIA",
                        "slug": "nvidia",
                        "baseUrl": "https://74819e7c-e3e6-4497-8fdb-5f5fdc17dc85.invocation.api.nvcf.nvidia.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                            "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.nvidia.com/en-us/&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "NVIDIA",
                    "provider_slug": "nvidia/bf16",
                    "provider_model_id": "nvidia/nvidia-nemotron-nano-9b-v2",
                    "quantization": "bf16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "structured_outputs",
                        "response_format",
                        "temperature",
                        "max_tokens",
                        "seed",
                        "top_p",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://assets.ngc.nvidia.com/products/api-catalog/legal/NVIDIA%20API%20Trial%20Terms%20of%20Service.pdf",
                        "privacyPolicyURL": "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": 50,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_multipart": true,
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": true,
                            "structured_outputs": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "arcee-ai/trinity-mini",
                "hf_slug": "arcee-ai/Trinity-Mini",
                "updated_at": "2025-12-04T14:14:34.176716+00:00",
                "created_at": "2025-12-01T15:08:40+00:00",
                "hf_updated_at": null,
                "name": "Arcee AI: Trinity Mini (free)",
                "short_name": "Trinity Mini (free)",
                "author": "arcee-ai",
                "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token. Engineered for efficient reasoning over long contexts (131k) with robust function calling and multi-step agent workflows.",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": "",
                "routing_error_message": "",
                "permaslug": "arcee-ai/trinity-mini-20251201",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>",
                    "system_prompt": ""
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>",
                        "system_prompt": ""
                    },
                    "chat_template_config": {}
                },
                "default_parameters": {
                    "temperature": 0.15,
                    "top_p": 0.75,
                    "frequency_penalty": null
                },
                "default_order": [],
                "quick_start_example_type": "reasoning",
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "57299f47-f9cd-460d-b2fb-8480a99fe88e",
                    "name": "Arcee AI | arcee-ai/trinity-mini-20251201:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "arcee-ai/trinity-mini",
                        "hf_slug": "arcee-ai/Trinity-Mini",
                        "updated_at": "2025-12-04T14:14:34.176716+00:00",
                        "created_at": "2025-12-01T15:08:40+00:00",
                        "hf_updated_at": null,
                        "name": "Arcee AI: Trinity Mini",
                        "short_name": "Trinity Mini",
                        "author": "arcee-ai",
                        "description": "Trinity Mini is a 26B-parameter (3B active) sparse mixture-of-experts language model featuring 128 experts with 8 active per token. Engineered for efficient reasoning over long contexts (131k) with robust function calling and multi-step agent workflows.",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": "",
                        "routing_error_message": "",
                        "permaslug": "arcee-ai/trinity-mini-20251201",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>",
                            "system_prompt": ""
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>",
                                "system_prompt": ""
                            },
                            "chat_template_config": {}
                        },
                        "default_parameters": {
                            "temperature": 0.15,
                            "top_p": 0.75,
                            "frequency_penalty": null
                        },
                        "default_order": [],
                        "quick_start_example_type": "reasoning",
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "arcee-ai/trinity-mini:free",
                    "model_variant_permaslug": "arcee-ai/trinity-mini-20251201:free",
                    "adapter_name": "ClarifaiAdapter",
                    "provider_name": "Arcee AI",
                    "provider_info": {
                        "name": "Arcee AI",
                        "displayName": "Arcee AI",
                        "slug": "arcee-ai",
                        "baseUrl": "https://api.clarifai.com/v2/ext/openai/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "ClarifaiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.arcee.ai/&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Arcee AI",
                    "provider_slug": "arcee-ai/bf16",
                    "provider_model_id": "arcee_ai/AFM/models/trinity-mini",
                    "quantization": "bf16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "max_tokens",
                        "temperature",
                        "top_k",
                        "top_p",
                        "tool_choice",
                        "tools",
                        "structured_outputs",
                        "response_format"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "is_mandatory_reasoning": true,
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": false,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "qwen/qwen3-4b",
                "hf_slug": "Qwen/Qwen3-4B",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-04-30T16:38:24.032465+00:00",
                "hf_updated_at": null,
                "name": "Qwen: Qwen3 4B (free)",
                "short_name": "Qwen3 4B (free)",
                "author": "qwen",
                "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
                "model_version_group_id": null,
                "context_length": 40960,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Qwen3",
                "instruct_type": "qwen3",
                "default_system": null,
                "default_stops": [
                    "<|im_start|>",
                    "<|im_end|>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "qwen/qwen3-4b-04-28",
                "supports_reasoning": true,
                "reasoning_config": {
                    "start_token": "<think>",
                    "end_token": "</think>"
                },
                "features": {
                    "reasoning_config": {
                        "start_token": "<think>",
                        "end_token": "</think>"
                    }
                },
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "2e98edb5-b21b-455b-afb4-d5c01aad515d",
                    "name": "Venice | qwen/qwen3-4b-04-28:free",
                    "context_length": 40960,
                    "model": {
                        "slug": "qwen/qwen3-4b",
                        "hf_slug": "Qwen/Qwen3-4B",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-04-30T16:38:24.032465+00:00",
                        "hf_updated_at": null,
                        "name": "Qwen: Qwen3 4B",
                        "short_name": "Qwen3 4B",
                        "author": "qwen",
                        "description": "Qwen3-4B is a 4 billion parameter dense language model from the Qwen3 series, designed to support both general-purpose and reasoning-intensive tasks. It introduces a dual-mode architecture—thinking and non-thinking—allowing dynamic switching between high-precision logical reasoning and efficient dialogue generation. This makes it well-suited for multi-turn chat, instruction following, and complex agent workflows.",
                        "model_version_group_id": null,
                        "context_length": 128000,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Qwen3",
                        "instruct_type": "qwen3",
                        "default_system": null,
                        "default_stops": [
                            "<|im_start|>",
                            "<|im_end|>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "qwen/qwen3-4b-04-28",
                        "supports_reasoning": true,
                        "reasoning_config": {
                            "start_token": "<think>",
                            "end_token": "</think>"
                        },
                        "features": {
                            "reasoning_config": {
                                "start_token": "<think>",
                                "end_token": "</think>"
                            }
                        },
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "qwen/qwen3-4b:free",
                    "model_variant_permaslug": "qwen/qwen3-4b-04-28:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice",
                        "slug": "venice",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice",
                    "provider_slug": "venice/fp8",
                    "provider_model_id": "qwen3-4b",
                    "quantization": "fp8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "reasoning",
                        "include_reasoning",
                        "structured_outputs",
                        "response_format",
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k",
                        "tools",
                        "tool_choice"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": true,
                    "supports_reasoning": true,
                    "supports_multipart": false,
                    "limit_rpm": 1,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": true,
                            "structured_outputs": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "meta-llama/llama-3.2-3b-instruct",
                "hf_slug": "meta-llama/Llama-3.2-3B-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-09-25T00:00:00+00:00",
                "hf_updated_at": null,
                "name": "Meta: Llama 3.2 3B Instruct (free)",
                "short_name": "Llama 3.2 3B Instruct (free)",
                "author": "meta-llama",
                "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
                "model_version_group_id": null,
                "context_length": 131072,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Llama3",
                "instruct_type": "llama3",
                "default_system": null,
                "default_stops": [
                    "<|eot_id|>",
                    "<|end_of_text|>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "meta-llama/llama-3.2-3b-instruct",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "e8440b11-29fb-4887-a222-eff9ba33dfbf",
                    "name": "Venice | meta-llama/llama-3.2-3b-instruct:free",
                    "context_length": 131072,
                    "model": {
                        "slug": "meta-llama/llama-3.2-3b-instruct",
                        "hf_slug": "meta-llama/Llama-3.2-3B-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-09-25T00:00:00+00:00",
                        "hf_updated_at": null,
                        "name": "Meta: Llama 3.2 3B Instruct",
                        "short_name": "Llama 3.2 3B Instruct",
                        "author": "meta-llama",
                        "description": "Llama 3.2 3B is a 3-billion-parameter multilingual large language model, optimized for advanced natural language processing tasks like dialogue generation, reasoning, and summarization. Designed with the latest transformer architecture, it supports eight languages, including English, Spanish, and Hindi, and is adaptable for additional languages.\n\nTrained on 9 trillion tokens, the Llama 3.2 3B model excels in instruction-following, complex reasoning, and tool use. Its balanced performance makes it ideal for applications needing accuracy and efficiency in text generation across multilingual settings.\n\nClick here for the [original model card](https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md).\n\nUsage of this model is subject to [Meta's Acceptable Use Policy](https://www.llama.com/llama3/use-policy/).",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Llama3",
                        "instruct_type": "llama3",
                        "default_system": null,
                        "default_stops": [
                            "<|eot_id|>",
                            "<|end_of_text|>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "meta-llama/llama-3.2-3b-instruct",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "meta-llama/llama-3.2-3b-instruct:free",
                    "model_variant_permaslug": "meta-llama/llama-3.2-3b-instruct:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "Venice",
                    "provider_info": {
                        "name": "Venice",
                        "displayName": "Venice",
                        "slug": "venice",
                        "baseUrl": "https://api.venice.ai/api/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://venice.ai/legal/tos",
                            "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                        },
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": false,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://venice.ai/&size=256"
                        },
                        "ignoredProviderModels": [
                            "llama-3.2-3b",
                            "deepseek-coder-v2-lite",
                            "dolphin-2.9.2-qwen2-72b",
                            "mistral-32-24b",
                            "zai-org-glm-4.6",
                            "qwen3-235b-a22b-thinking-2507",
                            "qwen3-235b-a22b-instruct-2507",
                            "google-gemma-3-27b-it",
                            "openai-gpt-oss-120b",
                            "deepseek-ai-DeepSeek-R1",
                            "grok-41-fast",
                            "gemini-3-pro-preview",
                            "claude-opus-45",
                            "kimi-k2-thinking",
                            "deepseek-v3.2",
                            "openai-gpt-52",
                            "gemini-3-flash-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Venice",
                    "provider_slug": "venice/fp16",
                    "provider_model_id": "llama-3.2-3b",
                    "quantization": "fp16",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty",
                        "top_k"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://venice.ai/legal/tos",
                        "privacyPolicyURL": "https://venice.ai/legal/privacy-policy"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": 1,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "qwen/qwen-2.5-vl-7b-instruct",
                "hf_slug": "Qwen/Qwen2.5-VL-7B-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2024-08-28T00:00:00+00:00",
                "hf_updated_at": null,
                "name": "Qwen: Qwen2.5-VL 7B Instruct (free)",
                "short_name": "Qwen2.5-VL 7B Instruct (free)",
                "author": "qwen",
                "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
                "model_version_group_id": null,
                "context_length": 32768,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Qwen",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "qwen/qwen-2-vl-7b-instruct",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "77ef6e4c-601d-4bd6-b168-c88a5b44a792",
                    "name": "ModelRun | qwen/qwen-2-vl-7b-instruct:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "qwen/qwen-2.5-vl-7b-instruct",
                        "hf_slug": "Qwen/Qwen2.5-VL-7B-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2024-08-28T00:00:00+00:00",
                        "hf_updated_at": null,
                        "name": "Qwen: Qwen2.5-VL 7B Instruct",
                        "short_name": "Qwen2.5-VL 7B Instruct",
                        "author": "qwen",
                        "description": "Qwen2.5 VL 7B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\n- SoTA understanding of images of various resolution & ratio: Qwen2.5-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\n- Understanding videos of 20min+: Qwen2.5-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\n- Agent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2.5-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\n- Multilingual Support: to serve global users, besides English and Chinese, Qwen2.5-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.\n\nFor more details, see this [blog post](https://qwenlm.github.io/blog/qwen2-vl/) and [GitHub repo](https://github.com/QwenLM/Qwen2-VL).\n\nUsage of this model is subject to [Tongyi Qianwen LICENSE AGREEMENT](https://huggingface.co/Qwen/Qwen1.5-110B-Chat/blob/main/LICENSE).",
                        "model_version_group_id": null,
                        "context_length": 32768,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Qwen",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "qwen/qwen-2-vl-7b-instruct",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "qwen/qwen-2.5-vl-7b-instruct:free",
                    "model_variant_permaslug": "qwen/qwen-2-vl-7b-instruct:free",
                    "adapter_name": "OpenAIAdapter",
                    "provider_name": "ModelRun",
                    "provider_info": {
                        "name": "ModelRun",
                        "displayName": "ModelRun",
                        "slug": "modelrun",
                        "baseUrl": "https://api.runmodelrun.com/v1",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": false,
                            "canPublish": false,
                            "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                            "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                        },
                        "headquarters": "US",
                        "datacenters": [
                            "US"
                        ],
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": false,
                        "editors": [],
                        "owners": [],
                        "adapterName": "OpenAIAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": false,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://api.runmodelrun.com&size=256"
                        },
                        "ignoredProviderModels": [],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "ModelRun",
                    "provider_slug": "modelrun",
                    "provider_model_id": "Qwen/Qwen2.5-VL-7B-Instruct",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "presence_penalty",
                        "repetition_penalty",
                        "frequency_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": false,
                        "trainingOpenRouter": false,
                        "retainsPrompts": false,
                        "canPublish": false,
                        "termsOfServiceURL": "https://www.runmodelrun.com/TOS.html",
                        "privacyPolicyURL": "https://www.runmodelrun.com/privacy-policy.html"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_input_audio": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemma-3n-e2b-it",
                "hf_slug": "google/gemma-3n-E2B-it",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-09T15:28:24.676165+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemma 3n 2B (free)",
                "short_name": "Gemma 3n 2B (free)",
                "author": "google",
                "description": "Gemma 3n E2B IT is a multimodal, instruction-tuned model developed by Google DeepMind, designed to operate efficiently at an effective parameter size of 2B while leveraging a 6B architecture. Based on the MatFormer architecture, it supports nested submodels and modular composition via the Mix-and-Match framework. Gemma 3n models are optimized for low-resource deployment, offering 32K context length and strong multilingual and reasoning performance across common benchmarks. This variant is trained on a diverse corpus including code, math, web, and multimodal data.",
                "model_version_group_id": null,
                "context_length": 8192,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemma-3n-e2b-it",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "d211b1a5-6379-4926-ac35-4f416b01f423",
                    "name": "Google AI Studio | google/gemma-3n-e2b-it:free",
                    "context_length": 8192,
                    "model": {
                        "slug": "google/gemma-3n-e2b-it",
                        "hf_slug": "google/gemma-3n-E2B-it",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-09T15:28:24.676165+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemma 3n 2B",
                        "short_name": "Gemma 3n 2B",
                        "author": "google",
                        "description": "Gemma 3n E2B IT is a multimodal, instruction-tuned model developed by Google DeepMind, designed to operate efficiently at an effective parameter size of 2B while leveraging a 6B architecture. Based on the MatFormer architecture, it supports nested submodels and modular composition via the Mix-and-Match framework. Gemma 3n models are optimized for low-resource deployment, offering 32K context length and strong multilingual and reasoning performance across common benchmarks. This variant is trained on a diverse corpus including code, math, web, and multimodal data.",
                        "model_version_group_id": null,
                        "context_length": 8192,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemma-3n-e2b-it",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemma-3n-e2b-it:free",
                    "model_variant_permaslug": "google/gemma-3n-e2b-it:free",
                    "adapter_name": "GoogleAIStudioGeminiAdapter",
                    "provider_name": "Google AI Studio",
                    "provider_info": {
                        "name": "Google AI Studio",
                        "displayName": "Google AI Studio",
                        "slug": "google-ai-studio",
                        "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 55,
                            "canPublish": false,
                            "termsOfServiceURL": "https://cloud.google.com/terms/",
                            "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "GoogleAIStudioGeminiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/GoogleAIStudio.svg"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-1p",
                            "gemini-2.5-pro-1p-recitation-off",
                            "gemini-2.5-flash-1p",
                            "gemini-2.5-flash-1p-recitation-off",
                            "gemini-2.5-flash-lite-preview-06-11-summarized",
                            "gemini-2.5-flash",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash-lite",
                            "gemini-1.5-pro-latest",
                            "gemini-1.5-pro",
                            "gemini-1.5-flash-latest",
                            "gemini-1.5-flash",
                            "gemini-1.5-flash-8b",
                            "gemini-1.5-flash-8b-latest",
                            "gemini-2.5-pro-preview-03-25",
                            "gemini-2.0-flash",
                            "gemini-2.0-flash-lite",
                            "gemini-2.0-flash-lite-preview",
                            "gemini-2.0-pro-exp",
                            "gemini-2.0-flash-thinking-exp",
                            "gemini-2.5-flash-preview-tts",
                            "gemini-2.5-pro-preview-tts",
                            "learnlm-2.0-flash-experimental",
                            "gracefulgolem",
                            "gemini-2.5-flash-preview-05-20",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.0-flash-exp-image-generation",
                            "gemini-2.0-flash-preview-image-generation",
                            "gemini-2.0-flash-lite-preview-02-05",
                            "gemini-2.0-pro-exp-02-05",
                            "gemini-exp-1206",
                            "gemini-2.0-flash-thinking-exp-01-21",
                            "gemini-2.0-flash-thinking-exp-1219",
                            "gemma-3-1b-it",
                            "gemini-flash-latest",
                            "gemini-flash-lite-latest",
                            "gemini-pro-latest",
                            "gemini-robotics-er-1.5-preview",
                            "gemini-embedding-001",
                            "riftrunner-fst-rewind",
                            "gemini-3-pro-image-preview",
                            "nano-banana-pro-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Google AI Studio",
                    "provider_slug": "google-ai-studio",
                    "provider_model_id": "gemma-3n-e2b-it",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 2048,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "seed",
                        "response_format",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 55,
                        "canPublish": false,
                        "termsOfServiceURL": "https://cloud.google.com/terms/",
                        "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": false,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_multipart": false,
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemma-3-4b-it",
                "hf_slug": "google/gemma-3-4b-it",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-03-13T22:38:30.653142+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemma 3 4B (free)",
                "short_name": "Gemma 3 4B (free)",
                "author": "google",
                "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
                "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                "context_length": 32768,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Gemini",
                "instruct_type": "gemma",
                "default_system": null,
                "default_stops": [
                    "<start_of_turn>",
                    "<end_of_turn>",
                    "<eos>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemma-3-4b-it",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "90fbd988-266d-4ef4-b345-63b46ab6caca",
                    "name": "Google AI Studio | google/gemma-3-4b-it:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "google/gemma-3-4b-it",
                        "hf_slug": "google/gemma-3-4b-it",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-03-13T22:38:30.653142+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemma 3 4B",
                        "short_name": "Gemma 3 4B",
                        "author": "google",
                        "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling.",
                        "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                        "context_length": 131072,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Gemini",
                        "instruct_type": "gemma",
                        "default_system": null,
                        "default_stops": [
                            "<start_of_turn>",
                            "<end_of_turn>",
                            "<eos>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemma-3-4b-it",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemma-3-4b-it:free",
                    "model_variant_permaslug": "google/gemma-3-4b-it:free",
                    "adapter_name": "GoogleAIStudioGeminiAdapter",
                    "provider_name": "Google AI Studio",
                    "provider_info": {
                        "name": "Google AI Studio",
                        "displayName": "Google AI Studio",
                        "slug": "google-ai-studio",
                        "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 55,
                            "canPublish": false,
                            "termsOfServiceURL": "https://cloud.google.com/terms/",
                            "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "GoogleAIStudioGeminiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/GoogleAIStudio.svg"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-1p",
                            "gemini-2.5-pro-1p-recitation-off",
                            "gemini-2.5-flash-1p",
                            "gemini-2.5-flash-1p-recitation-off",
                            "gemini-2.5-flash-lite-preview-06-11-summarized",
                            "gemini-2.5-flash",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash-lite",
                            "gemini-1.5-pro-latest",
                            "gemini-1.5-pro",
                            "gemini-1.5-flash-latest",
                            "gemini-1.5-flash",
                            "gemini-1.5-flash-8b",
                            "gemini-1.5-flash-8b-latest",
                            "gemini-2.5-pro-preview-03-25",
                            "gemini-2.0-flash",
                            "gemini-2.0-flash-lite",
                            "gemini-2.0-flash-lite-preview",
                            "gemini-2.0-pro-exp",
                            "gemini-2.0-flash-thinking-exp",
                            "gemini-2.5-flash-preview-tts",
                            "gemini-2.5-pro-preview-tts",
                            "learnlm-2.0-flash-experimental",
                            "gracefulgolem",
                            "gemini-2.5-flash-preview-05-20",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.0-flash-exp-image-generation",
                            "gemini-2.0-flash-preview-image-generation",
                            "gemini-2.0-flash-lite-preview-02-05",
                            "gemini-2.0-pro-exp-02-05",
                            "gemini-exp-1206",
                            "gemini-2.0-flash-thinking-exp-01-21",
                            "gemini-2.0-flash-thinking-exp-1219",
                            "gemma-3-1b-it",
                            "gemini-flash-latest",
                            "gemini-flash-lite-latest",
                            "gemini-pro-latest",
                            "gemini-robotics-er-1.5-preview",
                            "gemini-embedding-001",
                            "riftrunner-fst-rewind",
                            "gemini-3-pro-image-preview",
                            "nano-banana-pro-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Google AI Studio",
                    "provider_slug": "google-ai-studio",
                    "provider_model_id": "gemma-3-4b-it",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 8192,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "seed",
                        "response_format",
                        "structured_outputs"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 55,
                        "canPublish": false,
                        "termsOfServiceURL": "https://cloud.google.com/terms/",
                        "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "structured_outputs": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemma-3-12b-it",
                "hf_slug": "google/gemma-3-12b-it",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-03-13T21:50:25.140801+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemma 3 12B (free)",
                "short_name": "Gemma 3 12B (free)",
                "author": "google",
                "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
                "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                "context_length": 32768,
                "input_modalities": [
                    "text",
                    "image"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Gemini",
                "instruct_type": "gemma",
                "default_system": null,
                "default_stops": [
                    "<start_of_turn>",
                    "<end_of_turn>",
                    "<eos>"
                ],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemma-3-12b-it",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": {},
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "a6489e9a-e430-438f-9aa9-d6a664362e6e",
                    "name": "Google AI Studio | google/gemma-3-12b-it:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "google/gemma-3-12b-it",
                        "hf_slug": "google/gemma-3-12b-it",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-03-13T21:50:25.140801+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemma 3 12B",
                        "short_name": "Gemma 3 12B",
                        "author": "google",
                        "description": "Gemma 3 introduces multimodality, supporting vision-language input and text outputs. It handles context windows up to 128k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Gemma 3 12B is the second largest in the family of Gemma 3 models after [Gemma 3 27B](google/gemma-3-27b-it)",
                        "model_version_group_id": "c99b277a-cfaf-4e93-9360-8a79cfa2b2c4",
                        "context_length": 131072,
                        "input_modalities": [
                            "text",
                            "image"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Gemini",
                        "instruct_type": "gemma",
                        "default_system": null,
                        "default_stops": [
                            "<start_of_turn>",
                            "<end_of_turn>",
                            "<eos>"
                        ],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemma-3-12b-it",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": {},
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemma-3-12b-it:free",
                    "model_variant_permaslug": "google/gemma-3-12b-it:free",
                    "adapter_name": "GoogleAIStudioGeminiAdapter",
                    "provider_name": "Google AI Studio",
                    "provider_info": {
                        "name": "Google AI Studio",
                        "displayName": "Google AI Studio",
                        "slug": "google-ai-studio",
                        "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 55,
                            "canPublish": false,
                            "termsOfServiceURL": "https://cloud.google.com/terms/",
                            "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "GoogleAIStudioGeminiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/GoogleAIStudio.svg"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-1p",
                            "gemini-2.5-pro-1p-recitation-off",
                            "gemini-2.5-flash-1p",
                            "gemini-2.5-flash-1p-recitation-off",
                            "gemini-2.5-flash-lite-preview-06-11-summarized",
                            "gemini-2.5-flash",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash-lite",
                            "gemini-1.5-pro-latest",
                            "gemini-1.5-pro",
                            "gemini-1.5-flash-latest",
                            "gemini-1.5-flash",
                            "gemini-1.5-flash-8b",
                            "gemini-1.5-flash-8b-latest",
                            "gemini-2.5-pro-preview-03-25",
                            "gemini-2.0-flash",
                            "gemini-2.0-flash-lite",
                            "gemini-2.0-flash-lite-preview",
                            "gemini-2.0-pro-exp",
                            "gemini-2.0-flash-thinking-exp",
                            "gemini-2.5-flash-preview-tts",
                            "gemini-2.5-pro-preview-tts",
                            "learnlm-2.0-flash-experimental",
                            "gracefulgolem",
                            "gemini-2.5-flash-preview-05-20",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.0-flash-exp-image-generation",
                            "gemini-2.0-flash-preview-image-generation",
                            "gemini-2.0-flash-lite-preview-02-05",
                            "gemini-2.0-pro-exp-02-05",
                            "gemini-exp-1206",
                            "gemini-2.0-flash-thinking-exp-01-21",
                            "gemini-2.0-flash-thinking-exp-1219",
                            "gemma-3-1b-it",
                            "gemini-flash-latest",
                            "gemini-flash-lite-latest",
                            "gemini-pro-latest",
                            "gemini-robotics-er-1.5-preview",
                            "gemini-embedding-001",
                            "riftrunner-fst-rewind",
                            "gemini-3-pro-image-preview",
                            "nano-banana-pro-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Google AI Studio",
                    "provider_slug": "google-ai-studio",
                    "provider_model_id": "gemma-3-12b-it",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 8192,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "seed"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 55,
                        "canPublish": false,
                        "termsOfServiceURL": "https://cloud.google.com/terms/",
                        "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "structured_outputs": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "google/gemma-3n-e4b-it",
                "hf_slug": "google/gemma-3n-E4B-it",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-05-20T21:33:44.157973+00:00",
                "hf_updated_at": null,
                "name": "Google: Gemma 3n 4B (free)",
                "short_name": "Gemma 3n 4B (free)",
                "author": "google",
                "description": "Gemma 3n E4B-it is optimized for efficient execution on mobile and low-resource devices, such as phones, laptops, and tablets. It supports multimodal inputs—including text, visual data, and audio—enabling diverse tasks such as text generation, speech recognition, translation, and image analysis. Leveraging innovations like Per-Layer Embedding (PLE) caching and the MatFormer architecture, Gemma 3n dynamically manages memory usage and computational load by selectively activating model parameters, significantly reducing runtime resource requirements.\n\nThis model supports a wide linguistic range (trained in over 140 languages) and features a flexible 32K token context window. Gemma 3n can selectively load parameters, optimizing memory and computational efficiency based on the task or device capabilities, making it well-suited for privacy-focused, offline-capable applications and on-device AI solutions. [Read more in the blog post](https://developers.googleblog.com/en/introducing-gemma-3n/)",
                "model_version_group_id": null,
                "context_length": 8192,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": null,
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "google/gemma-3n-e4b-it",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": null,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "918e82fa-161a-4cc8-b482-d2c2e46e1b9c",
                    "name": "Google AI Studio | google/gemma-3n-e4b-it:free",
                    "context_length": 8192,
                    "model": {
                        "slug": "google/gemma-3n-e4b-it",
                        "hf_slug": "google/gemma-3n-E4B-it",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-05-20T21:33:44.157973+00:00",
                        "hf_updated_at": null,
                        "name": "Google: Gemma 3n 4B",
                        "short_name": "Gemma 3n 4B",
                        "author": "google",
                        "description": "Gemma 3n E4B-it is optimized for efficient execution on mobile and low-resource devices, such as phones, laptops, and tablets. It supports multimodal inputs—including text, visual data, and audio—enabling diverse tasks such as text generation, speech recognition, translation, and image analysis. Leveraging innovations like Per-Layer Embedding (PLE) caching and the MatFormer architecture, Gemma 3n dynamically manages memory usage and computational load by selectively activating model parameters, significantly reducing runtime resource requirements.\n\nThis model supports a wide linguistic range (trained in over 140 languages) and features a flexible 32K token context window. Gemma 3n can selectively load parameters, optimizing memory and computational efficiency based on the task or device capabilities, making it well-suited for privacy-focused, offline-capable applications and on-device AI solutions. [Read more in the blog post](https://developers.googleblog.com/en/introducing-gemma-3n/)",
                        "model_version_group_id": null,
                        "context_length": 32000,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": null,
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "google/gemma-3n-e4b-it",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": null,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "google/gemma-3n-e4b-it:free",
                    "model_variant_permaslug": "google/gemma-3n-e4b-it:free",
                    "adapter_name": "GoogleAIStudioGeminiAdapter",
                    "provider_name": "Google AI Studio",
                    "provider_info": {
                        "name": "Google AI Studio",
                        "displayName": "Google AI Studio",
                        "slug": "google-ai-studio",
                        "baseUrl": "https://generativelanguage.googleapis.com/v1beta",
                        "dataPolicy": {
                            "training": false,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "retentionDays": 55,
                            "canPublish": false,
                            "termsOfServiceURL": "https://cloud.google.com/terms/",
                            "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": false,
                        "isAbortable": false,
                        "moderationRequired": false,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "GoogleAIStudioGeminiAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "/images/icons/GoogleAIStudio.svg"
                        },
                        "ignoredProviderModels": [
                            "gemini-2.5-pro-1p",
                            "gemini-2.5-pro-1p-recitation-off",
                            "gemini-2.5-flash-1p",
                            "gemini-2.5-flash-1p-recitation-off",
                            "gemini-2.5-flash-lite-preview-06-11-summarized",
                            "gemini-2.5-flash",
                            "gemini-2.5-flash-lite-preview-06-17",
                            "gemini-2.5-flash-lite",
                            "gemini-1.5-pro-latest",
                            "gemini-1.5-pro",
                            "gemini-1.5-flash-latest",
                            "gemini-1.5-flash",
                            "gemini-1.5-flash-8b",
                            "gemini-1.5-flash-8b-latest",
                            "gemini-2.5-pro-preview-03-25",
                            "gemini-2.0-flash",
                            "gemini-2.0-flash-lite",
                            "gemini-2.0-flash-lite-preview",
                            "gemini-2.0-pro-exp",
                            "gemini-2.0-flash-thinking-exp",
                            "gemini-2.5-flash-preview-tts",
                            "gemini-2.5-pro-preview-tts",
                            "learnlm-2.0-flash-experimental",
                            "gracefulgolem",
                            "gemini-2.5-flash-preview-05-20",
                            "gemini-2.5-pro-preview-06-05",
                            "gemini-2.0-flash-exp-image-generation",
                            "gemini-2.0-flash-preview-image-generation",
                            "gemini-2.0-flash-lite-preview-02-05",
                            "gemini-2.0-pro-exp-02-05",
                            "gemini-exp-1206",
                            "gemini-2.0-flash-thinking-exp-01-21",
                            "gemini-2.0-flash-thinking-exp-1219",
                            "gemma-3-1b-it",
                            "gemini-flash-latest",
                            "gemini-flash-lite-latest",
                            "gemini-pro-latest",
                            "gemini-robotics-er-1.5-preview",
                            "gemini-embedding-001",
                            "riftrunner-fst-rewind",
                            "gemini-3-pro-image-preview",
                            "nano-banana-pro-preview"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "Google AI Studio",
                    "provider_slug": "google-ai-studio",
                    "provider_model_id": "gemma-3n-e4b-it",
                    "quantization": "unknown",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": false,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": 2048,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "max_tokens",
                        "temperature",
                        "top_p",
                        "seed",
                        "response_format",
                        "stop",
                        "frequency_penalty",
                        "presence_penalty"
                    ],
                    "is_byok": false,
                    "moderation_required": false,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "retentionDays": 55,
                        "canPublish": false,
                        "termsOfServiceURL": "https://cloud.google.com/terms/",
                        "privacyPolicyURL": "https://cloud.google.com/terms/cloud-privacy-notice"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": false,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {}
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            },
            {
                "slug": "moonshotai/kimi-k2",
                "hf_slug": "moonshotai/Kimi-K2-Instruct",
                "updated_at": "2025-11-10T16:00:38.246665+00:00",
                "created_at": "2025-07-11T19:47:32.565514+00:00",
                "hf_updated_at": null,
                "name": "MoonshotAI: Kimi K2 0711 (free)",
                "short_name": "Kimi K2 0711 (free)",
                "author": "moonshotai",
                "description": "Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It is optimized for agentic capabilities, including advanced tool use, reasoning, and code synthesis. Kimi K2 excels across a broad range of benchmarks, particularly in coding (LiveCodeBench, SWE-bench), reasoning (ZebraLogic, GPQA), and tool-use (Tau2, AceBench) tasks. It supports long-context inference up to 128K tokens and is designed with a novel training stack that includes the MuonClip optimizer for stable large-scale MoE training.",
                "model_version_group_id": null,
                "context_length": 32768,
                "input_modalities": [
                    "text"
                ],
                "output_modalities": [
                    "text"
                ],
                "has_text_output": true,
                "group": "Other",
                "instruct_type": null,
                "default_system": null,
                "default_stops": [],
                "hidden": false,
                "router": null,
                "warning_message": "",
                "promotion_message": null,
                "routing_error_message": null,
                "permaslug": "moonshotai/kimi-k2",
                "supports_reasoning": false,
                "reasoning_config": null,
                "features": null,
                "default_parameters": {},
                "default_order": [],
                "quick_start_example_type": null,
                "is_trainable_text": true,
                "is_trainable_image": null,
                "endpoint": {
                    "id": "64a83fb3-0dfe-4ef2-9ca3-af7bdf2e6aad",
                    "name": "OpenInference | moonshotai/kimi-k2:free",
                    "context_length": 32768,
                    "model": {
                        "slug": "moonshotai/kimi-k2",
                        "hf_slug": "moonshotai/Kimi-K2-Instruct",
                        "updated_at": "2025-11-10T16:00:38.246665+00:00",
                        "created_at": "2025-07-11T19:47:32.565514+00:00",
                        "hf_updated_at": null,
                        "name": "MoonshotAI: Kimi K2 0711",
                        "short_name": "Kimi K2 0711",
                        "author": "moonshotai",
                        "description": "Kimi K2 Instruct is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It is optimized for agentic capabilities, including advanced tool use, reasoning, and code synthesis. Kimi K2 excels across a broad range of benchmarks, particularly in coding (LiveCodeBench, SWE-bench), reasoning (ZebraLogic, GPQA), and tool-use (Tau2, AceBench) tasks. It supports long-context inference up to 128K tokens and is designed with a novel training stack that includes the MuonClip optimizer for stable large-scale MoE training.",
                        "model_version_group_id": null,
                        "context_length": 131072,
                        "input_modalities": [
                            "text"
                        ],
                        "output_modalities": [
                            "text"
                        ],
                        "has_text_output": true,
                        "group": "Other",
                        "instruct_type": null,
                        "default_system": null,
                        "default_stops": [],
                        "hidden": false,
                        "router": null,
                        "warning_message": "",
                        "promotion_message": null,
                        "routing_error_message": null,
                        "permaslug": "moonshotai/kimi-k2",
                        "supports_reasoning": false,
                        "reasoning_config": null,
                        "features": null,
                        "default_parameters": {},
                        "default_order": [],
                        "quick_start_example_type": null,
                        "is_trainable_text": true,
                        "is_trainable_image": null
                    },
                    "model_variant_slug": "moonshotai/kimi-k2:free",
                    "model_variant_permaslug": "moonshotai/kimi-k2:free",
                    "adapter_name": "OpenInferenceAdapter",
                    "provider_name": "OpenInference",
                    "provider_info": {
                        "name": "OpenInference",
                        "displayName": "OpenInference",
                        "slug": "open-inference",
                        "baseUrl": "https://openinference.ngrok.io/v1",
                        "dataPolicy": {
                            "training": true,
                            "trainingOpenRouter": false,
                            "retainsPrompts": true,
                            "canPublish": true,
                            "termsOfServiceURL": "https://www.openinference.xyz/terms",
                            "privacyPolicyURL": "https://www.openinference.xyz/terms"
                        },
                        "headquarters": "US",
                        "regionOverrides": {},
                        "hasChatCompletions": true,
                        "hasCompletions": true,
                        "isAbortable": true,
                        "moderationRequired": true,
                        "editors": [
                            "{}"
                        ],
                        "owners": [
                            "{}"
                        ],
                        "adapterName": "OpenInferenceAdapter",
                        "isMultipartSupported": true,
                        "statusPageUrl": null,
                        "byokEnabled": true,
                        "icon": {
                            "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://openinference.xyz/&size=256",
                            "className": "invert dark:invert-0"
                        },
                        "ignoredProviderModels": [
                            "meta-llama/Llama-3.1-8B-Instruct",
                            "meta-llama/Llama-Guard-3-8B",
                            "Qwen/Qwen3-4B-Thinking-2507",
                            "openai/gpt-oss-120b-test",
                            "openai/gpt-oss-20b-test"
                        ],
                        "sendClientIp": false,
                        "pricingStrategy": null
                    },
                    "provider_display_name": "OpenInference",
                    "provider_slug": "open-inference/int8",
                    "provider_model_id": "moonshotai/Kimi-K2-Instruct",
                    "quantization": "int8",
                    "variant": "free",
                    "is_free": true,
                    "can_abort": true,
                    "max_prompt_tokens": null,
                    "max_completion_tokens": null,
                    "max_tokens_per_image": null,
                    "supported_parameters": [
                        "temperature",
                        "max_tokens",
                        "stop",
                        "seed"
                    ],
                    "is_byok": false,
                    "moderation_required": true,
                    "data_policy": {
                        "training": true,
                        "trainingOpenRouter": false,
                        "retainsPrompts": true,
                        "canPublish": true,
                        "termsOfServiceURL": "https://www.openinference.xyz/terms",
                        "privacyPolicyURL": "https://www.openinference.xyz/terms"
                    },
                    "pricing": {
                        "prompt": "0",
                        "completion": "0",
                        "image": "0",
                        "request": "0",
                        "web_search": "0",
                        "internal_reasoning": "0",
                        "image_output": "0",
                        "discount": 0
                    },
                    "variable_pricings": [],
                    "is_hidden": false,
                    "is_deranked": false,
                    "is_disabled": false,
                    "supports_tool_parameters": false,
                    "supports_reasoning": false,
                    "supports_multipart": true,
                    "limit_rpm": null,
                    "limit_rpd": null,
                    "limit_rpm_cf": null,
                    "has_completions": true,
                    "has_chat_completions": true,
                    "features": {
                        "supports_tool_choice": {
                            "literal_none": true,
                            "literal_auto": true,
                            "literal_required": true,
                            "type_function": true
                        },
                        "supported_parameters": {
                            "response_format": false,
                            "structured_outputs": false
                        }
                    },
                    "provider_region": null,
                    "deprecation_date": null
                }
            }
        ],
        "analytics": {
            "anthropic/claude-4-opus-20250522": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4-opus-20250522",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4-opus-20250522",
                "count": 88754,
                "total_completion_tokens": 39983610,
                "total_prompt_tokens": 972078560,
                "total_native_tokens_reasoning": 741641,
                "num_media_prompt": 5491,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 176085240,
                "total_tool_calls": 6362,
                "requests_with_tool_call_errors": 460
            },
            "deepseek/deepseek-r1-distill-llama-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-distill-llama-70b",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1-distill-llama-70b",
                "count": 554914,
                "total_completion_tokens": 235134454,
                "total_prompt_tokens": 900434098,
                "total_native_tokens_reasoning": 209422988,
                "num_media_prompt": 2283,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 251379029,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meituan/longcat-flash-chat": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meituan/longcat-flash-chat",
                "variant": "standard",
                "variant_permaslug": "meituan/longcat-flash-chat",
                "count": 441998,
                "total_completion_tokens": 106780599,
                "total_prompt_tokens": 1809712062,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "anthropic/claude-4.5-opus-20251124": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4.5-opus-20251124",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4.5-opus-20251124",
                "count": 6374949,
                "total_completion_tokens": 4761332496,
                "total_prompt_tokens": 228789603732,
                "total_native_tokens_reasoning": 426110597,
                "num_media_prompt": 32819720,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 109509208048,
                "total_tool_calls": 3102939,
                "requests_with_tool_call_errors": 84848
            },
            "mistralai/ministral-3b-2512": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/ministral-3b-2512",
                "variant": "standard",
                "variant_permaslug": "mistralai/ministral-3b-2512",
                "count": 470195,
                "total_completion_tokens": 61076233,
                "total_prompt_tokens": 442420758,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 23485,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 11063,
                "requests_with_tool_call_errors": 347
            },
            "openai/text-embedding-ada-002": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/text-embedding-ada-002",
                "variant": "standard",
                "variant_permaslug": "openai/text-embedding-ada-002",
                "count": 298277,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 584431175,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-chat-v3-0324": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-chat-v3-0324",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-chat-v3-0324",
                "count": 23662364,
                "total_completion_tokens": 5336444522,
                "total_prompt_tokens": 110131931611,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 404,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3374424833,
                "total_tool_calls": 186812,
                "requests_with_tool_call_errors": 3473
            },
            "mistralai/mistral-medium-3.1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-medium-3.1",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-medium-3.1",
                "count": 417599,
                "total_completion_tokens": 189861266,
                "total_prompt_tokens": 2867657618,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 17751,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 16499,
                "requests_with_tool_call_errors": 832
            },
            "openai/gpt-5-nano-2025-08-07": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-nano-2025-08-07",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-nano-2025-08-07",
                "count": 5428786,
                "total_completion_tokens": 5857172389,
                "total_prompt_tokens": 18425736495,
                "total_native_tokens_reasoning": 5117545723,
                "num_media_prompt": 1059063,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6032511360,
                "total_tool_calls": 149933,
                "requests_with_tool_call_errors": 884
            },
            "microsoft/phi-4": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/phi-4",
                "variant": "standard",
                "variant_permaslug": "microsoft/phi-4",
                "count": 1668028,
                "total_completion_tokens": 53904610,
                "total_prompt_tokens": 559604420,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "kwaipilot/kat-coder-pro-v1": {
                "date": "2026-01-05 00:00:00",
                "model_permaslug": "kwaipilot/kat-coder-pro-v1",
                "variant": "standard",
                "variant_permaslug": "kwaipilot/kat-coder-pro-v1",
                "count": 48766,
                "total_completion_tokens": 28985448,
                "total_prompt_tokens": 314304967,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 175770535,
                "total_tool_calls": 1023,
                "requests_with_tool_call_errors": 56
            },
            "cohere/command-r-08-2024": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "cohere/command-r-08-2024",
                "variant": "standard",
                "variant_permaslug": "cohere/command-r-08-2024",
                "count": 102121,
                "total_completion_tokens": 10557188,
                "total_prompt_tokens": 67988962,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 180,
                "requests_with_tool_call_errors": 17
            },
            "openai/gpt-oss-120b:exacto": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-120b",
                "variant": "exacto",
                "variant_permaslug": "openai/gpt-oss-120b:exacto",
                "count": 1031980,
                "total_completion_tokens": 633919004,
                "total_prompt_tokens": 4218445151,
                "total_native_tokens_reasoning": 362002351,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 80488404,
                "total_tool_calls": 210325,
                "requests_with_tool_call_errors": 4737
            },
            "google/gemini-2.0-flash-lite-001": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.0-flash-lite-001",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.0-flash-lite-001",
                "count": 14545365,
                "total_completion_tokens": 2132422875,
                "total_prompt_tokens": 19062592139,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2557540,
                "num_media_completion": 0,
                "num_audio_prompt": 12794,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 62445,
                "requests_with_tool_call_errors": 12259
            },
            "google/gemini-2.5-flash": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash",
                "count": 100303277,
                "total_completion_tokens": 30910883703,
                "total_prompt_tokens": 345317692093,
                "total_native_tokens_reasoning": 5288869985,
                "num_media_prompt": 23820356,
                "num_media_completion": 0,
                "num_audio_prompt": 176023,
                "total_native_tokens_cached": 84087721730,
                "total_tool_calls": 8149829,
                "requests_with_tool_call_errors": 121985
            },
            "anthracite-org/magnum-v4-72b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthracite-org/magnum-v4-72b",
                "variant": "standard",
                "variant_permaslug": "anthracite-org/magnum-v4-72b",
                "count": 70695,
                "total_completion_tokens": 6404053,
                "total_prompt_tokens": 83071804,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-vl-30b-a3b-thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-30b-a3b-thinking",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-30b-a3b-thinking",
                "count": 26209,
                "total_completion_tokens": 31373247,
                "total_prompt_tokens": 185342717,
                "total_native_tokens_reasoning": 23783947,
                "num_media_prompt": 61992,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 695,
                "requests_with_tool_call_errors": 112
            },
            "qwen/qwen3-coder-480b-a35b-07-25": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                "count": 500372,
                "total_completion_tokens": 166331881,
                "total_prompt_tokens": 11167643020,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 23,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1104394659,
                "total_tool_calls": 179022,
                "requests_with_tool_call_errors": 9347
            },
            "moonshotai/kimi-k2-0905": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-k2-0905",
                "variant": "standard",
                "variant_permaslug": "moonshotai/kimi-k2-0905",
                "count": 10813847,
                "total_completion_tokens": 1722072773,
                "total_prompt_tokens": 38450013042,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 268,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 14172946626,
                "total_tool_calls": 69266,
                "requests_with_tool_call_errors": 687
            },
            "openai/gpt-4.1-nano-2025-04-14": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4.1-nano-2025-04-14",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4.1-nano-2025-04-14",
                "count": 8745113,
                "total_completion_tokens": 1138749940,
                "total_prompt_tokens": 18420850351,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 303606,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 9141558400,
                "total_tool_calls": 842208,
                "requests_with_tool_call_errors": 1239
            },
            "qwen/qwen3-vl-235b-a22b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-235b-a22b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-235b-a22b-instruct",
                "count": 9039656,
                "total_completion_tokens": 1083911220,
                "total_prompt_tokens": 29578198946,
                "total_native_tokens_reasoning": 20716,
                "num_media_prompt": 22287714,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1791970311,
                "total_tool_calls": 19477,
                "requests_with_tool_call_errors": 1366
            },
            "openai/gpt-4-1106-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4-1106-preview",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4-1106-preview",
                "count": 82175,
                "total_completion_tokens": 29287278,
                "total_prompt_tokens": 143325428,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 16786,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4o-audio-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-audio-preview",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-audio-preview",
                "count": 38537,
                "total_completion_tokens": 2238532,
                "total_prompt_tokens": 15620376,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 116430,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 36,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.2-1b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.2-1b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.2-1b-instruct",
                "count": 165442,
                "total_completion_tokens": 27787989,
                "total_prompt_tokens": 81692009,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.3-70b-instruct:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.3-70b-instruct",
                "variant": "free",
                "variant_permaslug": "meta-llama/llama-3.3-70b-instruct:free",
                "count": 723932,
                "total_completion_tokens": 294367326,
                "total_prompt_tokens": 3123579783,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 11097,
                "requests_with_tool_call_errors": 4955
            },
            "intfloat/e5-base-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "intfloat/e5-base-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "intfloat/e5-base-v2-20251117",
                "count": 896,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 109044,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "inception/mercury": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "inception/mercury",
                "variant": "standard",
                "variant_permaslug": "inception/mercury",
                "count": 49385,
                "total_completion_tokens": 2793290,
                "total_prompt_tokens": 48274103,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 41,
                "requests_with_tool_call_errors": 10
            },
            "openai/gpt-5.2-pro-20251211": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.2-pro-20251211",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.2-pro-20251211",
                "count": 57861,
                "total_completion_tokens": 89526310,
                "total_prompt_tokens": 2198883063,
                "total_native_tokens_reasoning": 46766921,
                "num_media_prompt": 11040,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 12256,
                "requests_with_tool_call_errors": 62
            },
            "meta-llama/llama-3.2-3b-instruct:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.2-3b-instruct",
                "variant": "free",
                "variant_permaslug": "meta-llama/llama-3.2-3b-instruct:free",
                "count": 80907,
                "total_completion_tokens": 19255824,
                "total_prompt_tokens": 119130968,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-3-pro-image-preview-20251120": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-3-pro-image-preview-20251120",
                "variant": "standard",
                "variant_permaslug": "google/gemini-3-pro-image-preview-20251120",
                "count": 1216842,
                "total_completion_tokens": 1690630818,
                "total_prompt_tokens": 1825906675,
                "total_native_tokens_reasoning": 404115531,
                "num_media_prompt": 1633510,
                "num_media_completion": 1334878,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 66880828,
                "total_tool_calls": 44,
                "requests_with_tool_call_errors": 44
            },
            "openai/codex-mini": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/codex-mini",
                "variant": "standard",
                "variant_permaslug": "openai/codex-mini",
                "count": 4920,
                "total_completion_tokens": 3385782,
                "total_prompt_tokens": 41016673,
                "total_native_tokens_reasoning": 2947177,
                "num_media_prompt": 130,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 21833216,
                "total_tool_calls": 2014,
                "requests_with_tool_call_errors": 2
            },
            "deepseek/deepseek-r1-0528": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-0528",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1-0528",
                "count": 1597599,
                "total_completion_tokens": 2051165859,
                "total_prompt_tokens": 12373256085,
                "total_native_tokens_reasoning": 1689439352,
                "num_media_prompt": 149,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3226683150,
                "total_tool_calls": 7251,
                "requests_with_tool_call_errors": 161
            },
            "z-ai/glm-4.7-20251222": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.7-20251222",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.7-20251222",
                "count": 12643504,
                "total_completion_tokens": 11191662181,
                "total_prompt_tokens": 133852883594,
                "total_native_tokens_reasoning": 4269653521,
                "num_media_prompt": 3924,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 60469859949,
                "total_tool_calls": 7206935,
                "requests_with_tool_call_errors": 46687
            },
            "mancer/weaver": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mancer/weaver",
                "variant": "standard",
                "variant_permaslug": "mancer/weaver",
                "count": 43677,
                "total_completion_tokens": 4112297,
                "total_prompt_tokens": 12266064,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-235b-a22b-04-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-235b-a22b-04-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-235b-a22b-04-28",
                "count": 810639,
                "total_completion_tokens": 402022480,
                "total_prompt_tokens": 2313070782,
                "total_native_tokens_reasoning": 277229033,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 254902514,
                "total_tool_calls": 20587,
                "requests_with_tool_call_errors": 1049
            },
            "qwen/qwen3-30b-a3b-instruct-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-30b-a3b-instruct-2507",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-30b-a3b-instruct-2507",
                "count": 2614253,
                "total_completion_tokens": 1036499624,
                "total_prompt_tokens": 4972052422,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 713029360,
                "total_tool_calls": 7514,
                "requests_with_tool_call_errors": 879
            },
            "deepseek/deepseek-r1-0528-qwen3-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-0528-qwen3-8b",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1-0528-qwen3-8b",
                "count": 228975,
                "total_completion_tokens": 206883288,
                "total_prompt_tokens": 947152493,
                "total_native_tokens_reasoning": 170053134,
                "num_media_prompt": 48,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "neversleep/noromaid-20b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "neversleep/noromaid-20b",
                "variant": "standard",
                "variant_permaslug": "neversleep/noromaid-20b",
                "count": 56262,
                "total_completion_tokens": 2776528,
                "total_prompt_tokens": 33012430,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-small-3.1-24b-instruct-2503": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
                "count": 406601,
                "total_completion_tokens": 40911894,
                "total_prompt_tokens": 616901161,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1357,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 45509103,
                "total_tool_calls": 2,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4o-mini-search-preview-2025-03-11": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-mini-search-preview-2025-03-11",
                "count": 78777,
                "total_completion_tokens": 90992164,
                "total_prompt_tokens": 73100902,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepcogito/cogito-v2-preview-llama-109b-moe": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepcogito/cogito-v2-preview-llama-109b-moe",
                "variant": "standard",
                "variant_permaslug": "deepcogito/cogito-v2-preview-llama-109b-moe",
                "count": 4408,
                "total_completion_tokens": 531416,
                "total_prompt_tokens": 21357703,
                "total_native_tokens_reasoning": 14244,
                "num_media_prompt": 8352,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 12,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mixtral-8x22b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mixtral-8x22b-instruct",
                "variant": "standard",
                "variant_permaslug": "mistralai/mixtral-8x22b-instruct",
                "count": 41223,
                "total_completion_tokens": 5055187,
                "total_prompt_tokens": 48685511,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 293,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/devstral-small-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/devstral-small-2507",
                "variant": "standard",
                "variant_permaslug": "mistralai/devstral-small-2507",
                "count": 414053,
                "total_completion_tokens": 44186091,
                "total_prompt_tokens": 505023649,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 5053,
                "requests_with_tool_call_errors": 32
            },
            "xiaomi/mimo-v2-flash-20251210:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "xiaomi/mimo-v2-flash-20251210",
                "variant": "free",
                "variant_permaslug": "xiaomi/mimo-v2-flash-20251210:free",
                "count": 42384449,
                "total_completion_tokens": 46044112668,
                "total_prompt_tokens": 340296052065,
                "total_native_tokens_reasoning": 24945207166,
                "num_media_prompt": 6456,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 17592743405,
                "total_tool_calls": 2027238,
                "requests_with_tool_call_errors": 80212
            },
            "mistralai/mistral-7b-instruct-v0.2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-7b-instruct-v0.2",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-7b-instruct-v0.2",
                "count": 158028,
                "total_completion_tokens": 5310061,
                "total_prompt_tokens": 47868931,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepcogito/cogito-v2.1-671b-20251118": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepcogito/cogito-v2.1-671b-20251118",
                "variant": "standard",
                "variant_permaslug": "deepcogito/cogito-v2.1-671b-20251118",
                "count": 55876,
                "total_completion_tokens": 8156929,
                "total_prompt_tokens": 157029689,
                "total_native_tokens_reasoning": 1934775,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "microsoft/phi-4-multimodal-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/phi-4-multimodal-instruct",
                "variant": "standard",
                "variant_permaslug": "microsoft/phi-4-multimodal-instruct",
                "count": 60139,
                "total_completion_tokens": 15863814,
                "total_prompt_tokens": 51212625,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 38766,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nousresearch/deephermes-3-mistral-24b-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
                "variant": "standard",
                "variant_permaslug": "nousresearch/deephermes-3-mistral-24b-preview",
                "count": 4361,
                "total_completion_tokens": 1945021,
                "total_prompt_tokens": 36272375,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 20958508,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-4-scout-17b-16e-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
                "count": 4577265,
                "total_completion_tokens": 685072049,
                "total_prompt_tokens": 6980306775,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1847126,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 13570,
                "requests_with_tool_call_errors": 383
            },
            "openai/gpt-4o-2024-11-20": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-2024-11-20",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-2024-11-20",
                "count": 509242,
                "total_completion_tokens": 63233942,
                "total_prompt_tokens": 753298229,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 81342,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 172772352,
                "total_tool_calls": 6884,
                "requests_with_tool_call_errors": 50
            },
            "google/gemini-2.5-flash-preview-09-2025": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash-preview-09-2025",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash-preview-09-2025",
                "count": 8758946,
                "total_completion_tokens": 4860184965,
                "total_prompt_tokens": 40653852695,
                "total_native_tokens_reasoning": 1234226823,
                "num_media_prompt": 956980,
                "num_media_completion": 0,
                "num_audio_prompt": 1963,
                "total_native_tokens_cached": 16940370173,
                "total_tool_calls": 2576912,
                "requests_with_tool_call_errors": 17907
            },
            "openai/gpt-5.1-20251113": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.1-20251113",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.1-20251113",
                "count": 2416073,
                "total_completion_tokens": 1651464221,
                "total_prompt_tokens": 12353674011,
                "total_native_tokens_reasoning": 868458407,
                "num_media_prompt": 487144,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 5825214976,
                "total_tool_calls": 159337,
                "requests_with_tool_call_errors": 1286
            },
            "openai/gpt-5-codex": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-codex",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-codex",
                "count": 38207,
                "total_completion_tokens": 24357168,
                "total_prompt_tokens": 1300603282,
                "total_native_tokens_reasoning": 16405743,
                "num_media_prompt": 2252,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1064018816,
                "total_tool_calls": 29797,
                "requests_with_tool_call_errors": 268
            },
            "google/gemma-3n-e4b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3n-e4b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-3n-e4b-it",
                "count": 3166753,
                "total_completion_tokens": 289943558,
                "total_prompt_tokens": 846092767,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 42,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sao10k/l3.1-70b-hanami-x1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sao10k/l3.1-70b-hanami-x1",
                "variant": "standard",
                "variant_permaslug": "sao10k/l3.1-70b-hanami-x1",
                "count": 1201,
                "total_completion_tokens": 160339,
                "total_prompt_tokens": 674143,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "anthropic/claude-3-7-sonnet-20250219:thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3-7-sonnet-20250219",
                "variant": "thinking",
                "variant_permaslug": "anthropic/claude-3-7-sonnet-20250219:thinking",
                "count": 92485,
                "total_completion_tokens": 113189655,
                "total_prompt_tokens": 1833303722,
                "total_native_tokens_reasoning": 50787024,
                "num_media_prompt": 12300,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 704222551,
                "total_tool_calls": 21308,
                "requests_with_tool_call_errors": 635
            },
            "anthropic/claude-3-5-haiku": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3-5-haiku",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-3-5-haiku",
                "count": 2023350,
                "total_completion_tokens": 377524698,
                "total_prompt_tokens": 6103923298,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 12434,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1115974593,
                "total_tool_calls": 180095,
                "requests_with_tool_call_errors": 7830
            },
            "nvidia/llama-3.1-nemotron-ultra-253b-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
                "variant": "standard",
                "variant_permaslug": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
                "count": 3341210,
                "total_completion_tokens": 15999234,
                "total_prompt_tokens": 1886027274,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sentence-transformers/all-mpnet-base-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sentence-transformers/all-mpnet-base-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "sentence-transformers/all-mpnet-base-v2-20251117",
                "count": 17791,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 9423073,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-coder-480b-a35b-07-25:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                "variant": "free",
                "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25:free",
                "count": 198087,
                "total_completion_tokens": 166291552,
                "total_prompt_tokens": 6723869179,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 96,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6788883,
                "total_tool_calls": 32847,
                "requests_with_tool_call_errors": 11075
            },
            "openai/o1-2024-12-17": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o1-2024-12-17",
                "variant": "standard",
                "variant_permaslug": "openai/o1-2024-12-17",
                "count": 9002,
                "total_completion_tokens": 9254401,
                "total_prompt_tokens": 19831271,
                "total_native_tokens_reasoning": 6417600,
                "num_media_prompt": 278,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4247040,
                "total_tool_calls": 155,
                "requests_with_tool_call_errors": 4
            },
            "qwen/qwen-plus-2025-07-28:thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-plus-2025-07-28",
                "variant": "thinking",
                "variant_permaslug": "qwen/qwen-plus-2025-07-28:thinking",
                "count": 5312,
                "total_completion_tokens": 11605168,
                "total_prompt_tokens": 32536429,
                "total_native_tokens_reasoning": 5304091,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 228,
                "requests_with_tool_call_errors": 50
            },
            "nousresearch/hermes-4-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-4-70b",
                "variant": "standard",
                "variant_permaslug": "nousresearch/hermes-4-70b",
                "count": 344686,
                "total_completion_tokens": 60996197,
                "total_prompt_tokens": 1698693323,
                "total_native_tokens_reasoning": 388224,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 69686496,
                "total_tool_calls": 2708,
                "requests_with_tool_call_errors": 77
            },
            "openai/gpt-3.5-turbo-16k": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-3.5-turbo-16k",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-3.5-turbo-16k",
                "count": 26033,
                "total_completion_tokens": 3931535,
                "total_prompt_tokens": 27183583,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 68224,
                "total_tool_calls": 5468,
                "requests_with_tool_call_errors": 31
            },
            "mistralai/mistral-medium-3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-medium-3",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-medium-3",
                "count": 6016730,
                "total_completion_tokens": 173043782,
                "total_prompt_tokens": 2190982724,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 5811940,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 110,
                "requests_with_tool_call_errors": 14
            },
            "meta-llama/llama-3.2-90b-vision-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.2-90b-vision-instruct",
                "count": 178132,
                "total_completion_tokens": 12114807,
                "total_prompt_tokens": 454676117,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 517631,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mixtral-8x7b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mixtral-8x7b-instruct",
                "variant": "standard",
                "variant_permaslug": "mistralai/mixtral-8x7b-instruct",
                "count": 2210687,
                "total_completion_tokens": 489553019,
                "total_prompt_tokens": 594261014,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 10,
                "requests_with_tool_call_errors": 7
            },
            "anthropic/claude-4-sonnet-20250522": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4-sonnet-20250522",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4-sonnet-20250522",
                "count": 4278020,
                "total_completion_tokens": 2335761792,
                "total_prompt_tokens": 58071513376,
                "total_native_tokens_reasoning": 25460858,
                "num_media_prompt": 690956,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 25929492487,
                "total_tool_calls": 896317,
                "requests_with_tool_call_errors": 15385
            },
            "meta-llama/llama-3.1-8b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.1-8b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.1-8b-instruct",
                "count": 25862193,
                "total_completion_tokens": 3023997413,
                "total_prompt_tokens": 29020412054,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 125,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1166429184,
                "total_tool_calls": 31457,
                "requests_with_tool_call_errors": 1501
            },
            "x-ai/grok-4-fast": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-4-fast",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-4-fast",
                "count": 21720268,
                "total_completion_tokens": 18449439429,
                "total_prompt_tokens": 114429387281,
                "total_native_tokens_reasoning": 9673666934,
                "num_media_prompt": 1714961,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 23072283841,
                "total_tool_calls": 1297396,
                "requests_with_tool_call_errors": 841
            },
            "openai/o3-pro-2025-06-10": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o3-pro-2025-06-10",
                "variant": "standard",
                "variant_permaslug": "openai/o3-pro-2025-06-10",
                "count": 362,
                "total_completion_tokens": 620871,
                "total_prompt_tokens": 2639402,
                "total_native_tokens_reasoning": 314908,
                "num_media_prompt": 15,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4o": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o",
                "count": 5192657,
                "total_completion_tokens": 586183680,
                "total_prompt_tokens": 9171784594,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 972929,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3015010432,
                "total_tool_calls": 601941,
                "requests_with_tool_call_errors": 10896
            },
            "qwen/qwq-32b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwq-32b",
                "variant": "standard",
                "variant_permaslug": "qwen/qwq-32b",
                "count": 160819,
                "total_completion_tokens": 211663959,
                "total_prompt_tokens": 413249036,
                "total_native_tokens_reasoning": 189172764,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 254,
                "requests_with_tool_call_errors": 26
            },
            "openai/gpt-4o-2024-08-06": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-2024-08-06",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-2024-08-06",
                "count": 729928,
                "total_completion_tokens": 194698127,
                "total_prompt_tokens": 893607835,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 6972,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 232163072,
                "total_tool_calls": 2161,
                "requests_with_tool_call_errors": 15
            },
            "aion-labs/aion-1.0-mini": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "aion-labs/aion-1.0-mini",
                "variant": "standard",
                "variant_permaslug": "aion-labs/aion-1.0-mini",
                "count": 41819,
                "total_completion_tokens": 14024583,
                "total_prompt_tokens": 11240219,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.2-11b-vision-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.2-11b-vision-instruct",
                "count": 530954,
                "total_completion_tokens": 72691020,
                "total_prompt_tokens": 2128969779,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 455853,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-2.5-flash-lite-preview-09-2025": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash-lite-preview-09-2025",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash-lite-preview-09-2025",
                "count": 15207022,
                "total_completion_tokens": 5615753531,
                "total_prompt_tokens": 37460308639,
                "total_native_tokens_reasoning": 975361638,
                "num_media_prompt": 1208909,
                "num_media_completion": 0,
                "num_audio_prompt": 7099,
                "total_native_tokens_cached": 8088803732,
                "total_tool_calls": 161973,
                "requests_with_tool_call_errors": 2467
            },
            "inflection/inflection-3-pi": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "inflection/inflection-3-pi",
                "variant": "standard",
                "variant_permaslug": "inflection/inflection-3-pi",
                "count": 32658,
                "total_completion_tokens": 1550071,
                "total_prompt_tokens": 9429692,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.2-3b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.2-3b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.2-3b-instruct",
                "count": 6653752,
                "total_completion_tokens": 1909934150,
                "total_prompt_tokens": 4730112153,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 557,
                "requests_with_tool_call_errors": 213
            },
            "openai/text-embedding-3-large": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/text-embedding-3-large",
                "variant": "standard",
                "variant_permaslug": "openai/text-embedding-3-large",
                "count": 3745230,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 2546485570,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sao10k/l3-lunaris-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sao10k/l3-lunaris-8b",
                "variant": "standard",
                "variant_permaslug": "sao10k/l3-lunaris-8b",
                "count": 2012336,
                "total_completion_tokens": 422232954,
                "total_prompt_tokens": 5057333894,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "minimax/minimax-m2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "minimax/minimax-m2",
                "variant": "standard",
                "variant_permaslug": "minimax/minimax-m2",
                "count": 2321383,
                "total_completion_tokens": 1260431222,
                "total_prompt_tokens": 84875485371,
                "total_native_tokens_reasoning": 609333113,
                "num_media_prompt": 371,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 7473372275,
                "total_tool_calls": 1723115,
                "requests_with_tool_call_errors": 227569
            },
            "mistralai/mistral-small-24b-instruct-2501": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-small-24b-instruct-2501",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-small-24b-instruct-2501",
                "count": 3364362,
                "total_completion_tokens": 577056030,
                "total_prompt_tokens": 10792385686,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 685088186,
                "total_tool_calls": 88,
                "requests_with_tool_call_errors": 6
            },
            "openai/gpt-3.5-turbo": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-3.5-turbo",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-3.5-turbo",
                "count": 1721673,
                "total_completion_tokens": 235674019,
                "total_prompt_tokens": 980603506,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 15299,
                "requests_with_tool_call_errors": 306
            },
            "alfredpros/codellama-7b-instruct-solidity": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "alfredpros/codellama-7b-instruct-solidity",
                "variant": "standard",
                "variant_permaslug": "alfredpros/codellama-7b-instruct-solidity",
                "count": 59998,
                "total_completion_tokens": 3135772,
                "total_prompt_tokens": 7786131,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-v3.2-speciale-20251201": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-v3.2-speciale-20251201",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-v3.2-speciale-20251201",
                "count": 112024,
                "total_completion_tokens": 567077335,
                "total_prompt_tokens": 816166913,
                "total_native_tokens_reasoning": 525363502,
                "num_media_prompt": 145,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 228570304,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "opengvlab/internvl3-78b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "opengvlab/internvl3-78b",
                "variant": "standard",
                "variant_permaslug": "opengvlab/internvl3-78b",
                "count": 122898,
                "total_completion_tokens": 9899771,
                "total_prompt_tokens": 89385059,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 20994,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 22928070,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-prover-v2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-prover-v2",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-prover-v2",
                "count": 105297,
                "total_completion_tokens": 70173437,
                "total_prompt_tokens": 280560009,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/devstral-2512": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/devstral-2512",
                "variant": "standard",
                "variant_permaslug": "mistralai/devstral-2512",
                "count": 779194,
                "total_completion_tokens": 164568464,
                "total_prompt_tokens": 5569105349,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4263223024,
                "total_tool_calls": 10459,
                "requests_with_tool_call_errors": 335
            },
            "deepseek/deepseek-r1-distill-qwen-32b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1-distill-qwen-32b",
                "count": 291109,
                "total_completion_tokens": 153236757,
                "total_prompt_tokens": 195768177,
                "total_native_tokens_reasoning": 149802733,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "anthropic/claude-4.5-haiku-20251001": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4.5-haiku-20251001",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4.5-haiku-20251001",
                "count": 6728843,
                "total_completion_tokens": 2597540914,
                "total_prompt_tokens": 90035490083,
                "total_native_tokens_reasoning": 177439261,
                "num_media_prompt": 1699391,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 46179574596,
                "total_tool_calls": 1930332,
                "requests_with_tool_call_errors": 81039
            },
            "mistralai/ministral-14b-2512": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/ministral-14b-2512",
                "variant": "standard",
                "variant_permaslug": "mistralai/ministral-14b-2512",
                "count": 4723232,
                "total_completion_tokens": 955487427,
                "total_prompt_tokens": 4412351840,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 4024654,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 3948,
                "requests_with_tool_call_errors": 171
            },
            "openai/gpt-3.5-turbo-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-3.5-turbo-instruct",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-3.5-turbo-instruct",
                "count": 18728,
                "total_completion_tokens": 3291130,
                "total_prompt_tokens": 6029185,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/voxtral-small-24b-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/voxtral-small-24b-2507",
                "variant": "standard",
                "variant_permaslug": "mistralai/voxtral-small-24b-2507",
                "count": 18505,
                "total_completion_tokens": 1563375,
                "total_prompt_tokens": 13137765,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 7014,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 526,
                "requests_with_tool_call_errors": 81
            },
            "nex-agi/deepseek-v3.1-nex-n1:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nex-agi/deepseek-v3.1-nex-n1",
                "variant": "free",
                "variant_permaslug": "nex-agi/deepseek-v3.1-nex-n1:free",
                "count": 4931627,
                "total_completion_tokens": 2840386203,
                "total_prompt_tokens": 68864246204,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 38,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 78722,
                "requests_with_tool_call_errors": 8703
            },
            "qwen/qwen-2-vl-7b-instruct:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-2-vl-7b-instruct",
                "variant": "free",
                "variant_permaslug": "qwen/qwen-2-vl-7b-instruct:free",
                "count": 42040,
                "total_completion_tokens": 12837626,
                "total_prompt_tokens": 124351126,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 26876,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "amazon/nova-2-lite-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "amazon/nova-2-lite-v1",
                "variant": "standard",
                "variant_permaslug": "amazon/nova-2-lite-v1",
                "count": 46844,
                "total_completion_tokens": 15551796,
                "total_prompt_tokens": 218059490,
                "total_native_tokens_reasoning": 6732,
                "num_media_prompt": 20544,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 2807,
                "requests_with_tool_call_errors": 21
            },
            "bytedance-seed/seed-1.6-flash-20250625": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "bytedance-seed/seed-1.6-flash-20250625",
                "variant": "standard",
                "variant_permaslug": "bytedance-seed/seed-1.6-flash-20250625",
                "count": 279528,
                "total_completion_tokens": 203136307,
                "total_prompt_tokens": 903867877,
                "total_native_tokens_reasoning": 156254241,
                "num_media_prompt": 180726,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 7952,
                "requests_with_tool_call_errors": 886
            },
            "google/gemma-3-4b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-4b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-3-4b-it",
                "count": 25810964,
                "total_completion_tokens": 715091553,
                "total_prompt_tokens": 1698739428,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 218521,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 286478144,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "intfloat/multilingual-e5-large-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "intfloat/multilingual-e5-large-20251117",
                "variant": "standard",
                "variant_permaslug": "intfloat/multilingual-e5-large-20251117",
                "count": 1007639,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 208162643,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "baai/bge-large-en-v1.5-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baai/bge-large-en-v1.5-20251117",
                "variant": "standard",
                "variant_permaslug": "baai/bge-large-en-v1.5-20251117",
                "count": 9006,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 28274141,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-30b-a3b-04-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-30b-a3b-04-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-30b-a3b-04-28",
                "count": 976628,
                "total_completion_tokens": 642198096,
                "total_prompt_tokens": 2030519876,
                "total_native_tokens_reasoning": 633777935,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 25425199,
                "total_tool_calls": 1634,
                "requests_with_tool_call_errors": 131
            },
            "openai/gpt-5.1-codex-mini-20251113": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.1-codex-mini-20251113",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.1-codex-mini-20251113",
                "count": 113666,
                "total_completion_tokens": 93339294,
                "total_prompt_tokens": 2416541161,
                "total_native_tokens_reasoning": 68846845,
                "num_media_prompt": 7792,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1876339968,
                "total_tool_calls": 45332,
                "requests_with_tool_call_errors": 209
            },
            "nousresearch/hermes-3-llama-3.1-405b:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
                "variant": "free",
                "variant_permaslug": "nousresearch/hermes-3-llama-3.1-405b:free",
                "count": 107513,
                "total_completion_tokens": 35686934,
                "total_prompt_tokens": 831563493,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "relace/relace-search-20251208": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "relace/relace-search-20251208",
                "variant": "standard",
                "variant_permaslug": "relace/relace-search-20251208",
                "count": 42497,
                "total_completion_tokens": 1809858,
                "total_prompt_tokens": 15123742,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 397,
                "requests_with_tool_call_errors": 15
            },
            "x-ai/grok-code-fast-1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-code-fast-1",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-code-fast-1",
                "count": 15881678,
                "total_completion_tokens": 11612099080,
                "total_prompt_tokens": 439632077504,
                "total_native_tokens_reasoning": 10185585270,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 367375925248,
                "total_tool_calls": 5340703,
                "requests_with_tool_call_errors": 7979
            },
            "google/gemma-3-12b-it:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-12b-it",
                "variant": "free",
                "variant_permaslug": "google/gemma-3-12b-it:free",
                "count": 35059,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 28273643,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 10141,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/o4-mini-deep-research-2025-06-26": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o4-mini-deep-research-2025-06-26",
                "variant": "standard",
                "variant_permaslug": "openai/o4-mini-deep-research-2025-06-26",
                "count": 1506,
                "total_completion_tokens": 14011713,
                "total_prompt_tokens": 34310906,
                "total_native_tokens_reasoning": 12946747,
                "num_media_prompt": 78,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 976000,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-4-maverick-17b-128e-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-4-maverick-17b-128e-instruct",
                "count": 8753680,
                "total_completion_tokens": 916107328,
                "total_prompt_tokens": 17053284210,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1304522,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 233849968,
                "total_tool_calls": 579889,
                "requests_with_tool_call_errors": 772
            },
            "google/gemma-3-12b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-12b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-3-12b-it",
                "count": 5352434,
                "total_completion_tokens": 759719363,
                "total_prompt_tokens": 3627023068,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2557509,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 608920515,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-small-3.1-24b-instruct-2503:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503",
                "variant": "free",
                "variant_permaslug": "mistralai/mistral-small-3.1-24b-instruct-2503:free",
                "count": 79911,
                "total_completion_tokens": 47941364,
                "total_prompt_tokens": 403568556,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 30,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 602,
                "requests_with_tool_call_errors": 580
            },
            "openai/gpt-5-mini-2025-08-07": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-mini-2025-08-07",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-mini-2025-08-07",
                "count": 9758484,
                "total_completion_tokens": 7739630221,
                "total_prompt_tokens": 39134627357,
                "total_native_tokens_reasoning": 4971282533,
                "num_media_prompt": 1434198,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 11985320832,
                "total_tool_calls": 1394981,
                "requests_with_tool_call_errors": 3585
            },
            "amazon/nova-premier-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "amazon/nova-premier-v1",
                "variant": "standard",
                "variant_permaslug": "amazon/nova-premier-v1",
                "count": 5186,
                "total_completion_tokens": 600976,
                "total_prompt_tokens": 11583320,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 144,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 77,
                "requests_with_tool_call_errors": 1
            },
            "tngtech/tng-r1t-chimera": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/tng-r1t-chimera",
                "variant": "standard",
                "variant_permaslug": "tngtech/tng-r1t-chimera",
                "count": 21569,
                "total_completion_tokens": 14348689,
                "total_prompt_tokens": 85573094,
                "total_native_tokens_reasoning": 11048369,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 36362752,
                "total_tool_calls": 27,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/codestral-2508": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/codestral-2508",
                "variant": "standard",
                "variant_permaslug": "mistralai/codestral-2508",
                "count": 1629320,
                "total_completion_tokens": 262366365,
                "total_prompt_tokens": 4905477081,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1371,
                "requests_with_tool_call_errors": 16
            },
            "google/gemma-3n-e2b-it:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3n-e2b-it",
                "variant": "free",
                "variant_permaslug": "google/gemma-3n-e2b-it:free",
                "count": 82340,
                "total_completion_tokens": 34118187,
                "total_prompt_tokens": 25559377,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nvidia/nemotron-3-nano-30b-a3b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
                "variant": "standard",
                "variant_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
                "count": 304166,
                "total_completion_tokens": 1206596378,
                "total_prompt_tokens": 1446189675,
                "total_native_tokens_reasoning": 1143379513,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 31799,
                "requests_with_tool_call_errors": 16024
            },
            "relace/relace-apply-3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "relace/relace-apply-3",
                "variant": "standard",
                "variant_permaslug": "relace/relace-apply-3",
                "count": 9651,
                "total_completion_tokens": 12847690,
                "total_prompt_tokens": 17400548,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nvidia/llama-3.3-nemotron-super-49b-v1.5": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
                "variant": "standard",
                "variant_permaslug": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
                "count": 118589,
                "total_completion_tokens": 73169510,
                "total_prompt_tokens": 495144930,
                "total_native_tokens_reasoning": 65005718,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 511,
                "requests_with_tool_call_errors": 46
            },
            "nvidia/nemotron-nano-12b-v2-vl": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
                "variant": "standard",
                "variant_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
                "count": 9042,
                "total_completion_tokens": 4878983,
                "total_prompt_tokens": 19160734,
                "total_native_tokens_reasoning": 4016531,
                "num_media_prompt": 10932,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "z-ai/glm-4.6": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.6",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.6",
                "count": 3447753,
                "total_completion_tokens": 1583444508,
                "total_prompt_tokens": 22905565706,
                "total_native_tokens_reasoning": 791948454,
                "num_media_prompt": 7013,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6019529788,
                "total_tool_calls": 225979,
                "requests_with_tool_call_errors": 36885
            },
            "thedrummer/skyfall-36b-v2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thedrummer/skyfall-36b-v2",
                "variant": "standard",
                "variant_permaslug": "thedrummer/skyfall-36b-v2",
                "count": 644309,
                "total_completion_tokens": 186622214,
                "total_prompt_tokens": 1619897324,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 893381040,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "perplexity/sonar-pro-search": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "perplexity/sonar-pro-search",
                "variant": "standard",
                "variant_permaslug": "perplexity/sonar-pro-search",
                "count": 64508,
                "total_completion_tokens": 26231522,
                "total_prompt_tokens": 114826192,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1946,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 761,
                "requests_with_tool_call_errors": 0
            },
            "raifle/sorcererlm-8x22b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "raifle/sorcererlm-8x22b",
                "variant": "standard",
                "variant_permaslug": "raifle/sorcererlm-8x22b",
                "count": 3378,
                "total_completion_tokens": 596949,
                "total_prompt_tokens": 8609000,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.1-405b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.1-405b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.1-405b-instruct",
                "count": 472683,
                "total_completion_tokens": 52729332,
                "total_prompt_tokens": 503401407,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 57,
                "requests_with_tool_call_errors": 8
            },
            "aion-labs/aion-rp-llama-3.1-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "aion-labs/aion-rp-llama-3.1-8b",
                "variant": "standard",
                "variant_permaslug": "aion-labs/aion-rp-llama-3.1-8b",
                "count": 54481,
                "total_completion_tokens": 5072781,
                "total_prompt_tokens": 67917084,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sao10k/l3.1-euryale-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sao10k/l3.1-euryale-70b",
                "variant": "standard",
                "variant_permaslug": "sao10k/l3.1-euryale-70b",
                "count": 155343,
                "total_completion_tokens": 20421685,
                "total_prompt_tokens": 489238156,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-14b-04-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-14b-04-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-14b-04-28",
                "count": 4451197,
                "total_completion_tokens": 1625959239,
                "total_prompt_tokens": 8609535857,
                "total_native_tokens_reasoning": 326781046,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1405338288,
                "total_tool_calls": 6322,
                "requests_with_tool_call_errors": 284
            },
            "nvidia/llama-3.1-nemotron-70b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
                "variant": "standard",
                "variant_permaslug": "nvidia/llama-3.1-nemotron-70b-instruct",
                "count": 69231,
                "total_completion_tokens": 12342416,
                "total_prompt_tokens": 66321610,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 6,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 80,
                "requests_with_tool_call_errors": 10
            },
            "qwen/qwen3-max": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-max",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-max",
                "count": 240701,
                "total_completion_tokens": 113773693,
                "total_prompt_tokens": 1373502797,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 63,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 153922902,
                "total_tool_calls": 17286,
                "requests_with_tool_call_errors": 1099
            },
            "baidu/ernie-4.5-300b-a47b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baidu/ernie-4.5-300b-a47b",
                "variant": "standard",
                "variant_permaslug": "baidu/ernie-4.5-300b-a47b",
                "count": 62490,
                "total_completion_tokens": 11722827,
                "total_prompt_tokens": 147582874,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4585344,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-r1-distill-qwen-14b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1-distill-qwen-14b",
                "count": 32555,
                "total_completion_tokens": 27562811,
                "total_prompt_tokens": 36864156,
                "total_native_tokens_reasoning": 19140819,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "z-ai/glm-4.6-20251208": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.6-20251208",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.6-20251208",
                "count": 308653,
                "total_completion_tokens": 794547774,
                "total_prompt_tokens": 3236293465,
                "total_native_tokens_reasoning": 586650657,
                "num_media_prompt": 293844,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1175855146,
                "total_tool_calls": 86978,
                "requests_with_tool_call_errors": 18469
            },
            "openai/gpt-5.2-chat-20251211": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.2-chat-20251211",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.2-chat-20251211",
                "count": 723944,
                "total_completion_tokens": 303916930,
                "total_prompt_tokens": 4687472199,
                "total_native_tokens_reasoning": 38133568,
                "num_media_prompt": 235841,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2143276672,
                "total_tool_calls": 61239,
                "requests_with_tool_call_errors": 4601
            },
            "black-forest-labs/flux.2-max": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "black-forest-labs/flux.2-max",
                "variant": "standard",
                "variant_permaslug": "black-forest-labs/flux.2-max",
                "count": 4003,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 10303940,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3230,
                "num_media_completion": 4003,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-embedding-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-embedding-8b",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-embedding-8b",
                "count": 7674300,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 11542334200,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "arcee-ai/trinity-mini-20251201": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "arcee-ai/trinity-mini-20251201",
                "variant": "standard",
                "variant_permaslug": "arcee-ai/trinity-mini-20251201",
                "count": 56890,
                "total_completion_tokens": 28394481,
                "total_prompt_tokens": 51705565,
                "total_native_tokens_reasoning": 22713780,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 264,
                "requests_with_tool_call_errors": 59
            },
            "qwen/qwen2.5-coder-7b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen2.5-coder-7b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen2.5-coder-7b-instruct",
                "count": 32671,
                "total_completion_tokens": 17456238,
                "total_prompt_tokens": 47833777,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-2.5-coder-32b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-2.5-coder-32b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-2.5-coder-32b-instruct",
                "count": 780684,
                "total_completion_tokens": 274778057,
                "total_prompt_tokens": 857388077,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 131202019,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4o-search-preview-2025-03-11": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-search-preview-2025-03-11",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-search-preview-2025-03-11",
                "count": 21849,
                "total_completion_tokens": 10406846,
                "total_prompt_tokens": 39562718,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-5.1-chat-20251113": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.1-chat-20251113",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.1-chat-20251113",
                "count": 344408,
                "total_completion_tokens": 61925801,
                "total_prompt_tokens": 2422046910,
                "total_native_tokens_reasoning": 7445056,
                "num_media_prompt": 84432,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 957078400,
                "total_tool_calls": 36457,
                "requests_with_tool_call_errors": 331
            },
            "anthropic/claude-4.5-sonnet-20250929": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4.5-sonnet-20250929",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4.5-sonnet-20250929",
                "count": 15058696,
                "total_completion_tokens": 8874309019,
                "total_prompt_tokens": 396975646302,
                "total_native_tokens_reasoning": 407332194,
                "num_media_prompt": 5077198,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 185258803635,
                "total_tool_calls": 4058012,
                "requests_with_tool_call_errors": 136648
            },
            "z-ai/glm-4.6:exacto": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.6",
                "variant": "exacto",
                "variant_permaslug": "z-ai/glm-4.6:exacto",
                "count": 93967,
                "total_completion_tokens": 29467364,
                "total_prompt_tokens": 711550882,
                "total_native_tokens_reasoning": 19424567,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 260550907,
                "total_tool_calls": 19043,
                "requests_with_tool_call_errors": 9414
            },
            "cohere/command-r-plus-08-2024": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "cohere/command-r-plus-08-2024",
                "variant": "standard",
                "variant_permaslug": "cohere/command-r-plus-08-2024",
                "count": 68850,
                "total_completion_tokens": 4958142,
                "total_prompt_tokens": 145671864,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 14062,
                "requests_with_tool_call_errors": 1367
            },
            "qwen/qwen3-coder-plus": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-plus",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-coder-plus",
                "count": 71078,
                "total_completion_tokens": 17649305,
                "total_prompt_tokens": 590394030,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 353541637,
                "total_tool_calls": 12792,
                "requests_with_tool_call_errors": 191
            },
            "mistralai/mistral-small-creative-20251216": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-small-creative-20251216",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-small-creative-20251216",
                "count": 440575,
                "total_completion_tokens": 209933656,
                "total_prompt_tokens": 2520722951,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1642,
                "requests_with_tool_call_errors": 56
            },
            "meta-llama/llama-3.1-405b-instruct:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.1-405b-instruct",
                "variant": "free",
                "variant_permaslug": "meta-llama/llama-3.1-405b-instruct:free",
                "count": 143002,
                "total_completion_tokens": 31914550,
                "total_prompt_tokens": 549897686,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 18,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-large-2411": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-large-2411",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-large-2411",
                "count": 69671,
                "total_completion_tokens": 19595920,
                "total_prompt_tokens": 223278846,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 3215,
                "requests_with_tool_call_errors": 52
            },
            "nousresearch/hermes-3-llama-3.1-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-3-llama-3.1-70b",
                "variant": "standard",
                "variant_permaslug": "nousresearch/hermes-3-llama-3.1-70b",
                "count": 463127,
                "total_completion_tokens": 85368565,
                "total_prompt_tokens": 694559003,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "essentialai/rnj-1-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "essentialai/rnj-1-instruct",
                "variant": "standard",
                "variant_permaslug": "essentialai/rnj-1-instruct",
                "count": 46696,
                "total_completion_tokens": 3156540,
                "total_prompt_tokens": 10492226,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "x-ai/grok-4.1-fast": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-4.1-fast",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-4.1-fast",
                "count": 34146697,
                "total_completion_tokens": 28620028036,
                "total_prompt_tokens": 192356867660,
                "total_native_tokens_reasoning": 19733586048,
                "num_media_prompt": 5138497,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 50974439306,
                "total_tool_calls": 1981620,
                "requests_with_tool_call_errors": 8908
            },
            "anthropic/claude-4.1-opus-20250805": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-4.1-opus-20250805",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-4.1-opus-20250805",
                "count": 67030,
                "total_completion_tokens": 34318255,
                "total_prompt_tokens": 781565562,
                "total_native_tokens_reasoning": 1957108,
                "num_media_prompt": 5926,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 276530011,
                "total_tool_calls": 7837,
                "requests_with_tool_call_errors": 161
            },
            "z-ai/glm-4.5-air:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.5-air",
                "variant": "free",
                "variant_permaslug": "z-ai/glm-4.5-air:free",
                "count": 588198,
                "total_completion_tokens": 484936293,
                "total_prompt_tokens": 5520336479,
                "total_native_tokens_reasoning": 249790151,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2506738576,
                "total_tool_calls": 35954,
                "requests_with_tool_call_errors": 2393
            },
            "mistralai/mistral-embed-2312": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-embed-2312",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-embed-2312",
                "count": 70657,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 226140730,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-5.1-codex-20251113": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.1-codex-20251113",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.1-codex-20251113",
                "count": 240833,
                "total_completion_tokens": 138894649,
                "total_prompt_tokens": 10309435048,
                "total_native_tokens_reasoning": 83153670,
                "num_media_prompt": 21214,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 9003703168,
                "total_tool_calls": 175002,
                "requests_with_tool_call_errors": 1321
            },
            "qwen/qwen3-coder-flash": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-flash",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-coder-flash",
                "count": 41730,
                "total_completion_tokens": 9501982,
                "total_prompt_tokens": 264240199,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 188834688,
                "total_tool_calls": 6126,
                "requests_with_tool_call_errors": 784
            },
            "deepseek/deepseek-v3.2-20251201": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-v3.2-20251201",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-v3.2-20251201",
                "count": 49466016,
                "total_completion_tokens": 24241820497,
                "total_prompt_tokens": 339015498794,
                "total_native_tokens_reasoning": 4214344381,
                "num_media_prompt": 837,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 160729242496,
                "total_tool_calls": 1259928,
                "requests_with_tool_call_errors": 29669
            },
            "mistralai/mistral-saba-2502": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-saba-2502",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-saba-2502",
                "count": 49541,
                "total_completion_tokens": 3671805,
                "total_prompt_tokens": 15951854,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 15,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-coder-480b-a35b-07-25:exacto": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-480b-a35b-07-25",
                "variant": "exacto",
                "variant_permaslug": "qwen/qwen3-coder-480b-a35b-07-25:exacto",
                "count": 23428,
                "total_completion_tokens": 6138198,
                "total_prompt_tokens": 1408492645,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 19242,
                "requests_with_tool_call_errors": 775
            },
            "cohere/command-a-03-2025": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "cohere/command-a-03-2025",
                "variant": "standard",
                "variant_permaslug": "cohere/command-a-03-2025",
                "count": 56833,
                "total_completion_tokens": 4499920,
                "total_prompt_tokens": 20360325,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-3.5-turbo-0613": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-3.5-turbo-0613",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-3.5-turbo-0613",
                "count": 404337,
                "total_completion_tokens": 75655316,
                "total_prompt_tokens": 116639772,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 293888,
                "total_tool_calls": 850,
                "requests_with_tool_call_errors": 5
            },
            "openai/gpt-4-turbo": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4-turbo",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4-turbo",
                "count": 52062,
                "total_completion_tokens": 8845114,
                "total_prompt_tokens": 140230644,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3753,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 7557,
                "requests_with_tool_call_errors": 37
            },
            "z-ai/glm-4.5": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.5",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.5",
                "count": 278418,
                "total_completion_tokens": 349866446,
                "total_prompt_tokens": 2995983804,
                "total_native_tokens_reasoning": 175227160,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1477820072,
                "total_tool_calls": 41038,
                "requests_with_tool_call_errors": 3140
            },
            "thenlper/gte-base-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thenlper/gte-base-20251117",
                "variant": "standard",
                "variant_permaslug": "thenlper/gte-base-20251117",
                "count": 32274,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 161359172,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepcogito/cogito-v2-preview-llama-405b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepcogito/cogito-v2-preview-llama-405b",
                "variant": "standard",
                "variant_permaslug": "deepcogito/cogito-v2-preview-llama-405b",
                "count": 3364,
                "total_completion_tokens": 568398,
                "total_prompt_tokens": 11227027,
                "total_native_tokens_reasoning": 3662,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 22,
                "requests_with_tool_call_errors": 0
            },
            "baidu/ernie-4.5-21b-a3b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baidu/ernie-4.5-21b-a3b",
                "variant": "standard",
                "variant_permaslug": "baidu/ernie-4.5-21b-a3b",
                "count": 37652,
                "total_completion_tokens": 4070103,
                "total_prompt_tokens": 21229463,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "anthropic/claude-3-haiku": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3-haiku",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-3-haiku",
                "count": 1384917,
                "total_completion_tokens": 398582999,
                "total_prompt_tokens": 2128435304,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 23995,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 36711718,
                "total_tool_calls": 107120,
                "requests_with_tool_call_errors": 2153
            },
            "openai/gpt-5-chat-2025-08-07": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-chat-2025-08-07",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-chat-2025-08-07",
                "count": 1910074,
                "total_completion_tokens": 424746449,
                "total_prompt_tokens": 8552504507,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 172867,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4723794304,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-embedding-4b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-embedding-4b",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-embedding-4b",
                "count": 802287,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 1288795539,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-oss-120b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-120b",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-oss-120b",
                "count": 25459844,
                "total_completion_tokens": 14675952023,
                "total_prompt_tokens": 94920832911,
                "total_native_tokens_reasoning": 9951348918,
                "num_media_prompt": 894,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 23270957718,
                "total_tool_calls": 943148,
                "requests_with_tool_call_errors": 121357
            },
            "mistralai/mistral-7b-instruct:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-7b-instruct",
                "variant": "free",
                "variant_permaslug": "mistralai/mistral-7b-instruct:free",
                "count": 217611,
                "total_completion_tokens": 51201906,
                "total_prompt_tokens": 457845982,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/pixtral-large-2411": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/pixtral-large-2411",
                "variant": "standard",
                "variant_permaslug": "mistralai/pixtral-large-2411",
                "count": 7552,
                "total_completion_tokens": 2840882,
                "total_prompt_tokens": 22240484,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 5147,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 163,
                "requests_with_tool_call_errors": 3
            },
            "tngtech/deepseek-r1t2-chimera:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/deepseek-r1t2-chimera",
                "variant": "free",
                "variant_permaslug": "tngtech/deepseek-r1t2-chimera:free",
                "count": 8279259,
                "total_completion_tokens": 7317258386,
                "total_prompt_tokens": 78970802844,
                "total_native_tokens_reasoning": 4182032196,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 8327976930,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "baidu/ernie-4.5-21b-a3b-thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baidu/ernie-4.5-21b-a3b-thinking",
                "variant": "standard",
                "variant_permaslug": "baidu/ernie-4.5-21b-a3b-thinking",
                "count": 13422,
                "total_completion_tokens": 29594625,
                "total_prompt_tokens": 29198668,
                "total_native_tokens_reasoning": 25705261,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "gryphe/mythomax-l2-13b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "gryphe/mythomax-l2-13b",
                "variant": "standard",
                "variant_permaslug": "gryphe/mythomax-l2-13b",
                "count": 1442994,
                "total_completion_tokens": 192874742,
                "total_prompt_tokens": 1605512985,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "eleutherai/llemma_7b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "eleutherai/llemma_7b",
                "variant": "standard",
                "variant_permaslug": "eleutherai/llemma_7b",
                "count": 1205,
                "total_completion_tokens": 1486404,
                "total_prompt_tokens": 166056,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sao10k/l3.3-euryale-70b-v2.3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sao10k/l3.3-euryale-70b-v2.3",
                "variant": "standard",
                "variant_permaslug": "sao10k/l3.3-euryale-70b-v2.3",
                "count": 217415,
                "total_completion_tokens": 24875225,
                "total_prompt_tokens": 450497188,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "inflection/inflection-3-productivity": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "inflection/inflection-3-productivity",
                "variant": "standard",
                "variant_permaslug": "inflection/inflection-3-productivity",
                "count": 1713,
                "total_completion_tokens": 294901,
                "total_prompt_tokens": 2086611,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "moonshotai/kimi-k2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-k2",
                "variant": "standard",
                "variant_permaslug": "moonshotai/kimi-k2",
                "count": 851546,
                "total_completion_tokens": 179799289,
                "total_prompt_tokens": 3709924304,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 8,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1636953109,
                "total_tool_calls": 38628,
                "requests_with_tool_call_errors": 589
            },
            "openai/o3-mini-2025-01-31": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o3-mini-2025-01-31",
                "variant": "standard",
                "variant_permaslug": "openai/o3-mini-2025-01-31",
                "count": 207408,
                "total_completion_tokens": 341280433,
                "total_prompt_tokens": 403543437,
                "total_native_tokens_reasoning": 233836736,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 97847296,
                "total_tool_calls": 2744,
                "requests_with_tool_call_errors": 13
            },
            "cohere/command-r7b-12-2024": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "cohere/command-r7b-12-2024",
                "variant": "standard",
                "variant_permaslug": "cohere/command-r7b-12-2024",
                "count": 126419,
                "total_completion_tokens": 12263875,
                "total_prompt_tokens": 307568659,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-2.5-7b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-2.5-7b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-2.5-7b-instruct",
                "count": 8009041,
                "total_completion_tokens": 948050448,
                "total_prompt_tokens": 4699095746,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-2.0-flash-001": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.0-flash-001",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.0-flash-001",
                "count": 126989741,
                "total_completion_tokens": 22514497844,
                "total_prompt_tokens": 142164314460,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 9457523,
                "num_media_completion": 0,
                "num_audio_prompt": 29700,
                "total_native_tokens_cached": 472819910,
                "total_tool_calls": 1515897,
                "requests_with_tool_call_errors": 24893
            },
            "mistralai/mistral-7b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-7b-instruct",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-7b-instruct",
                "count": 706656,
                "total_completion_tokens": 68188553,
                "total_prompt_tokens": 503738684,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 17,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-5-2025-08-07": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-2025-08-07",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-2025-08-07",
                "count": 2290200,
                "total_completion_tokens": 2613118277,
                "total_prompt_tokens": 18708787834,
                "total_native_tokens_reasoning": 1948477876,
                "num_media_prompt": 2211650,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 10482254592,
                "total_tool_calls": 450449,
                "requests_with_tool_call_errors": 1502
            },
            "thedrummer/unslopnemo-12b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thedrummer/unslopnemo-12b",
                "variant": "standard",
                "variant_permaslug": "thedrummer/unslopnemo-12b",
                "count": 476007,
                "total_completion_tokens": 76495464,
                "total_prompt_tokens": 1395688671,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/o3-deep-research-2025-06-26": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o3-deep-research-2025-06-26",
                "variant": "standard",
                "variant_permaslug": "openai/o3-deep-research-2025-06-26",
                "count": 1051,
                "total_completion_tokens": 8105342,
                "total_prompt_tokens": 18921151,
                "total_native_tokens_reasoning": 6827401,
                "num_media_prompt": 163,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1529216,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/text-embedding-3-small": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/text-embedding-3-small",
                "variant": "standard",
                "variant_permaslug": "openai/text-embedding-3-small",
                "count": 8928218,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 18517834325,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "baidu/ernie-4.5-vl-424b-a47b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baidu/ernie-4.5-vl-424b-a47b",
                "variant": "standard",
                "variant_permaslug": "baidu/ernie-4.5-vl-424b-a47b",
                "count": 6493,
                "total_completion_tokens": 1974419,
                "total_prompt_tokens": 22877256,
                "total_native_tokens_reasoning": 90662,
                "num_media_prompt": 929,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "undi95/remm-slerp-l2-13b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "undi95/remm-slerp-l2-13b",
                "variant": "standard",
                "variant_permaslug": "undi95/remm-slerp-l2-13b",
                "count": 243582,
                "total_completion_tokens": 21514938,
                "total_prompt_tokens": 321812936,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-vl-plus": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-vl-plus",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-vl-plus",
                "count": 30064,
                "total_completion_tokens": 12101503,
                "total_prompt_tokens": 57674990,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 28332,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4",
                "count": 55804,
                "total_completion_tokens": 10379000,
                "total_prompt_tokens": 47931220,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2083200,
                "total_tool_calls": 2027,
                "requests_with_tool_call_errors": 214
            },
            "allenai/olmo-3-7b-think-20251121": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "allenai/olmo-3-7b-think-20251121",
                "variant": "standard",
                "variant_permaslug": "allenai/olmo-3-7b-think-20251121",
                "count": 55976,
                "total_completion_tokens": 48087610,
                "total_prompt_tokens": 29621432,
                "total_native_tokens_reasoning": 48855506,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 7972112,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "baai/bge-m3-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baai/bge-m3-20251117",
                "variant": "standard",
                "variant_permaslug": "baai/bge-m3-20251117",
                "count": 1169881,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 777864132,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-3-pro-preview-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-3-pro-preview-20251117",
                "variant": "standard",
                "variant_permaslug": "google/gemini-3-pro-preview-20251117",
                "count": 6987827,
                "total_completion_tokens": 15651814051,
                "total_prompt_tokens": 107629333917,
                "total_native_tokens_reasoning": 10247375984,
                "num_media_prompt": 2359292,
                "num_media_completion": 0,
                "num_audio_prompt": 587979,
                "total_native_tokens_cached": 51602109957,
                "total_tool_calls": 909890,
                "requests_with_tool_call_errors": 34108
            },
            "allenai/olmo-2-0325-32b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "allenai/olmo-2-0325-32b-instruct",
                "variant": "standard",
                "variant_permaslug": "allenai/olmo-2-0325-32b-instruct",
                "count": 1857,
                "total_completion_tokens": 620910,
                "total_prompt_tokens": 3256363,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-large": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-large",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-large",
                "count": 142264,
                "total_completion_tokens": 24836538,
                "total_prompt_tokens": 307772750,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1555,
                "requests_with_tool_call_errors": 28
            },
            "microsoft/wizardlm-2-8x22b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/wizardlm-2-8x22b",
                "variant": "standard",
                "variant_permaslug": "microsoft/wizardlm-2-8x22b",
                "count": 632855,
                "total_completion_tokens": 127623956,
                "total_prompt_tokens": 1620782805,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-guard-4-12b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-guard-4-12b",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-guard-4-12b",
                "count": 2677658,
                "total_completion_tokens": 10587203,
                "total_prompt_tokens": 984484386,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 125,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-235b-a22b-thinking-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-235b-a22b-thinking-2507",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-235b-a22b-thinking-2507",
                "count": 447206,
                "total_completion_tokens": 702181743,
                "total_prompt_tokens": 1982242585,
                "total_native_tokens_reasoning": 546821887,
                "num_media_prompt": 76,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 330588422,
                "total_tool_calls": 78664,
                "requests_with_tool_call_errors": 15194
            },
            "sentence-transformers/all-minilm-l6-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sentence-transformers/all-minilm-l6-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "sentence-transformers/all-minilm-l6-v2-20251117",
                "count": 38761,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 106907746,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-large-2512": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-large-2512",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-large-2512",
                "count": 532398,
                "total_completion_tokens": 201056367,
                "total_prompt_tokens": 1912450020,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 120224,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 6737,
                "requests_with_tool_call_errors": 273
            },
            "qwen/qwen-2-vl-7b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-2-vl-7b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-2-vl-7b-instruct",
                "count": 113322,
                "total_completion_tokens": 7486778,
                "total_prompt_tokens": 88370077,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 105238,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/codestral-embed-2505": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/codestral-embed-2505",
                "variant": "standard",
                "variant_permaslug": "mistralai/codestral-embed-2505",
                "count": 118888,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 278458771,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/ministral-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/ministral-8b",
                "variant": "standard",
                "variant_permaslug": "mistralai/ministral-8b",
                "count": 876948,
                "total_completion_tokens": 253619088,
                "total_prompt_tokens": 398000820,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1252,
                "requests_with_tool_call_errors": 134
            },
            "qwen/qwen3-32b-04-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-32b-04-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-32b-04-28",
                "count": 9497717,
                "total_completion_tokens": 1471913634,
                "total_prompt_tokens": 8644392255,
                "total_native_tokens_reasoning": 1153767239,
                "num_media_prompt": 3,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 927729906,
                "total_tool_calls": 181681,
                "requests_with_tool_call_errors": 1057
            },
            "google/gemma-3-27b-it:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-27b-it",
                "variant": "free",
                "variant_permaslug": "google/gemma-3-27b-it:free",
                "count": 700296,
                "total_completion_tokens": 564087225,
                "total_prompt_tokens": 3066525477,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 84995,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 997,
                "requests_with_tool_call_errors": 50
            },
            "openai/o3-2025-04-16": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o3-2025-04-16",
                "variant": "standard",
                "variant_permaslug": "openai/o3-2025-04-16",
                "count": 157013,
                "total_completion_tokens": 92842204,
                "total_prompt_tokens": 456048613,
                "total_native_tokens_reasoning": 59322904,
                "num_media_prompt": 8047,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 135067648,
                "total_tool_calls": 13975,
                "requests_with_tool_call_errors": 9
            },
            "black-forest-labs/flux.2-flex": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "black-forest-labs/flux.2-flex",
                "variant": "standard",
                "variant_permaslug": "black-forest-labs/flux.2-flex",
                "count": 1504,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 5316253,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 588,
                "num_media_completion": 1504,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4.1-2025-04-14": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4.1-2025-04-14",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4.1-2025-04-14",
                "count": 5989674,
                "total_completion_tokens": 1363519054,
                "total_prompt_tokens": 23358841703,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 627513,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 8926827136,
                "total_tool_calls": 513088,
                "requests_with_tool_call_errors": 4399
            },
            "google/gemma-3-27b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-27b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-3-27b-it",
                "count": 10726151,
                "total_completion_tokens": 2918386448,
                "total_prompt_tokens": 18893949137,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3429733,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1736670912,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-vl-235b-a22b-thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-235b-a22b-thinking",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-235b-a22b-thinking",
                "count": 396845,
                "total_completion_tokens": 556747383,
                "total_prompt_tokens": 2697121175,
                "total_native_tokens_reasoning": 416891784,
                "num_media_prompt": 1528521,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2625687,
                "total_tool_calls": 227,
                "requests_with_tool_call_errors": 22
            },
            "openai/gpt-4-0314": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4-0314",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4-0314",
                "count": 1753,
                "total_completion_tokens": 161586,
                "total_prompt_tokens": 795444,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nousresearch/hermes-3-llama-3.1-405b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
                "variant": "standard",
                "variant_permaslug": "nousresearch/hermes-3-llama-3.1-405b",
                "count": 384137,
                "total_completion_tokens": 71734114,
                "total_prompt_tokens": 997498834,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-guard-3-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-guard-3-8b",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-guard-3-8b",
                "count": 296642,
                "total_completion_tokens": 4869145,
                "total_prompt_tokens": 185736916,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nvidia/nemotron-nano-9b-v2:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-nano-9b-v2",
                "variant": "free",
                "variant_permaslug": "nvidia/nemotron-nano-9b-v2:free",
                "count": 61198,
                "total_completion_tokens": 58347619,
                "total_prompt_tokens": 267842441,
                "total_native_tokens_reasoning": 45525829,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 3159,
                "requests_with_tool_call_errors": 629
            },
            "moonshotai/kimi-k2-0905:exacto": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-k2-0905",
                "variant": "exacto",
                "variant_permaslug": "moonshotai/kimi-k2-0905:exacto",
                "count": 292108,
                "total_completion_tokens": 240387966,
                "total_prompt_tokens": 2063822130,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1262230890,
                "total_tool_calls": 16479,
                "requests_with_tool_call_errors": 73
            },
            "google/gemini-2.0-flash-exp:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.0-flash-exp",
                "variant": "free",
                "variant_permaslug": "google/gemini-2.0-flash-exp:free",
                "count": 197195,
                "total_completion_tokens": 85412505,
                "total_prompt_tokens": 1277365051,
                "total_native_tokens_reasoning": 31,
                "num_media_prompt": 69310,
                "num_media_completion": 157,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 3201,
                "requests_with_tool_call_errors": 214
            },
            "thenlper/gte-large-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thenlper/gte-large-20251117",
                "variant": "standard",
                "variant_permaslug": "thenlper/gte-large-20251117",
                "count": 7771,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 29308996,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "thedrummer/cydonia-24b-v4.1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thedrummer/cydonia-24b-v4.1",
                "variant": "standard",
                "variant_permaslug": "thedrummer/cydonia-24b-v4.1",
                "count": 267501,
                "total_completion_tokens": 55956216,
                "total_prompt_tokens": 1035154432,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 540093776,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-v3.1-terminus:exacto": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-v3.1-terminus",
                "variant": "exacto",
                "variant_permaslug": "deepseek/deepseek-v3.1-terminus:exacto",
                "count": 318152,
                "total_completion_tokens": 165773290,
                "total_prompt_tokens": 3944713146,
                "total_native_tokens_reasoning": 78263641,
                "num_media_prompt": 45,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 36624907,
                "total_tool_calls": 82508,
                "requests_with_tool_call_errors": 1343
            },
            "google/gemma-2-9b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-2-9b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-2-9b-it",
                "count": 1482836,
                "total_completion_tokens": 402005709,
                "total_prompt_tokens": 940406128,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "z-ai/glm-4.5v": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.5v",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.5v",
                "count": 32428,
                "total_completion_tokens": 13260780,
                "total_prompt_tokens": 73106042,
                "total_native_tokens_reasoning": 8881417,
                "num_media_prompt": 8001,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 9463246,
                "total_tool_calls": 262,
                "requests_with_tool_call_errors": 51
            },
            "google/gemini-2.5-flash-lite": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash-lite",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash-lite",
                "count": 78550493,
                "total_completion_tokens": 25078389904,
                "total_prompt_tokens": 165707275839,
                "total_native_tokens_reasoning": 1260635951,
                "num_media_prompt": 125786717,
                "num_media_completion": 0,
                "num_audio_prompt": 622559,
                "total_native_tokens_cached": 24738446782,
                "total_tool_calls": 761367,
                "requests_with_tool_call_errors": 37430
            },
            "qwen/qwen2.5-vl-72b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen2.5-vl-72b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen2.5-vl-72b-instruct",
                "count": 1164061,
                "total_completion_tokens": 148010419,
                "total_prompt_tokens": 2637088257,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1037179,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 130734144,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemma-3n-e4b-it:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3n-e4b-it",
                "variant": "free",
                "variant_permaslug": "google/gemma-3n-e4b-it:free",
                "count": 31557,
                "total_completion_tokens": 10315693,
                "total_prompt_tokens": 14002573,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "stepfun-ai/step3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "stepfun-ai/step3",
                "variant": "standard",
                "variant_permaslug": "stepfun-ai/step3",
                "count": 1128,
                "total_completion_tokens": 2105190,
                "total_prompt_tokens": 5562117,
                "total_native_tokens_reasoning": 1540102,
                "num_media_prompt": 152,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-2.5-flash-image": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash-image",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash-image",
                "count": 1124009,
                "total_completion_tokens": 1191897870,
                "total_prompt_tokens": 1273235770,
                "total_native_tokens_reasoning": 17874,
                "num_media_prompt": 1038630,
                "num_media_completion": 896681,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nvidia/nemotron-3-nano-30b-a3b:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-3-nano-30b-a3b",
                "variant": "free",
                "variant_permaslug": "nvidia/nemotron-3-nano-30b-a3b:free",
                "count": 2832178,
                "total_completion_tokens": 4319080885,
                "total_prompt_tokens": 8683504234,
                "total_native_tokens_reasoning": 2394886467,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 159579,
                "requests_with_tool_call_errors": 10000
            },
            "neversleep/llama-3.1-lumimaid-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "neversleep/llama-3.1-lumimaid-8b",
                "variant": "standard",
                "variant_permaslug": "neversleep/llama-3.1-lumimaid-8b",
                "count": 143894,
                "total_completion_tokens": 9826703,
                "total_prompt_tokens": 184145914,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-vl-max-2025-01-25": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-vl-max-2025-01-25",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-vl-max-2025-01-25",
                "count": 53751,
                "total_completion_tokens": 21705767,
                "total_prompt_tokens": 142039723,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 51222,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 49,
                "requests_with_tool_call_errors": 5
            },
            "black-forest-labs/flux.2-pro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "black-forest-labs/flux.2-pro",
                "variant": "standard",
                "variant_permaslug": "black-forest-labs/flux.2-pro",
                "count": 12351,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 28884447,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 11315,
                "num_media_completion": 12351,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sentence-transformers/all-minilm-l12-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sentence-transformers/all-minilm-l12-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "sentence-transformers/all-minilm-l12-v2-20251117",
                "count": 570797,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 74571356,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-2.5-pro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-pro",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-pro",
                "count": 9403603,
                "total_completion_tokens": 15563867727,
                "total_prompt_tokens": 89122339436,
                "total_native_tokens_reasoning": 8891660771,
                "num_media_prompt": 806807,
                "num_media_completion": 0,
                "num_audio_prompt": 20268,
                "total_native_tokens_cached": 28686771654,
                "total_tool_calls": 338716,
                "requests_with_tool_call_errors": 9639
            },
            "meta-llama/llama-3.1-70b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.1-70b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.1-70b-instruct",
                "count": 17246053,
                "total_completion_tokens": 556965242,
                "total_prompt_tokens": 12909201840,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 4852,
                "requests_with_tool_call_errors": 152
            },
            "meta-llama/llama-3-70b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3-70b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3-70b-instruct",
                "count": 767199,
                "total_completion_tokens": 29990111,
                "total_prompt_tokens": 408716364,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 73,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 302,
                "requests_with_tool_call_errors": 91
            },
            "mistralai/mistral-7b-instruct-v0.3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-7b-instruct-v0.3",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-7b-instruct-v0.3",
                "count": 92814,
                "total_completion_tokens": 8180541,
                "total_prompt_tokens": 76725190,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-30b-a3b-thinking-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-30b-a3b-thinking-2507",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-30b-a3b-thinking-2507",
                "count": 314082,
                "total_completion_tokens": 856224527,
                "total_prompt_tokens": 1415398800,
                "total_native_tokens_reasoning": 795013534,
                "num_media_prompt": 40,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1537,
                "requests_with_tool_call_errors": 137
            },
            "openai/gpt-oss-120b:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-120b",
                "variant": "free",
                "variant_permaslug": "openai/gpt-oss-120b:free",
                "count": 159906,
                "total_completion_tokens": 148269993,
                "total_prompt_tokens": 1130288921,
                "total_native_tokens_reasoning": 77755119,
                "num_media_prompt": 4,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 17582,
                "requests_with_tool_call_errors": 1488
            },
            "minimax/minimax-m1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "minimax/minimax-m1",
                "variant": "standard",
                "variant_permaslug": "minimax/minimax-m1",
                "count": 43043,
                "total_completion_tokens": 9852870,
                "total_prompt_tokens": 53539496,
                "total_native_tokens_reasoning": 7956459,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 273,
                "requests_with_tool_call_errors": 34
            },
            "moonshotai/kimi-k2-thinking-20251106": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-k2-thinking-20251106",
                "variant": "standard",
                "variant_permaslug": "moonshotai/kimi-k2-thinking-20251106",
                "count": 778128,
                "total_completion_tokens": 1714836757,
                "total_prompt_tokens": 9987817670,
                "total_native_tokens_reasoning": 1309278439,
                "num_media_prompt": 1701,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4161836266,
                "total_tool_calls": 184340,
                "requests_with_tool_call_errors": 3196
            },
            "sourceful/riverflow-v2-fast-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sourceful/riverflow-v2-fast-preview",
                "variant": "standard",
                "variant_permaslug": "sourceful/riverflow-v2-fast-preview",
                "count": 2991,
                "total_completion_tokens": 12487425,
                "total_prompt_tokens": 16113148,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1720,
                "num_media_completion": 2991,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-chat-v3.1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-chat-v3.1",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-chat-v3.1",
                "count": 22878119,
                "total_completion_tokens": 4031445420,
                "total_prompt_tokens": 87145802606,
                "total_native_tokens_reasoning": 598123145,
                "num_media_prompt": 121,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 8231177313,
                "total_tool_calls": 182550,
                "requests_with_tool_call_errors": 3233
            },
            "minimax/minimax-01": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "minimax/minimax-01",
                "variant": "standard",
                "variant_permaslug": "minimax/minimax-01",
                "count": 298730,
                "total_completion_tokens": 48975462,
                "total_prompt_tokens": 722276547,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 943,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4o:extended": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o",
                "variant": "extended",
                "variant_permaslug": "openai/gpt-4o:extended",
                "count": 1815,
                "total_completion_tokens": 554662,
                "total_prompt_tokens": 3391910,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1,
                "requests_with_tool_call_errors": 0
            },
            "bytedance/ui-tars-1.5-7b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "bytedance/ui-tars-1.5-7b",
                "variant": "standard",
                "variant_permaslug": "bytedance/ui-tars-1.5-7b",
                "count": 47890,
                "total_completion_tokens": 2476665,
                "total_prompt_tokens": 165054554,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 57158,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 44495792,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-plus-2025-01-25": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-plus-2025-01-25",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-plus-2025-01-25",
                "count": 83014,
                "total_completion_tokens": 16404454,
                "total_prompt_tokens": 279690159,
                "total_native_tokens_reasoning": 40416,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 185542259,
                "total_tool_calls": 2317,
                "requests_with_tool_call_errors": 85
            },
            "openai/o4-mini-2025-04-16": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o4-mini-2025-04-16",
                "variant": "standard",
                "variant_permaslug": "openai/o4-mini-2025-04-16",
                "count": 302294,
                "total_completion_tokens": 222318718,
                "total_prompt_tokens": 956478885,
                "total_native_tokens_reasoning": 181467072,
                "num_media_prompt": 158311,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 360161408,
                "total_tool_calls": 28361,
                "requests_with_tool_call_errors": 23
            },
            "allenai/olmo-3-7b-instruct-20251121": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "allenai/olmo-3-7b-instruct-20251121",
                "variant": "standard",
                "variant_permaslug": "allenai/olmo-3-7b-instruct-20251121",
                "count": 96871,
                "total_completion_tokens": 17671648,
                "total_prompt_tokens": 89871634,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 31658800,
                "total_tool_calls": 1,
                "requests_with_tool_call_errors": 0
            },
            "tngtech/deepseek-r1t-chimera": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/deepseek-r1t-chimera",
                "variant": "standard",
                "variant_permaslug": "tngtech/deepseek-r1t-chimera",
                "count": 259522,
                "total_completion_tokens": 36706654,
                "total_prompt_tokens": 1330287047,
                "total_native_tokens_reasoning": 56901,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 210921607,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "moonshotai/kimi-dev-72b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-dev-72b",
                "variant": "standard",
                "variant_permaslug": "moonshotai/kimi-dev-72b",
                "count": 50265,
                "total_completion_tokens": 41339575,
                "total_prompt_tokens": 13989994,
                "total_native_tokens_reasoning": 37665450,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-4b-04-28:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-4b-04-28",
                "variant": "free",
                "variant_permaslug": "qwen/qwen3-4b-04-28:free",
                "count": 44164,
                "total_completion_tokens": 46036524,
                "total_prompt_tokens": 114144928,
                "total_native_tokens_reasoning": 37672650,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1177,
                "requests_with_tool_call_errors": 1098
            },
            "openai/o1-pro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o1-pro",
                "variant": "standard",
                "variant_permaslug": "openai/o1-pro",
                "count": 526,
                "total_completion_tokens": 267811,
                "total_prompt_tokens": 990526,
                "total_native_tokens_reasoning": 143360,
                "num_media_prompt": 3,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "z-ai/glm-4.5-air": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4.5-air",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4.5-air",
                "count": 1744275,
                "total_completion_tokens": 413762672,
                "total_prompt_tokens": 4702456741,
                "total_native_tokens_reasoning": 226511365,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2405444064,
                "total_tool_calls": 28165,
                "requests_with_tool_call_errors": 2273
            },
            "mistralai/mistral-large-2407": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-large-2407",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-large-2407",
                "count": 19952,
                "total_completion_tokens": 8337988,
                "total_prompt_tokens": 27469036,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 106,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-oss-safeguard-20b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-safeguard-20b",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-oss-safeguard-20b",
                "count": 1622006,
                "total_completion_tokens": 1034759303,
                "total_prompt_tokens": 4815736993,
                "total_native_tokens_reasoning": 775559762,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3545313280,
                "total_tool_calls": 19824,
                "requests_with_tool_call_errors": 169
            },
            "openai/chatgpt-4o-latest": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/chatgpt-4o-latest",
                "variant": "standard",
                "variant_permaslug": "openai/chatgpt-4o-latest",
                "count": 221191,
                "total_completion_tokens": 76126863,
                "total_prompt_tokens": 825975801,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 70930,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-r1-0528:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1-0528",
                "variant": "free",
                "variant_permaslug": "deepseek/deepseek-r1-0528:free",
                "count": 1072307,
                "total_completion_tokens": 866434395,
                "total_prompt_tokens": 3893552549,
                "total_native_tokens_reasoning": 574674272,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen2.5-vl-32b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen2.5-vl-32b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen2.5-vl-32b-instruct",
                "count": 427177,
                "total_completion_tokens": 50368561,
                "total_prompt_tokens": 1596674509,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 232522,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 82206747,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "ibm-granite/granite-4.0-h-micro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "ibm-granite/granite-4.0-h-micro",
                "variant": "standard",
                "variant_permaslug": "ibm-granite/granite-4.0-h-micro",
                "count": 400165,
                "total_completion_tokens": 45094041,
                "total_prompt_tokens": 604854728,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 8,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "morph/morph-v3-fast": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "morph/morph-v3-fast",
                "variant": "standard",
                "variant_permaslug": "morph/morph-v3-fast",
                "count": 55057,
                "total_completion_tokens": 53344590,
                "total_prompt_tokens": 50114834,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "inception/mercury-coder-small-beta": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "inception/mercury-coder-small-beta",
                "variant": "standard",
                "variant_permaslug": "inception/mercury-coder-small-beta",
                "count": 21976,
                "total_completion_tokens": 10668794,
                "total_prompt_tokens": 77980914,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 612,
                "requests_with_tool_call_errors": 136
            },
            "amazon/nova-pro-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "amazon/nova-pro-v1",
                "variant": "standard",
                "variant_permaslug": "amazon/nova-pro-v1",
                "count": 22097,
                "total_completion_tokens": 4926680,
                "total_prompt_tokens": 23253825,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1080,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 22,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-chat-v3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-chat-v3",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-chat-v3",
                "count": 6511686,
                "total_completion_tokens": 1322890249,
                "total_prompt_tokens": 12562230256,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1200387478,
                "total_tool_calls": 113579,
                "requests_with_tool_call_errors": 1091
            },
            "perplexity/sonar": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "perplexity/sonar",
                "variant": "standard",
                "variant_permaslug": "perplexity/sonar",
                "count": 953494,
                "total_completion_tokens": 395439874,
                "total_prompt_tokens": 889514839,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 4382,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "perplexity/sonar-pro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "perplexity/sonar-pro",
                "variant": "standard",
                "variant_permaslug": "perplexity/sonar-pro",
                "count": 212154,
                "total_completion_tokens": 95456303,
                "total_prompt_tokens": 535394128,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1364,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-next-80b-a3b-instruct-2509": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-next-80b-a3b-instruct-2509",
                "count": 4262459,
                "total_completion_tokens": 369382234,
                "total_prompt_tokens": 14816400773,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 40151733,
                "total_tool_calls": 168365,
                "requests_with_tool_call_errors": 16669
            },
            "perplexity/sonar-deep-research": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "perplexity/sonar-deep-research",
                "variant": "standard",
                "variant_permaslug": "perplexity/sonar-deep-research",
                "count": 8012,
                "total_completion_tokens": 1571374190,
                "total_prompt_tokens": 44450337,
                "total_native_tokens_reasoning": 1532975222,
                "num_media_prompt": 129,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "tngtech/deepseek-r1t-chimera:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/deepseek-r1t-chimera",
                "variant": "free",
                "variant_permaslug": "tngtech/deepseek-r1t-chimera:free",
                "count": 2196415,
                "total_completion_tokens": 1129177376,
                "total_prompt_tokens": 22140759022,
                "total_native_tokens_reasoning": 20414157,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 5605209442,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "tngtech/deepseek-r1t2-chimera": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/deepseek-r1t2-chimera",
                "variant": "standard",
                "variant_permaslug": "tngtech/deepseek-r1t2-chimera",
                "count": 758584,
                "total_completion_tokens": 258926712,
                "total_prompt_tokens": 3743291754,
                "total_native_tokens_reasoning": 256603880,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 330632024,
                "total_tool_calls": 249,
                "requests_with_tool_call_errors": 2
            },
            "deepseek/deepseek-v3.1-terminus": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-v3.1-terminus",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-v3.1-terminus",
                "count": 2986536,
                "total_completion_tokens": 916440723,
                "total_prompt_tokens": 13544001905,
                "total_native_tokens_reasoning": 171725433,
                "num_media_prompt": 92,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 559531586,
                "total_tool_calls": 82127,
                "requests_with_tool_call_errors": 2687
            },
            "qwen/qwen3-vl-8b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-8b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-8b-instruct",
                "count": 1494329,
                "total_completion_tokens": 1270403665,
                "total_prompt_tokens": 3630625876,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3521893,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 47769840,
                "total_tool_calls": 86791,
                "requests_with_tool_call_errors": 4032
            },
            "deepseek/deepseek-r1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-r1",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-r1",
                "count": 879707,
                "total_completion_tokens": 1089795106,
                "total_prompt_tokens": 4511695822,
                "total_native_tokens_reasoning": 645285296,
                "num_media_prompt": 30,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 122898688,
                "total_tool_calls": 4241,
                "requests_with_tool_call_errors": 260
            },
            "qwen/qwen-max-2025-01-25": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-max-2025-01-25",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-max-2025-01-25",
                "count": 61959,
                "total_completion_tokens": 14781164,
                "total_prompt_tokens": 110515392,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 48944000,
                "total_tool_calls": 1563,
                "requests_with_tool_call_errors": 209
            },
            "mistralai/mistral-small-3.2-24b-instruct-2506": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-small-3.2-24b-instruct-2506",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-small-3.2-24b-instruct-2506",
                "count": 5553422,
                "total_completion_tokens": 3394434790,
                "total_prompt_tokens": 18313855020,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 209314,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2334310943,
                "total_tool_calls": 35981,
                "requests_with_tool_call_errors": 2681
            },
            "openai/gpt-5.1-codex-max-20251204": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.1-codex-max-20251204",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.1-codex-max-20251204",
                "count": 133584,
                "total_completion_tokens": 102577190,
                "total_prompt_tokens": 3767991453,
                "total_native_tokens_reasoning": 52922495,
                "num_media_prompt": 14289,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2781055744,
                "total_tool_calls": 86923,
                "requests_with_tool_call_errors": 923
            },
            "baai/bge-base-en-v1.5-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baai/bge-base-en-v1.5-20251117",
                "variant": "standard",
                "variant_permaslug": "baai/bge-base-en-v1.5-20251117",
                "count": 14237,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 30610063,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "aion-labs/aion-1.0": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "aion-labs/aion-1.0",
                "variant": "standard",
                "variant_permaslug": "aion-labs/aion-1.0",
                "count": 72254,
                "total_completion_tokens": 71353992,
                "total_prompt_tokens": 368432757,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nvidia/nemotron-nano-9b-v2": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-nano-9b-v2",
                "variant": "standard",
                "variant_permaslug": "nvidia/nemotron-nano-9b-v2",
                "count": 655489,
                "total_completion_tokens": 1200914607,
                "total_prompt_tokens": 4444823194,
                "total_native_tokens_reasoning": 1022464973,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 260331,
                "requests_with_tool_call_errors": 255942
            },
            "ai21/jamba-large-1.7": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "ai21/jamba-large-1.7",
                "variant": "standard",
                "variant_permaslug": "ai21/jamba-large-1.7",
                "count": 33421,
                "total_completion_tokens": 3892372,
                "total_prompt_tokens": 71653425,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1084,
                "requests_with_tool_call_errors": 403
            },
            "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117",
                "variant": "standard",
                "variant_permaslug": "sentence-transformers/multi-qa-mpnet-base-dot-v1-20251117",
                "count": 168,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 8733,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "nousresearch/hermes-2-pro-llama-3-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
                "variant": "standard",
                "variant_permaslug": "nousresearch/hermes-2-pro-llama-3-8b",
                "count": 530906,
                "total_completion_tokens": 227914344,
                "total_prompt_tokens": 360419770,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 18,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "thudm/glm-4.1v-9b-thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thudm/glm-4.1v-9b-thinking",
                "variant": "standard",
                "variant_permaslug": "thudm/glm-4.1v-9b-thinking",
                "count": 8859,
                "total_completion_tokens": 6303124,
                "total_prompt_tokens": 36591059,
                "total_native_tokens_reasoning": 5766945,
                "num_media_prompt": 19315,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "kwaipilot/kat-coder-pro-v1:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "kwaipilot/kat-coder-pro-v1",
                "variant": "free",
                "variant_permaslug": "kwaipilot/kat-coder-pro-v1:free",
                "count": 6905877,
                "total_completion_tokens": 3877403132,
                "total_prompt_tokens": 87325738256,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 393,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 71665530157,
                "total_tool_calls": 509635,
                "requests_with_tool_call_errors": 43505
            },
            "openai/gpt-oss-20b:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-20b",
                "variant": "free",
                "variant_permaslug": "openai/gpt-oss-20b:free",
                "count": 76866,
                "total_completion_tokens": 80273544,
                "total_prompt_tokens": 413335254,
                "total_native_tokens_reasoning": 67521687,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 8906,
                "requests_with_tool_call_errors": 3906
            },
            "baidu/ernie-4.5-vl-28b-a3b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "baidu/ernie-4.5-vl-28b-a3b",
                "variant": "standard",
                "variant_permaslug": "baidu/ernie-4.5-vl-28b-a3b",
                "count": 2918,
                "total_completion_tokens": 1671706,
                "total_prompt_tokens": 3519904,
                "total_native_tokens_reasoning": 420499,
                "num_media_prompt": 1590,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-oss-20b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-oss-20b",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-oss-20b",
                "count": 12285079,
                "total_completion_tokens": 10008870395,
                "total_prompt_tokens": 28540654057,
                "total_native_tokens_reasoning": 7947419952,
                "num_media_prompt": 6,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6041602437,
                "total_tool_calls": 149435,
                "requests_with_tool_call_errors": 6457
            },
            "openai/gpt-4o-mini": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-mini",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-mini",
                "count": 48481353,
                "total_completion_tokens": 5778100049,
                "total_prompt_tokens": 105011326433,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1380091,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 24694408960,
                "total_tool_calls": 2671176,
                "requests_with_tool_call_errors": 89825
            },
            "anthropic/claude-3-7-sonnet-20250219": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3-7-sonnet-20250219",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-3-7-sonnet-20250219",
                "count": 2749722,
                "total_completion_tokens": 1172647659,
                "total_prompt_tokens": 24682762605,
                "total_native_tokens_reasoning": 7101086,
                "num_media_prompt": 247220,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6820127943,
                "total_tool_calls": 98949,
                "requests_with_tool_call_errors": 4113
            },
            "openai/gpt-5.2-20251211": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5.2-20251211",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5.2-20251211",
                "count": 3759624,
                "total_completion_tokens": 4039105844,
                "total_prompt_tokens": 82870509192,
                "total_native_tokens_reasoning": 2485012785,
                "num_media_prompt": 54047795,
                "num_media_completion": 28,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 49849435648,
                "total_tool_calls": 1303183,
                "requests_with_tool_call_errors": 9983
            },
            "openai/gpt-5-pro-2025-10-06": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-pro-2025-10-06",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-pro-2025-10-06",
                "count": 6208,
                "total_completion_tokens": 14242422,
                "total_prompt_tokens": 43848686,
                "total_native_tokens_reasoning": 11734311,
                "num_media_prompt": 1215,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 644,
                "requests_with_tool_call_errors": 3
            },
            "liquid/lfm2-8b-a1b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "liquid/lfm2-8b-a1b",
                "variant": "standard",
                "variant_permaslug": "liquid/lfm2-8b-a1b",
                "count": 49921,
                "total_completion_tokens": 3381301,
                "total_prompt_tokens": 18232325,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "allenai/olmo-3.1-32b-think-20251215": {
                "date": "2026-01-05 00:00:00",
                "model_permaslug": "allenai/olmo-3.1-32b-think-20251215",
                "variant": "standard",
                "variant_permaslug": "allenai/olmo-3.1-32b-think-20251215",
                "count": 3245,
                "total_completion_tokens": 11626120,
                "total_prompt_tokens": 4987816,
                "total_native_tokens_reasoning": 10891630,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2788928,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/o3-mini-high-2025-01-31": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o3-mini-high-2025-01-31",
                "variant": "standard",
                "variant_permaslug": "openai/o3-mini-high-2025-01-31",
                "count": 6681,
                "total_completion_tokens": 7811969,
                "total_prompt_tokens": 16443089,
                "total_native_tokens_reasoning": 4883392,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1486720,
                "total_tool_calls": 145,
                "requests_with_tool_call_errors": 0
            },
            "alpindale/goliath-120b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "alpindale/goliath-120b",
                "variant": "standard",
                "variant_permaslug": "alpindale/goliath-120b",
                "count": 54617,
                "total_completion_tokens": 2732348,
                "total_prompt_tokens": 12959089,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-vl-8b-thinking": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-8b-thinking",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-8b-thinking",
                "count": 16391,
                "total_completion_tokens": 49551821,
                "total_prompt_tokens": 96281639,
                "total_native_tokens_reasoning": 43917658,
                "num_media_prompt": 48288,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 115,
                "requests_with_tool_call_errors": 37
            },
            "mistralai/pixtral-12b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/pixtral-12b",
                "variant": "standard",
                "variant_permaslug": "mistralai/pixtral-12b",
                "count": 68931,
                "total_completion_tokens": 13885086,
                "total_prompt_tokens": 105288644,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 49744,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 10,
                "requests_with_tool_call_errors": 4
            },
            "qwen/qwen3-235b-a22b-07-25": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-235b-a22b-07-25",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-235b-a22b-07-25",
                "count": 21922311,
                "total_completion_tokens": 3832092968,
                "total_prompt_tokens": 59330041441,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 613,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 14062452991,
                "total_tool_calls": 378082,
                "requests_with_tool_call_errors": 6763
            },
            "openai/gpt-5-image": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-image",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-image",
                "count": 24335,
                "total_completion_tokens": 60425246,
                "total_prompt_tokens": 107958761,
                "total_native_tokens_reasoning": 47833128,
                "num_media_prompt": 26993,
                "num_media_completion": 21283,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 4207232,
                "total_tool_calls": 77,
                "requests_with_tool_call_errors": 0
            },
            "nousresearch/hermes-4-405b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nousresearch/hermes-4-405b",
                "variant": "standard",
                "variant_permaslug": "nousresearch/hermes-4-405b",
                "count": 99486,
                "total_completion_tokens": 36244789,
                "total_prompt_tokens": 406093577,
                "total_native_tokens_reasoning": 12060068,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 21875376,
                "total_tool_calls": 146,
                "requests_with_tool_call_errors": 8
            },
            "deepcogito/cogito-v2-preview-llama-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepcogito/cogito-v2-preview-llama-70b",
                "variant": "standard",
                "variant_permaslug": "deepcogito/cogito-v2-preview-llama-70b",
                "count": 42887,
                "total_completion_tokens": 1362933,
                "total_prompt_tokens": 8992496,
                "total_native_tokens_reasoning": 345,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 21,
                "requests_with_tool_call_errors": 1
            },
            "sourceful/riverflow-v2-max-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sourceful/riverflow-v2-max-preview",
                "variant": "standard",
                "variant_permaslug": "sourceful/riverflow-v2-max-preview",
                "count": 2777,
                "total_completion_tokens": 11593975,
                "total_prompt_tokens": 44964129,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 3983,
                "num_media_completion": 2777,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/devstral-medium-2507": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/devstral-medium-2507",
                "variant": "standard",
                "variant_permaslug": "mistralai/devstral-medium-2507",
                "count": 67019,
                "total_completion_tokens": 5395986,
                "total_prompt_tokens": 736439748,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 531,
                "requests_with_tool_call_errors": 61
            },
            "meta-llama/llama-3-8b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3-8b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3-8b-instruct",
                "count": 1103058,
                "total_completion_tokens": 87868654,
                "total_prompt_tokens": 854183331,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 374,
                "requests_with_tool_call_errors": 75
            },
            "qwen/qwen-turbo-2024-11-01": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-turbo-2024-11-01",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-turbo-2024-11-01",
                "count": 300227,
                "total_completion_tokens": 33165757,
                "total_prompt_tokens": 617226382,
                "total_native_tokens_reasoning": 126423,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 191798395,
                "total_tool_calls": 19990,
                "requests_with_tool_call_errors": 68
            },
            "qwen/qwen-plus-2025-07-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-plus-2025-07-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-plus-2025-07-28",
                "count": 22039,
                "total_completion_tokens": 17728912,
                "total_prompt_tokens": 154107331,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1613,
                "requests_with_tool_call_errors": 65
            },
            "sao10k/l3-euryale-70b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sao10k/l3-euryale-70b",
                "variant": "standard",
                "variant_permaslug": "sao10k/l3-euryale-70b",
                "count": 32279,
                "total_completion_tokens": 6631898,
                "total_prompt_tokens": 41427953,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-coder-30b-a3b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-coder-30b-a3b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-coder-30b-a3b-instruct",
                "count": 617207,
                "total_completion_tokens": 145918967,
                "total_prompt_tokens": 3540969239,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 12,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 144136,
                "requests_with_tool_call_errors": 10656
            },
            "prime-intellect/intellect-3-20251126": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "prime-intellect/intellect-3-20251126",
                "variant": "standard",
                "variant_permaslug": "prime-intellect/intellect-3-20251126",
                "count": 36277,
                "total_completion_tokens": 55747676,
                "total_prompt_tokens": 123486564,
                "total_native_tokens_reasoning": 49990043,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 26794224,
                "total_tool_calls": 10996,
                "requests_with_tool_call_errors": 95
            },
            "nvidia/nemotron-nano-12b-v2-vl:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "nvidia/nemotron-nano-12b-v2-vl",
                "variant": "free",
                "variant_permaslug": "nvidia/nemotron-nano-12b-v2-vl:free",
                "count": 2087811,
                "total_completion_tokens": 2392929002,
                "total_prompt_tokens": 6474899668,
                "total_native_tokens_reasoning": 1435885641,
                "num_media_prompt": 2641582,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 6116,
                "requests_with_tool_call_errors": 495
            },
            "alibaba/tongyi-deepresearch-30b-a3b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "alibaba/tongyi-deepresearch-30b-a3b",
                "variant": "standard",
                "variant_permaslug": "alibaba/tongyi-deepresearch-30b-a3b",
                "count": 97830,
                "total_completion_tokens": 65700208,
                "total_prompt_tokens": 541666702,
                "total_native_tokens_reasoning": 52688861,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1297188,
                "total_tool_calls": 3161,
                "requests_with_tool_call_errors": 883
            },
            "openai/gpt-4o-mini-2024-07-18": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-mini-2024-07-18",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-mini-2024-07-18",
                "count": 2911999,
                "total_completion_tokens": 398028780,
                "total_prompt_tokens": 5282325892,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 17951,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1351544832,
                "total_tool_calls": 17664,
                "requests_with_tool_call_errors": 257
            },
            "amazon/nova-lite-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "amazon/nova-lite-v1",
                "variant": "standard",
                "variant_permaslug": "amazon/nova-lite-v1",
                "count": 154689,
                "total_completion_tokens": 20056144,
                "total_prompt_tokens": 240929571,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 80763,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 9686,
                "requests_with_tool_call_errors": 29
            },
            "ai21/jamba-mini-1.7": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "ai21/jamba-mini-1.7",
                "variant": "standard",
                "variant_permaslug": "ai21/jamba-mini-1.7",
                "count": 5496,
                "total_completion_tokens": 1024270,
                "total_prompt_tokens": 18990015,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 41,
                "requests_with_tool_call_errors": 7
            },
            "anthropic/claude-3.5-sonnet": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3.5-sonnet",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-3.5-sonnet",
                "count": 1639361,
                "total_completion_tokens": 307348836,
                "total_prompt_tokens": 4670229438,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 77491,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 707652242,
                "total_tool_calls": 58199,
                "requests_with_tool_call_errors": 784
            },
            "switchpoint/router": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "switchpoint/router",
                "variant": "standard",
                "variant_permaslug": "switchpoint/router",
                "count": 39869,
                "total_completion_tokens": 845574,
                "total_prompt_tokens": 11614088,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/ministral-8b-2512": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/ministral-8b-2512",
                "variant": "standard",
                "variant_permaslug": "mistralai/ministral-8b-2512",
                "count": 884118,
                "total_completion_tokens": 192838199,
                "total_prompt_tokens": 1189253621,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 28267,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 9535,
                "requests_with_tool_call_errors": 111
            },
            "mistralai/mistral-tiny": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-tiny",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-tiny",
                "count": 3613281,
                "total_completion_tokens": 48173278,
                "total_prompt_tokens": 1788977779,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 213,
                "requests_with_tool_call_errors": 1
            },
            "intfloat/e5-large-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "intfloat/e5-large-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "intfloat/e5-large-v2-20251117",
                "count": 14045,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 49987033,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sourceful/riverflow-v2-standard-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sourceful/riverflow-v2-standard-preview",
                "variant": "standard",
                "variant_permaslug": "sourceful/riverflow-v2-standard-preview",
                "count": 9744,
                "total_completion_tokens": 40681200,
                "total_prompt_tokens": 35368762,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 10081,
                "num_media_completion": 9744,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen-2.5-72b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen-2.5-72b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen-2.5-72b-instruct",
                "count": 3151454,
                "total_completion_tokens": 241519610,
                "total_prompt_tokens": 3079806033,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 46005067,
                "total_tool_calls": 21585,
                "requests_with_tool_call_errors": 1311
            },
            "qwen/qwen3-next-80b-a3b-thinking-2509": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-next-80b-a3b-thinking-2509",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-next-80b-a3b-thinking-2509",
                "count": 143671,
                "total_completion_tokens": 658932443,
                "total_prompt_tokens": 302754457,
                "total_native_tokens_reasoning": 506016092,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 2761,
                "requests_with_tool_call_errors": 36
            },
            "openai/gpt-4-turbo-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4-turbo-preview",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4-turbo-preview",
                "count": 5723,
                "total_completion_tokens": 1641025,
                "total_prompt_tokens": 7670801,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 263,
                "requests_with_tool_call_errors": 19
            },
            "google/gemma-2-27b-it": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-2-27b-it",
                "variant": "standard",
                "variant_permaslug": "google/gemma-2-27b-it",
                "count": 403317,
                "total_completion_tokens": 40753969,
                "total_prompt_tokens": 437494746,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/mistral-7b-instruct-v0.1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-7b-instruct-v0.1",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-7b-instruct-v0.1",
                "count": 47398,
                "total_completion_tokens": 3487560,
                "total_prompt_tokens": 8732654,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "x-ai/grok-4-07-09": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-4-07-09",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-4-07-09",
                "count": 665606,
                "total_completion_tokens": 989232754,
                "total_prompt_tokens": 4924080054,
                "total_native_tokens_reasoning": 711131495,
                "num_media_prompt": 370276,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2597018935,
                "total_tool_calls": 69910,
                "requests_with_tool_call_errors": 407
            },
            "google/gemma-3-4b-it:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemma-3-4b-it",
                "variant": "free",
                "variant_permaslug": "google/gemma-3-4b-it:free",
                "count": 55273,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 46805692,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 67497,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/devstral-2512:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/devstral-2512",
                "variant": "free",
                "variant_permaslug": "mistralai/devstral-2512:free",
                "count": 9129662,
                "total_completion_tokens": 4847330798,
                "total_prompt_tokens": 105807599691,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 1176275,
                "requests_with_tool_call_errors": 73659
            },
            "openai/gpt-4o-2024-05-13": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4o-2024-05-13",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4o-2024-05-13",
                "count": 47629,
                "total_completion_tokens": 10220062,
                "total_prompt_tokens": 112006069,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 18148,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3887616,
                "total_tool_calls": 2296,
                "requests_with_tool_call_errors": 7
            },
            "arcee-ai/trinity-mini-20251201:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "arcee-ai/trinity-mini-20251201",
                "variant": "free",
                "variant_permaslug": "arcee-ai/trinity-mini-20251201:free",
                "count": 50595,
                "total_completion_tokens": 87978713,
                "total_prompt_tokens": 174174011,
                "total_native_tokens_reasoning": 63537918,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 2399,
                "requests_with_tool_call_errors": 246
            },
            "mistralai/mistral-nemo": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/mistral-nemo",
                "variant": "standard",
                "variant_permaslug": "mistralai/mistral-nemo",
                "count": 31033868,
                "total_completion_tokens": 3982060164,
                "total_prompt_tokens": 94539299642,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 612,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 396712483,
                "total_tool_calls": 1618,
                "requests_with_tool_call_errors": 32
            },
            "minimax/minimax-m2.1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "minimax/minimax-m2.1",
                "variant": "standard",
                "variant_permaslug": "minimax/minimax-m2.1",
                "count": 2486453,
                "total_completion_tokens": 1827993732,
                "total_prompt_tokens": 90988828048,
                "total_native_tokens_reasoning": 645136352,
                "num_media_prompt": 1347,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 62747445010,
                "total_tool_calls": 1657366,
                "requests_with_tool_call_errors": 76232
            },
            "tngtech/tng-r1t-chimera:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tngtech/tng-r1t-chimera",
                "variant": "free",
                "variant_permaslug": "tngtech/tng-r1t-chimera:free",
                "count": 500903,
                "total_completion_tokens": 392471214,
                "total_prompt_tokens": 5067120497,
                "total_native_tokens_reasoning": 249544962,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2473504832,
                "total_tool_calls": 5026,
                "requests_with_tool_call_errors": 145
            },
            "qwen/qwen3-8b-04-28": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-8b-04-28",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-8b-04-28",
                "count": 1439659,
                "total_completion_tokens": 1565590663,
                "total_prompt_tokens": 2700737184,
                "total_native_tokens_reasoning": 1265587109,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 490680074,
                "total_tool_calls": 38178,
                "requests_with_tool_call_errors": 33
            },
            "x-ai/grok-3": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-3",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-3",
                "count": 1044542,
                "total_completion_tokens": 355976075,
                "total_prompt_tokens": 3941775691,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 16,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 473887782,
                "total_tool_calls": 6099,
                "requests_with_tool_call_errors": 1
            },
            "openai/o4-mini-high-2025-04-16": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/o4-mini-high-2025-04-16",
                "variant": "standard",
                "variant_permaslug": "openai/o4-mini-high-2025-04-16",
                "count": 84008,
                "total_completion_tokens": 116631643,
                "total_prompt_tokens": 450846762,
                "total_native_tokens_reasoning": 96694514,
                "num_media_prompt": 7252,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 171140096,
                "total_tool_calls": 5465,
                "requests_with_tool_call_errors": 4
            },
            "z-ai/glm-4-32b-0414": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "z-ai/glm-4-32b-0414",
                "variant": "standard",
                "variant_permaslug": "z-ai/glm-4-32b-0414",
                "count": 19212718,
                "total_completion_tokens": 105321186,
                "total_prompt_tokens": 5853164680,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 125,
                "requests_with_tool_call_errors": 9
            },
            "liquid/lfm-2.2-6b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "liquid/lfm-2.2-6b",
                "variant": "standard",
                "variant_permaslug": "liquid/lfm-2.2-6b",
                "count": 48397,
                "total_completion_tokens": 3804492,
                "total_prompt_tokens": 15730244,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "sentence-transformers/paraphrase-minilm-l6-v2-20251117": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "sentence-transformers/paraphrase-minilm-l6-v2-20251117",
                "variant": "standard",
                "variant_permaslug": "sentence-transformers/paraphrase-minilm-l6-v2-20251117",
                "count": 3507,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 3503125,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "meta-llama/llama-3.1-405b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.1-405b",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.1-405b",
                "count": 21888,
                "total_completion_tokens": 3347738,
                "total_prompt_tokens": 1117395,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "perplexity/sonar-reasoning-pro": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "perplexity/sonar-reasoning-pro",
                "variant": "standard",
                "variant_permaslug": "perplexity/sonar-reasoning-pro",
                "count": 36746,
                "total_completion_tokens": 40823985,
                "total_prompt_tokens": 108745882,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 409,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "qwen/qwen3-vl-32b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-32b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-32b-instruct",
                "count": 165361,
                "total_completion_tokens": 66802174,
                "total_prompt_tokens": 214525054,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 134462,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "deepseek/deepseek-v3.2-exp": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "deepseek/deepseek-v3.2-exp",
                "variant": "standard",
                "variant_permaslug": "deepseek/deepseek-v3.2-exp",
                "count": 2924684,
                "total_completion_tokens": 1415264191,
                "total_prompt_tokens": 18685610486,
                "total_native_tokens_reasoning": 411762622,
                "num_media_prompt": 60,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 291488512,
                "total_tool_calls": 62348,
                "requests_with_tool_call_errors": 7480
            },
            "bytedance-seed/seedream-4.5-20251203": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "bytedance-seed/seedream-4.5-20251203",
                "variant": "standard",
                "variant_permaslug": "bytedance-seed/seedream-4.5-20251203",
                "count": 74912,
                "total_completion_tokens": 312757600,
                "total_prompt_tokens": 467155657,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 152049,
                "num_media_completion": 74912,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "bytedance-seed/seed-1.6-20250625": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "bytedance-seed/seed-1.6-20250625",
                "variant": "standard",
                "variant_permaslug": "bytedance-seed/seed-1.6-20250625",
                "count": 95739,
                "total_completion_tokens": 85202483,
                "total_prompt_tokens": 461214244,
                "total_native_tokens_reasoning": 57135588,
                "num_media_prompt": 142559,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 2918,
                "requests_with_tool_call_errors": 198
            },
            "thedrummer/rocinante-12b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "thedrummer/rocinante-12b",
                "variant": "standard",
                "variant_permaslug": "thedrummer/rocinante-12b",
                "count": 569874,
                "total_completion_tokens": 155307322,
                "total_prompt_tokens": 931379644,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-3-flash-preview-20251217": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-3-flash-preview-20251217",
                "variant": "standard",
                "variant_permaslug": "google/gemini-3-flash-preview-20251217",
                "count": 35102625,
                "total_completion_tokens": 15120013317,
                "total_prompt_tokens": 319587390307,
                "total_native_tokens_reasoning": 2930926512,
                "num_media_prompt": 7444496,
                "num_media_completion": 0,
                "num_audio_prompt": 137454,
                "total_native_tokens_cached": 149558012649,
                "total_tool_calls": 5169509,
                "requests_with_tool_call_errors": 244126
            },
            "meta-llama/llama-3.3-70b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-3.3-70b-instruct",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-3.3-70b-instruct",
                "count": 24062950,
                "total_completion_tokens": 2120402783,
                "total_prompt_tokens": 25977011425,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6858472065,
                "total_tool_calls": 47545,
                "requests_with_tool_call_errors": 3060
            },
            "qwen/qwen3-vl-30b-a3b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "qwen/qwen3-vl-30b-a3b-instruct",
                "variant": "standard",
                "variant_permaslug": "qwen/qwen3-vl-30b-a3b-instruct",
                "count": 2306636,
                "total_completion_tokens": 258472369,
                "total_prompt_tokens": 4055190390,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 2468089,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1613328094,
                "total_tool_calls": 51007,
                "requests_with_tool_call_errors": 37069
            },
            "morph/morph-v3-large": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "morph/morph-v3-large",
                "variant": "standard",
                "variant_permaslug": "morph/morph-v3-large",
                "count": 122713,
                "total_completion_tokens": 364140505,
                "total_prompt_tokens": 417429740,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-4.1-mini-2025-04-14": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-4.1-mini-2025-04-14",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-4.1-mini-2025-04-14",
                "count": 11839407,
                "total_completion_tokens": 1782574661,
                "total_prompt_tokens": 24412994651,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 1311242,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 6495620352,
                "total_tool_calls": 1253650,
                "requests_with_tool_call_errors": 6955
            },
            "meta-llama/llama-guard-2-8b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "meta-llama/llama-guard-2-8b",
                "variant": "standard",
                "variant_permaslug": "meta-llama/llama-guard-2-8b",
                "count": 41593,
                "total_completion_tokens": 140710,
                "total_prompt_tokens": 5409943,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "x-ai/grok-3-mini": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "x-ai/grok-3-mini",
                "variant": "standard",
                "variant_permaslug": "x-ai/grok-3-mini",
                "count": 3380083,
                "total_completion_tokens": 2723779296,
                "total_prompt_tokens": 7190250677,
                "total_native_tokens_reasoning": 2174002830,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2210455121,
                "total_tool_calls": 22459,
                "requests_with_tool_call_errors": 9822
            },
            "google/gemini-2.5-flash-image-preview": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-2.5-flash-image-preview",
                "variant": "standard",
                "variant_permaslug": "google/gemini-2.5-flash-image-preview",
                "count": 344277,
                "total_completion_tokens": 273504737,
                "total_prompt_tokens": 352473159,
                "total_native_tokens_reasoning": 27852,
                "num_media_prompt": 344627,
                "num_media_completion": 201741,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/devstral-small-2505": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/devstral-small-2505",
                "variant": "standard",
                "variant_permaslug": "mistralai/devstral-small-2505",
                "count": 96265,
                "total_completion_tokens": 10714945,
                "total_prompt_tokens": 522438868,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "mistralai/ministral-3b": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "mistralai/ministral-3b",
                "variant": "standard",
                "variant_permaslug": "mistralai/ministral-3b",
                "count": 3735842,
                "total_completion_tokens": 172290522,
                "total_prompt_tokens": 2640205360,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 3538,
                "requests_with_tool_call_errors": 13
            },
            "amazon/nova-micro-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "amazon/nova-micro-v1",
                "variant": "standard",
                "variant_permaslug": "amazon/nova-micro-v1",
                "count": 1285321,
                "total_completion_tokens": 275369297,
                "total_prompt_tokens": 1471373384,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 4342,
                "requests_with_tool_call_errors": 162
            },
            "venice/uncensored:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "venice/uncensored",
                "variant": "free",
                "variant_permaslug": "venice/uncensored:free",
                "count": 298991,
                "total_completion_tokens": 110487655,
                "total_prompt_tokens": 1186150741,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "google/gemini-embedding-001": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "google/gemini-embedding-001",
                "variant": "standard",
                "variant_permaslug": "google/gemini-embedding-001",
                "count": 1754903,
                "total_completion_tokens": 0,
                "total_prompt_tokens": 3201950927,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "tencent/hunyuan-a13b-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "tencent/hunyuan-a13b-instruct",
                "variant": "standard",
                "variant_permaslug": "tencent/hunyuan-a13b-instruct",
                "count": 45682,
                "total_completion_tokens": 3948015,
                "total_prompt_tokens": 21662258,
                "total_native_tokens_reasoning": 6220,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "openai/gpt-5-image-mini": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "openai/gpt-5-image-mini",
                "variant": "standard",
                "variant_permaslug": "openai/gpt-5-image-mini",
                "count": 55309,
                "total_completion_tokens": 62185361,
                "total_prompt_tokens": 116958052,
                "total_native_tokens_reasoning": 49005408,
                "num_media_prompt": 38720,
                "num_media_completion": 17744,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 3288960,
                "total_tool_calls": 75,
                "requests_with_tool_call_errors": 0
            },
            "microsoft/phi-4-reasoning-plus-04-30": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/phi-4-reasoning-plus-04-30",
                "variant": "standard",
                "variant_permaslug": "microsoft/phi-4-reasoning-plus-04-30",
                "count": 94413,
                "total_completion_tokens": 155966820,
                "total_prompt_tokens": 161172812,
                "total_native_tokens_reasoning": 10749,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "allenai/olmo-3-32b-think-20251121:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "allenai/olmo-3-32b-think-20251121",
                "variant": "free",
                "variant_permaslug": "allenai/olmo-3-32b-think-20251121:free",
                "count": 9773,
                "total_completion_tokens": 15404613,
                "total_prompt_tokens": 17794714,
                "total_native_tokens_reasoning": 16322598,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 7074720,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "allenai/olmo-3.1-32b-think-20251215:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "allenai/olmo-3.1-32b-think-20251215",
                "variant": "free",
                "variant_permaslug": "allenai/olmo-3.1-32b-think-20251215:free",
                "count": 231132,
                "total_completion_tokens": 923004486,
                "total_prompt_tokens": 1136911885,
                "total_native_tokens_reasoning": 901701074,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 580919552,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "anthropic/claude-3-opus": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "anthropic/claude-3-opus",
                "variant": "standard",
                "variant_permaslug": "anthropic/claude-3-opus",
                "count": 50326,
                "total_completion_tokens": 58430674,
                "total_prompt_tokens": 3276417122,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 294,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 2742551080,
                "total_tool_calls": 240,
                "requests_with_tool_call_errors": 18
            },
            "alibaba/tongyi-deepresearch-30b-a3b:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "alibaba/tongyi-deepresearch-30b-a3b",
                "variant": "free",
                "variant_permaslug": "alibaba/tongyi-deepresearch-30b-a3b:free",
                "count": 5029,
                "total_completion_tokens": 354906,
                "total_prompt_tokens": 1679280,
                "total_native_tokens_reasoning": 295649,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 1141340,
                "total_tool_calls": 3,
                "requests_with_tool_call_errors": 1
            },
            "arliai/qwq-32b-arliai-rpr-v1": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "arliai/qwq-32b-arliai-rpr-v1",
                "variant": "standard",
                "variant_permaslug": "arliai/qwq-32b-arliai-rpr-v1",
                "count": 340,
                "total_completion_tokens": 538688,
                "total_prompt_tokens": 1537100,
                "total_native_tokens_reasoning": 363760,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 108231,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "microsoft/phi-3-mini-128k-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/phi-3-mini-128k-instruct",
                "variant": "standard",
                "variant_permaslug": "microsoft/phi-3-mini-128k-instruct",
                "count": 8961,
                "total_completion_tokens": 1024883,
                "total_prompt_tokens": 1352510,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "microsoft/phi-3.5-mini-128k-instruct": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "microsoft/phi-3.5-mini-128k-instruct",
                "variant": "standard",
                "variant_permaslug": "microsoft/phi-3.5-mini-128k-instruct",
                "count": 22774,
                "total_completion_tokens": 11546593,
                "total_prompt_tokens": 45455437,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            },
            "moonshotai/kimi-k2:free": {
                "date": "2025-12-30 00:00:00",
                "model_permaslug": "moonshotai/kimi-k2",
                "variant": "free",
                "variant_permaslug": "moonshotai/kimi-k2:free",
                "count": 3872,
                "total_completion_tokens": 2693785,
                "total_prompt_tokens": 19810393,
                "total_native_tokens_reasoning": 0,
                "num_media_prompt": 0,
                "num_media_completion": 0,
                "num_audio_prompt": 0,
                "total_native_tokens_cached": 0,
                "total_tool_calls": 0,
                "requests_with_tool_call_errors": 0
            }
        },
        "categories": {
            "x-ai/grok-code-fast-1": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-code-fast-1",
                    "category": "programming",
                    "count": 10819,
                    "total_prompt_tokens": 722307875,
                    "total_completion_tokens": 6942474,
                    "volume": 3.3888124476,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-code-fast-1",
                    "category": "academia",
                    "count": 641,
                    "total_prompt_tokens": 2033027,
                    "total_completion_tokens": 786655,
                    "volume": 0.09219455459999999,
                    "rank": 10
                }
            ],
            "openai/gpt-oss-120b": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-oss-120b",
                    "category": "legal",
                    "count": 2720,
                    "total_prompt_tokens": 10656515,
                    "total_completion_tokens": 774007,
                    "volume": 2.25335594706,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-oss-120b",
                    "category": "finance",
                    "count": 2360,
                    "total_prompt_tokens": 15536775,
                    "total_completion_tokens": 1265542,
                    "volume": 2.54912158842,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-oss-120b",
                    "category": "marketing",
                    "count": 552,
                    "total_prompt_tokens": 3057418,
                    "total_completion_tokens": 653818,
                    "volume": 0.2987839062,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-oss-120b",
                    "category": "science",
                    "count": 4854,
                    "total_prompt_tokens": 19147438,
                    "total_completion_tokens": 3033274,
                    "volume": 3.94504554233,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-oss-120b",
                    "category": "technology",
                    "count": 4451,
                    "total_prompt_tokens": 27068845,
                    "total_completion_tokens": 2931476,
                    "volume": 4.51576643934,
                    "rank": 9
                }
            ],
            "google/gemini-2.0-flash-001": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.0-flash-001",
                    "category": "translation",
                    "count": 42963,
                    "total_prompt_tokens": 43075334,
                    "total_completion_tokens": 12350542,
                    "volume": 2.264674604,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.0-flash-001",
                    "category": "trivia",
                    "count": 464,
                    "total_prompt_tokens": 756731,
                    "total_completion_tokens": 56669,
                    "volume": 0.1305126125,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.0-flash-001",
                    "category": "legal",
                    "count": 1305,
                    "total_prompt_tokens": 2137533,
                    "total_completion_tokens": 767354,
                    "volume": 0.5053223487,
                    "rank": 7
                }
            ],
            "openai/gpt-4.1-nano-2025-04-14": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4.1-nano-2025-04-14",
                    "category": "health",
                    "count": 1799,
                    "total_prompt_tokens": 8398277,
                    "total_completion_tokens": 365671,
                    "volume": 0.4039945,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4.1-nano-2025-04-14",
                    "category": "finance",
                    "count": 788,
                    "total_prompt_tokens": 10454803,
                    "total_completion_tokens": 86668,
                    "volume": 0.5160897,
                    "rank": 8
                }
            ],
            "xiaomi/mimo-v2-flash-20251210:free": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "trivia",
                    "count": 526,
                    "total_prompt_tokens": 490714,
                    "total_completion_tokens": 5157037,
                    "volume": 0,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "academia",
                    "count": 1667,
                    "total_prompt_tokens": 5986422,
                    "total_completion_tokens": 8133804,
                    "volume": 0,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "finance",
                    "count": 2208,
                    "total_prompt_tokens": 51274800,
                    "total_completion_tokens": 3611415,
                    "volume": 0,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "science",
                    "count": 6051,
                    "total_prompt_tokens": 44488160,
                    "total_completion_tokens": 28680609,
                    "volume": 0.02,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "roleplay",
                    "count": 9701,
                    "total_prompt_tokens": 111361417,
                    "total_completion_tokens": 7145568,
                    "volume": 0.06,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "marketing",
                    "count": 1015,
                    "total_prompt_tokens": 5884011,
                    "total_completion_tokens": 416007,
                    "volume": 0,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "translation",
                    "count": 1487,
                    "total_prompt_tokens": 2950234,
                    "total_completion_tokens": 1372682,
                    "volume": 0,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "technology",
                    "count": 4818,
                    "total_prompt_tokens": 39892564,
                    "total_completion_tokens": 2891365,
                    "volume": 0.04,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "health",
                    "count": 857,
                    "total_prompt_tokens": 2560588,
                    "total_completion_tokens": 195691,
                    "volume": 0,
                    "rank": 9
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "xiaomi/mimo-v2-flash-20251210",
                    "category": "programming",
                    "count": 2105,
                    "total_prompt_tokens": 92760996,
                    "total_completion_tokens": 1334718,
                    "volume": 0.08,
                    "rank": 9
                }
            ],
            "google/gemini-2.5-flash-lite": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "marketing",
                    "count": 4075,
                    "total_prompt_tokens": 15081976,
                    "total_completion_tokens": 1088468,
                    "volume": 1.084619044,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "translation",
                    "count": 8300,
                    "total_prompt_tokens": 8252181,
                    "total_completion_tokens": 2151255,
                    "volume": 1.6389138985,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "legal",
                    "count": 2047,
                    "total_prompt_tokens": 3930665,
                    "total_completion_tokens": 1129742,
                    "volume": 0.728451155,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "technology",
                    "count": 8436,
                    "total_prompt_tokens": 44423512,
                    "total_completion_tokens": 4721486,
                    "volume": 2.5539322356,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "academia",
                    "count": 1900,
                    "total_prompt_tokens": 5818564,
                    "total_completion_tokens": 654236,
                    "volume": 1.482736439,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "health",
                    "count": 5064,
                    "total_prompt_tokens": 2920567,
                    "total_completion_tokens": 726793,
                    "volume": 0.697191262,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite",
                    "category": "marketing/seo",
                    "count": 562,
                    "total_prompt_tokens": 602010,
                    "total_completion_tokens": 68747,
                    "volume": 0.11589218200000001,
                    "rank": 9
                }
            ],
            "deepseek/deepseek-v3.2-20251201": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-v3.2-20251201",
                    "category": "roleplay",
                    "count": 32277,
                    "total_prompt_tokens": 277716463,
                    "total_completion_tokens": 15706929,
                    "volume": 19.92857641669,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-v3.2-20251201",
                    "category": "academia",
                    "count": 1807,
                    "total_prompt_tokens": 7477948,
                    "total_completion_tokens": 2542377,
                    "volume": 3.07457465092,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-v3.2-20251201",
                    "category": "finance",
                    "count": 1692,
                    "total_prompt_tokens": 12850842,
                    "total_completion_tokens": 698373,
                    "volume": 6.82752035295,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-v3.2-20251201",
                    "category": "science",
                    "count": 2384,
                    "total_prompt_tokens": 13429929,
                    "total_completion_tokens": 2783902,
                    "volume": 7.94439019019,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-v3.2-20251201",
                    "category": "translation",
                    "count": 788,
                    "total_prompt_tokens": 1482502,
                    "total_completion_tokens": 900815,
                    "volume": 0.7318162037,
                    "rank": 9
                }
            ],
            "anthropic/claude-4.5-opus-20251124": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-opus-20251124",
                    "category": "technology",
                    "count": 2074,
                    "total_prompt_tokens": 112732492,
                    "total_completion_tokens": 728960,
                    "volume": 194.72897545,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-opus-20251124",
                    "category": "programming",
                    "count": 3509,
                    "total_prompt_tokens": 153364685,
                    "total_completion_tokens": 3045665,
                    "volume": 497.65799445,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-opus-20251124",
                    "category": "marketing/seo",
                    "count": 51,
                    "total_prompt_tokens": 1029850,
                    "total_completion_tokens": 23550,
                    "volume": 6.4538,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-opus-20251124",
                    "category": "science",
                    "count": 623,
                    "total_prompt_tokens": 15834421,
                    "total_completion_tokens": 294290,
                    "volume": 50.90821315,
                    "rank": 8
                }
            ],
            "x-ai/grok-4-fast": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4-fast",
                    "category": "marketing/seo",
                    "count": 1513,
                    "total_prompt_tokens": 6604300,
                    "total_completion_tokens": 2228450,
                    "volume": 1.5444703575,
                    "rank": 1
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4-fast",
                    "category": "translation",
                    "count": 634,
                    "total_prompt_tokens": 5470337,
                    "total_completion_tokens": 97679,
                    "volume": 0.8411091414999999,
                    "rank": 4
                }
            ],
            "anthropic/claude-4.5-sonnet-20250929": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "technology",
                    "count": 3163,
                    "total_prompt_tokens": 100674255,
                    "total_completion_tokens": 1649197,
                    "volume": 165.90507555,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "legal",
                    "count": 252,
                    "total_prompt_tokens": 5728175,
                    "total_completion_tokens": 157647,
                    "volume": 15.44963503,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "science",
                    "count": 1627,
                    "total_prompt_tokens": 26942468,
                    "total_completion_tokens": 814333,
                    "volume": 103.214426765,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "programming",
                    "count": 2591,
                    "total_prompt_tokens": 126196547,
                    "total_completion_tokens": 1644262,
                    "volume": 182.5004750275,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "academia",
                    "count": 469,
                    "total_prompt_tokens": 4921481,
                    "total_completion_tokens": 297719,
                    "volume": 16.675146235,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-sonnet-20250929",
                    "category": "trivia",
                    "count": 58,
                    "total_prompt_tokens": 409776,
                    "total_completion_tokens": 15775,
                    "volume": 0.80090547,
                    "rank": 10
                }
            ],
            "google/gemini-3-flash-preview-20251217": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "programming",
                    "count": 4439,
                    "total_prompt_tokens": 163343905,
                    "total_completion_tokens": 1986471,
                    "volume": 32.4316894725,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "science",
                    "count": 3257,
                    "total_prompt_tokens": 33450709,
                    "total_completion_tokens": 1460469,
                    "volume": 15.0611678325,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "health",
                    "count": 2183,
                    "total_prompt_tokens": 4757137,
                    "total_completion_tokens": 696483,
                    "volume": 5.123965865,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "legal",
                    "count": 1108,
                    "total_prompt_tokens": 3667440,
                    "total_completion_tokens": 320829,
                    "volume": 3.324001065,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "trivia",
                    "count": 259,
                    "total_prompt_tokens": 840717,
                    "total_completion_tokens": 58103,
                    "volume": 0.7024423399999999,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "marketing/seo",
                    "count": 202,
                    "total_prompt_tokens": 801232,
                    "total_completion_tokens": 189914,
                    "volume": 1.1145293600000001,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "technology",
                    "count": 3897,
                    "total_prompt_tokens": 38634289,
                    "total_completion_tokens": 1224417,
                    "volume": 17.230824485,
                    "rank": 8
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "translation",
                    "count": 3027,
                    "total_prompt_tokens": 2861823,
                    "total_completion_tokens": 960827,
                    "volume": 3.566458585,
                    "rank": 8
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "academia",
                    "count": 1021,
                    "total_prompt_tokens": 2783437,
                    "total_completion_tokens": 329099,
                    "volume": 2.437878095,
                    "rank": 8
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "finance",
                    "count": 1301,
                    "total_prompt_tokens": 8746199,
                    "total_completion_tokens": 352544,
                    "volume": 4.905809405,
                    "rank": 9
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-flash-preview-20251217",
                    "category": "roleplay",
                    "count": 6151,
                    "total_prompt_tokens": 38841834,
                    "total_completion_tokens": 2132220,
                    "volume": 17.866279852999998,
                    "rank": 10
                }
            ],
            "openai/gpt-4o-mini": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "trivia",
                    "count": 1374,
                    "total_prompt_tokens": 1475378,
                    "total_completion_tokens": 17908,
                    "volume": 0.1598508975,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "marketing/seo",
                    "count": 866,
                    "total_prompt_tokens": 569742,
                    "total_completion_tokens": 174068,
                    "volume": 0.227388019,
                    "rank": 8
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "legal",
                    "count": 3727,
                    "total_prompt_tokens": 1435009,
                    "total_completion_tokens": 1103613,
                    "volume": 0.8661073875,
                    "rank": 8
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "marketing",
                    "count": 2148,
                    "total_prompt_tokens": 1646930,
                    "total_completion_tokens": 107926,
                    "volume": 0.290870478,
                    "rank": 9
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "translation",
                    "count": 3853,
                    "total_prompt_tokens": 1932625,
                    "total_completion_tokens": 317760,
                    "volume": 0.5118075755,
                    "rank": 10
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "finance",
                    "count": 2003,
                    "total_prompt_tokens": 5310559,
                    "total_completion_tokens": 202704,
                    "volume": 0.9278978845,
                    "rank": 10
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-4o-mini",
                    "category": "technology",
                    "count": 7226,
                    "total_prompt_tokens": 24367866,
                    "total_completion_tokens": 969371,
                    "volume": 3.34484637,
                    "rank": 10
                }
            ],
            "google/gemini-2.5-flash": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "health",
                    "count": 1657,
                    "total_prompt_tokens": 7935149,
                    "total_completion_tokens": 703900,
                    "volume": 2.9201088528,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "legal",
                    "count": 2176,
                    "total_prompt_tokens": 6416317,
                    "total_completion_tokens": 407472,
                    "volume": 1.907860591,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "marketing",
                    "count": 1417,
                    "total_prompt_tokens": 6063660,
                    "total_completion_tokens": 719708,
                    "volume": 2.571582621,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "academia",
                    "count": 4102,
                    "total_prompt_tokens": 10237031,
                    "total_completion_tokens": 1578370,
                    "volume": 4.8671372154,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "marketing/seo",
                    "count": 597,
                    "total_prompt_tokens": 3365154,
                    "total_completion_tokens": 491999,
                    "volume": 1.286256402,
                    "rank": 2
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "finance",
                    "count": 4328,
                    "total_prompt_tokens": 12267908,
                    "total_completion_tokens": 1361690,
                    "volume": 4.238565083,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "translation",
                    "count": 6715,
                    "total_prompt_tokens": 6188502,
                    "total_completion_tokens": 813426,
                    "volume": 3.138038528,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "roleplay",
                    "count": 16694,
                    "total_prompt_tokens": 110439963,
                    "total_completion_tokens": 7017866,
                    "volume": 40.2430322517,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "science",
                    "count": 7330,
                    "total_prompt_tokens": 25159293,
                    "total_completion_tokens": 1497760,
                    "volume": 10.0308608729,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "trivia",
                    "count": 1080,
                    "total_prompt_tokens": 886891,
                    "total_completion_tokens": 66074,
                    "volume": 0.37330915000000003,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash",
                    "category": "technology",
                    "count": 9238,
                    "total_prompt_tokens": 39734312,
                    "total_completion_tokens": 3117192,
                    "volume": 14.703286727,
                    "rank": 6
                }
            ],
            "openai/gpt-5.2-20251211": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-5.2-20251211",
                    "category": "technology",
                    "count": 867,
                    "total_prompt_tokens": 74816628,
                    "total_completion_tokens": 429389,
                    "volume": 19.90857002,
                    "rank": 3
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-5.2-20251211",
                    "category": "academia",
                    "count": 139,
                    "total_prompt_tokens": 7760704,
                    "total_completion_tokens": 175093,
                    "volume": 5.15608555,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-5.2-20251211",
                    "category": "marketing",
                    "count": 28,
                    "total_prompt_tokens": 2315750,
                    "total_completion_tokens": 8200,
                    "volume": 0.5194593,
                    "rank": 6
                }
            ],
            "meta-llama/llama-3.1-70b-instruct": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "meta-llama/llama-3.1-70b-instruct",
                    "category": "trivia",
                    "count": 1772,
                    "total_prompt_tokens": 1424178,
                    "total_completion_tokens": 1806,
                    "volume": 0.460807252,
                    "rank": 3
                }
            ],
            "google/gemini-2.5-flash-lite-preview-09-2025": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-lite-preview-09-2025",
                    "category": "marketing/seo",
                    "count": 303,
                    "total_prompt_tokens": 1383952,
                    "total_completion_tokens": 564583,
                    "volume": 0.36793887799999997,
                    "rank": 3
                }
            ],
            "mistralai/devstral-2512:free": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/devstral-2512",
                    "category": "health",
                    "count": 1634,
                    "total_prompt_tokens": 4901127,
                    "total_completion_tokens": 241256,
                    "volume": 0,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/devstral-2512",
                    "category": "programming",
                    "count": 1750,
                    "total_prompt_tokens": 138531453,
                    "total_completion_tokens": 753678,
                    "volume": 0.32468127550000003,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/devstral-2512",
                    "category": "legal",
                    "count": 878,
                    "total_prompt_tokens": 4295413,
                    "total_completion_tokens": 84904,
                    "volume": 0.0000156222,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/devstral-2512",
                    "category": "academia",
                    "count": 942,
                    "total_prompt_tokens": 4175008,
                    "total_completion_tokens": 1161222,
                    "volume": 0.04014985,
                    "rank": 6
                }
            ],
            "anthropic/claude-4.5-haiku-20251001": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-haiku-20251001",
                    "category": "technology",
                    "count": 1737,
                    "total_prompt_tokens": 53073590,
                    "total_completion_tokens": 519755,
                    "volume": 12.80101721,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4.5-haiku-20251001",
                    "category": "health",
                    "count": 144,
                    "total_prompt_tokens": 3923949,
                    "total_completion_tokens": 127578,
                    "volume": 4.588274999999999,
                    "rank": 6
                }
            ],
            "x-ai/grok-4.1-fast": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4.1-fast",
                    "category": "trivia",
                    "count": 719,
                    "total_prompt_tokens": 963133,
                    "total_completion_tokens": 192459,
                    "volume": 0.461699892,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4.1-fast",
                    "category": "marketing",
                    "count": 545,
                    "total_prompt_tokens": 3245052,
                    "total_completion_tokens": 412701,
                    "volume": 0.974329175,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4.1-fast",
                    "category": "roleplay",
                    "count": 10538,
                    "total_prompt_tokens": 80620876,
                    "total_completion_tokens": 6066031,
                    "volume": 11.9456982565,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4.1-fast",
                    "category": "marketing/seo",
                    "count": 364,
                    "total_prompt_tokens": 460606,
                    "total_completion_tokens": 587292,
                    "volume": 0.5830270305,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "x-ai/grok-4.1-fast",
                    "category": "finance",
                    "count": 2949,
                    "total_prompt_tokens": 10047623,
                    "total_completion_tokens": 758601,
                    "volume": 3.626605221,
                    "rank": 7
                }
            ],
            "deepseek/deepseek-chat-v3-0324": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-chat-v3-0324",
                    "category": "roleplay",
                    "count": 16525,
                    "total_prompt_tokens": 93963057,
                    "total_completion_tokens": 3714556,
                    "volume": 30.7715743326,
                    "rank": 4
                }
            ],
            "openai/gpt-5-mini-2025-08-07": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-5-mini-2025-08-07",
                    "category": "marketing/seo",
                    "count": 422,
                    "total_prompt_tokens": 1034212,
                    "total_completion_tokens": 249987,
                    "volume": 1.2660219899999998,
                    "rank": 4
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "openai/gpt-5-mini-2025-08-07",
                    "category": "finance",
                    "count": 1806,
                    "total_prompt_tokens": 11677901,
                    "total_completion_tokens": 845545,
                    "volume": 4.6079584325,
                    "rank": 5
                }
            ],
            "anthropic/claude-4-sonnet-20250522": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "anthropic/claude-4-sonnet-20250522",
                    "category": "health",
                    "count": 865,
                    "total_prompt_tokens": 3554000,
                    "total_completion_tokens": 1040083,
                    "volume": 30.04110489,
                    "rank": 5
                }
            ],
            "z-ai/glm-4.7-20251222": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "z-ai/glm-4.7-20251222",
                    "category": "translation",
                    "count": 803,
                    "total_prompt_tokens": 2731664,
                    "total_completion_tokens": 2632615,
                    "volume": 0.46260208399999997,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "z-ai/glm-4.7-20251222",
                    "category": "programming",
                    "count": 3578,
                    "total_prompt_tokens": 61224907,
                    "total_completion_tokens": 4247654,
                    "volume": 16.1320460216,
                    "rank": 10
                }
            ],
            "minimax/minimax-m2.1": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "minimax/minimax-m2.1",
                    "category": "science",
                    "count": 519,
                    "total_prompt_tokens": 24710839,
                    "total_completion_tokens": 736206,
                    "volume": 3.7539722892,
                    "rank": 5
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "minimax/minimax-m2.1",
                    "category": "programming",
                    "count": 1499,
                    "total_prompt_tokens": 93711376,
                    "total_completion_tokens": 805547,
                    "volume": 2.5659924635,
                    "rank": 8
                }
            ],
            "tngtech/deepseek-r1t2-chimera:free": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "tngtech/deepseek-r1t2-chimera",
                    "category": "roleplay",
                    "count": 8522,
                    "total_prompt_tokens": 84911524,
                    "total_completion_tokens": 6933486,
                    "volume": 0.6343763845,
                    "rank": 5
                }
            ],
            "deepseek/deepseek-chat-v3.1": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-chat-v3.1",
                    "category": "finance",
                    "count": 697,
                    "total_prompt_tokens": 10354951,
                    "total_completion_tokens": 1001527,
                    "volume": 2.8680224134,
                    "rank": 6
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "deepseek/deepseek-chat-v3.1",
                    "category": "roleplay",
                    "count": 14524,
                    "total_prompt_tokens": 65877601,
                    "total_completion_tokens": 1990267,
                    "volume": 22.54238274426,
                    "rank": 8
                }
            ],
            "minimax/minimax-m2": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "minimax/minimax-m2",
                    "category": "programming",
                    "count": 1408,
                    "total_prompt_tokens": 111089679,
                    "total_completion_tokens": 869611,
                    "volume": 1.60066254315,
                    "rank": 6
                }
            ],
            "meta-llama/llama-3.1-8b-instruct": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "meta-llama/llama-3.1-8b-instruct",
                    "category": "translation",
                    "count": 3631,
                    "total_prompt_tokens": 4020851,
                    "total_completion_tokens": 204941,
                    "volume": 0.029194335,
                    "rank": 7
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "meta-llama/llama-3.1-8b-instruct",
                    "category": "trivia",
                    "count": 885,
                    "total_prompt_tokens": 550886,
                    "total_completion_tokens": 8709,
                    "volume": 0.0166291247,
                    "rank": 8
                }
            ],
            "kwaipilot/kat-coder-pro-v1:free": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "kwaipilot/kat-coder-pro-v1",
                    "category": "programming",
                    "count": 1529,
                    "total_prompt_tokens": 95424452,
                    "total_completion_tokens": 999022,
                    "volume": 0.00102673242,
                    "rank": 7
                }
            ],
            "meta-llama/llama-3.3-70b-instruct": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "meta-llama/llama-3.3-70b-instruct",
                    "category": "marketing",
                    "count": 285,
                    "total_prompt_tokens": 2204950,
                    "total_completion_tokens": 40050,
                    "volume": 0.33389253249999995,
                    "rank": 7
                }
            ],
            "nex-agi/deepseek-v3.1-nex-n1:free": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "nex-agi/deepseek-v3.1-nex-n1",
                    "category": "roleplay",
                    "count": 5298,
                    "total_prompt_tokens": 74845785,
                    "total_completion_tokens": 2869700,
                    "volume": 0.08,
                    "rank": 7
                }
            ],
            "google/gemini-2.5-pro": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-pro",
                    "category": "health",
                    "count": 344,
                    "total_prompt_tokens": 2629154,
                    "total_completion_tokens": 310589,
                    "volume": 6.3619253625,
                    "rank": 8
                }
            ],
            "qwen/qwen3-30b-a3b-04-28": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "qwen/qwen3-30b-a3b-04-28",
                    "category": "marketing",
                    "count": 645,
                    "total_prompt_tokens": 1419400,
                    "total_completion_tokens": 392350,
                    "volume": 0.27276192,
                    "rank": 8
                }
            ],
            "qwen/qwen-2.5-72b-instruct": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "qwen/qwen-2.5-72b-instruct",
                    "category": "legal",
                    "count": 1831,
                    "total_prompt_tokens": 1819796,
                    "total_completion_tokens": 22488,
                    "volume": 0.2820044395,
                    "rank": 9
                }
            ],
            "mistralai/mistral-nemo": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/mistral-nemo",
                    "category": "roleplay",
                    "count": 12314,
                    "total_prompt_tokens": 42845897,
                    "total_completion_tokens": 1125652,
                    "volume": 1.08135126444,
                    "rank": 9
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/mistral-nemo",
                    "category": "trivia",
                    "count": 112,
                    "total_prompt_tokens": 428899,
                    "total_completion_tokens": 9129,
                    "volume": 0.0091135574,
                    "rank": 9
                }
            ],
            "google/gemini-3-pro-preview-20251117": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-pro-preview-20251117",
                    "category": "science",
                    "count": 528,
                    "total_prompt_tokens": 13802691,
                    "total_completion_tokens": 774351,
                    "volume": 30.741309935,
                    "rank": 9
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-3-pro-preview-20251117",
                    "category": "marketing",
                    "count": 48,
                    "total_prompt_tokens": 1331607,
                    "total_completion_tokens": 52594,
                    "volume": 2.28418494,
                    "rank": 10
                }
            ],
            "mistralai/mistral-small-3.2-24b-instruct-2506": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "mistralai/mistral-small-3.2-24b-instruct-2506",
                    "category": "academia",
                    "count": 860,
                    "total_prompt_tokens": 1693550,
                    "total_completion_tokens": 1284200,
                    "volume": 0.58240057,
                    "rank": 9
                }
            ],
            "google/gemini-2.5-flash-preview-09-2025": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-preview-09-2025",
                    "category": "marketing/seo",
                    "count": 35,
                    "total_prompt_tokens": 544450,
                    "total_completion_tokens": 20300,
                    "volume": 0.187467575,
                    "rank": 10
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-preview-09-2025",
                    "category": "legal",
                    "count": 141,
                    "total_prompt_tokens": 1549421,
                    "total_completion_tokens": 72736,
                    "volume": 0.363571416,
                    "rank": 10
                },
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "google/gemini-2.5-flash-preview-09-2025",
                    "category": "health",
                    "count": 500,
                    "total_prompt_tokens": 2405076,
                    "total_completion_tokens": 283403,
                    "volume": 2.051381875,
                    "rank": 10
                }
            ],
            "qwen/qwen3-vl-235b-a22b-instruct": [
                {
                    "id": 0,
                    "date": "2026-01-05",
                    "model": "qwen/qwen3-vl-235b-a22b-instruct",
                    "category": "science",
                    "count": 4800,
                    "total_prompt_tokens": 13689576,
                    "total_completion_tokens": 496494,
                    "volume": 2.739789646,
                    "rank": 10
                }
            ]
        }
    }
}